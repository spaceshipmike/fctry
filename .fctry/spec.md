# fctry

```yaml
---
title: fctry
spec-version: 3.42
plugin-version: 0.24.0
date: 2026-02-27
status: active
author: Mike
spec-format: nlspec-v2
synopsis:
  short: "Claude Code plugin for autonomous software development from experience-first specs"
  medium: "fctry is a Claude Code plugin that orchestrates eight specialized agents to produce experience-first specifications (NLSpec v2), then drives autonomous parallel builds from them. A recursive kanban interface lets non-coders visually prioritize what matters, auto-generated diagrams reveal how everything connects, and dark mode keeps it comfortable at any hour."
  readme: "fctry is a Claude Code plugin that enables autonomous software development from experience-first specifications. It provides seven commands that orchestrate eight specialized agents to convert conversational descriptions of user experiences into complete NLSpec v2 documents, generate scenario holdout sets, and manage the build-measure-learn loop until scenario satisfaction is achieved. The spec viewer serves as a recursive kanban board — projects, sections, and sub-features are all draggable cards in priority columns, with auto-generated diagrams, dark mode, and fuzzy search. Designed for a non-coder with many projects and a clear vision for each — no code review, no implementation decisions, just vision in, working software out."
  tech-stack: ["Node.js", "SQLite", "WebSocket", "Mermaid.js", "Claude Code Plugin API"]
  patterns: ["multi-agent pipeline", "event-driven", "holdout-set validation", "experience-first specification", "recursive kanban"]
  goals: ["Enable non-coders to build software from conversational vision descriptions", "Autonomous end-to-end development with spec and scenarios as the only contract", "Multi-project management with visual prioritization and progressive refinement across sessions", "Seamless plugin upgrades that silently bring projects forward without losing user customizations", "Cross-session institutional learning — the system remembers what worked and what didn't"]
---
```

fctry is a Claude Code plugin that enables autonomous software development from experience-first specifications. It provides seven commands (/fctry:init, evolve, ref, review, execute, view, stop) that orchestrate eight specialized agents to produce complete specifications in NLSpec v2 format, then drive autonomous parallel builds toward satisfaction across user scenarios. The user approves the plan once; the system executes independently until scenarios are satisfied, resurfacing only for experience-level questions. Agents verify their own outputs through the Observer — an infrastructure agent that can observe any surface (browser, terminal, file system, APIs) and report findings back to the calling agent. The spec viewer serves as a decision surface — a project dashboard with aggregated state and recommended next actions, live mission control during builds, and an async inbox for evolve ideas, references, and new features — so the factory never idles. No human touches or reviews the code — the spec and scenarios are the entire contract. Designed for a non-coder with many projects and a clear vision for each.

---

## Table of Contents

1. [Vision and Principles](#1-vision-and-principles)
   - 1.1 [Problem Statement](#11-problem-statement) `#problem-statement`
   - 1.2 [What This System Is](#12-what-this-system-is) `#what-this-is`
   - 1.3 [Design Principles](#13-design-principles) `#design-principles`
   - 1.4 [What Success Looks Like](#14-what-success-looks-like) `#success-looks-like`
2. [The Experience](#2-the-experience)
   - 2.1 [First Run / Onboarding](#21-first-run--onboarding) `#first-run`
   - 2.2 [Core Flow: From Idea to Spec](#22-core-flow-from-idea-to-spec) `#core-flow`
   - 2.3 [Multi-Session Interviews](#23-multi-session-interviews) `#multi-session`
   - 2.4 [Evolving an Existing Spec](#24-evolving-an-existing-spec) `#evolve-flow`
   - 2.5 [Incorporating References](#25-incorporating-references) `#ref-flow`
   - 2.6 [Reviewing Alignment](#26-reviewing-alignment) `#review-flow`
   - 2.7 [Executing the Build](#27-executing-the-build) `#execute-flow`
   - 2.8 [Navigating by Section](#28-navigating-by-section) `#navigate-sections`
   - 2.9 [Live Spec Viewer](#29-live-spec-viewer) `#spec-viewer`
   - 2.10 [What Happens When Things Go Wrong](#210-what-happens-when-things-go-wrong) `#error-handling`
   - 2.11 [The Details That Matter](#211-the-details-that-matter) `#details`
   - 2.12 [Terminal Status Line](#212-terminal-status-line) `#status-line`
3. [System Behavior](#3-system-behavior)
   - 3.1 [Core Capabilities](#31-core-capabilities) `#capabilities`
   - 3.2 [Things the System Keeps Track Of](#32-things-the-system-keeps-track-of) `#entities`
   - 3.3 [Rules and Logic](#33-rules-and-logic) `#rules`
   - 3.4 [External Connections](#34-external-connections) `#external-connections`
   - 3.5 [Performance Expectations](#35-performance-expectations) `#performance`
4. [Boundaries and Constraints](#4-boundaries-and-constraints)
   - 4.1 [Scope](#41-scope) `#scope`
   - 4.2 [Platform and Environment](#42-platform-and-environment) `#platform`
   - 4.3 [Directory Structure and Git Tracking](#43-directory-structure-and-git-tracking) `#directory-structure`
   - 4.4 [Hard Constraints](#44-hard-constraints) `#hard-constraints`
   - 4.5 [Anti-Patterns](#45-anti-patterns) `#anti-patterns`
5. [Reference and Prior Art](#5-reference-and-prior-art)
   - 5.1 [Inspirations](#51-inspirations) `#inspirations`
   - 5.2 [Experience References](#52-experience-references) `#experience-references`
6. [Satisfaction and Convergence](#6-satisfaction-and-convergence)
   - 6.1 [Satisfaction Definition](#61-satisfaction-definition) `#satisfaction-definition`
   - 6.2 [Convergence Strategy](#62-convergence-strategy) `#convergence-strategy`
   - 6.3 [Observability](#63-observability) `#observability`
   - 6.4 [What the Agent Decides](#64-what-the-agent-decides) `#agent-decides`

Appendices:
- [A: Decision Rationale](#appendix-a-decision-rationale)
- [B: Glossary](#appendix-b-glossary)

---

## 1. Vision and Principles

### 1.1 Problem Statement {#problem-statement}

A non-coder with a clear vision for a software project faces a painful choice: learn to code (hundreds of hours), hire developers (expensive, slow, communication overhead), or settle for no-code tools that constrain the vision. Even with AI coding assistants, the non-coder must translate their experience-oriented vision into implementation language — databases, APIs, architectural decisions — which they don't have mental models for.

Meanwhile, the StrongDM Software Factory model has demonstrated that code written entirely by machines, validated entirely through scenario satisfaction rather than human code review, can reach production quality. The missing piece is a system that bridges the gap: takes an experience-centric vision from a non-technical user and produces a complete, self-contained specification that a coding agent can build from without asking follow-up questions.

This spec solves that problem. It enables a single person with many project ideas to articulate their vision conversationally, refine it over multiple sessions, incorporate inspiration from the web, and launch autonomous builds — all without touching code or learning implementation concepts.

### 1.2 What This System Is {#what-this-is}

fctry is a Claude Code plugin that orchestrates eight specialized agents across seven commands to produce experience-first specifications and drive autonomous builds from them. It converts conversational descriptions of "what the user sees, does, and feels" into complete NLSpec v2 documents, generates scenario holdout sets, and manages the build-measure-learn loop until scenario satisfaction is achieved. The system delivers the core command loop (init, evolve, ref, review, execute) with multi-session interviews, addressable spec sections, conflict resolution, context-aware reference incorporation, tool validation, and changelog-aware drift detection. Builds are plan-gated and autonomous: the user approves the plan once, and the system executes independently — handling failures, retries, and rearchitecting silently — resurfacing only when the spec is ambiguous or contradictory. The live spec viewer (view, stop) provides WebSocket updates, section highlighting, and visual change history during spec work, then transforms into mission control during builds (showing build progress and section completion) and an async inbox for evolve ideas, references, and new features. The system enforces its own workflow (preventing agents from skipping steps), maintains a structured spec index for efficient section-level access, and tracks per-section readiness so both the user and agents know what's ready to build at a glance.

### 1.3 Design Principles {#design-principles}

**Experience language, always.** The system accepts and produces descriptions of what users see, do, and feel — never databases, APIs, or code patterns. When the user says "I want a list of my recent items, sorted by urgency, with overdue ones highlighted," that exact phrasing appears in the spec. This rules out any UI that asks the user to describe data models, API endpoints, or technical architecture.

**The agent decides implementation.** Every spec explicitly grants the coding agent full authority over technology choices, architecture, and data model. The user describes the experience; the agent figures out how to build it. This rules out any UI that lets the user specify frameworks, libraries, or implementation details unless they're genuinely experience constraints (e.g., "must work offline" is an experience constraint; "must use SQLite" is an implementation detail the agent infers).

**Grounded in reality.** Every command starts with the State Owner scanning the current codebase and producing a briefing. Spec updates are always informed by what actually exists. This rules out speculative updates that ignore the current state — the system never updates a spec without first understanding whether code exists, what state it's in, and how it relates to the spec.

**Plan-gated, autonomous execution.** The Executor proposes a build plan; the user approves it once. After approval, the system executes autonomously — handling failures, retries, and rearchitecting silently — until scenarios are satisfied or it encounters an experience-level question that only the user can answer. The user controls what gets built (the plan) but not the moment-to-moment execution. This rules out per-chunk approval gates that interrupt the build for technical decisions, while preserving the user's authority over the scope and direction of work.

**Conversational, not form-filling.** The Interviewer draws out the vision through dialogue, asking follow-up questions based on what the user says. This rules out wizards, forms, or templates the user fills in. The experience feels like talking to a co-founder who's helping you think through your vision.

**Progressive, not all-at-once.** Commands are discrete steps. The user can run init to create a spec, stop for a week, run evolve to add a feature, run ref to incorporate inspiration, run execute to build. Each command stands alone. This rules out workflows that require completing all steps in one session or remembering complex state between sessions.

**Process-aware, not just process-documented.** The system enforces its own workflow — agents cannot skip steps, and the user always knows whether they're working within the factory process or outside it. When code changes happen outside fctry commands, the system notices and surfaces them. This rules out silent process drift where the user thinks they're following the factory model but Claude has reverted to ad-hoc development.

**Addressable and navigable.** Every section of the spec has both a stable alias (e.g., `#core-flow`) and a number (e.g., `2.2`). Users can reference sections in commands: `/fctry:evolve core-flow` or `/fctry:evolve 2.2`. The spec viewer highlights the section being worked on. This rules out opaque specs where users can't point to specific parts or understand what's changing.

### 1.4 What Success Looks Like {#success-looks-like}

The user opens Claude Code, types `/fctry:init`, and within minutes is having a conversation about their vision. The Interviewer asks thoughtful questions. The conversation feels natural. When it's done, the user sees a complete spec that captures exactly what they described — clear enough that they can read it and say "yes, that's it," specific enough that a coding agent can build from it.

Days later, they think of a feature. They type `/fctry:evolve core-flow` and describe the change. The system updates just that section, shows exactly what changed, and the spec remains coherent.

They see a design they love on the web. They type `/fctry:ref 2.3 https://example.com` and the system interprets the reference in experience language, updates section 2.3, and stores the visual for later.

When they're ready to build, they type `/fctry:execute`. The Executor proposes a plan — showing the work chunks, their dependencies, and the order of operations. They approve. The build runs autonomously. They can watch progress in the spec viewer's mission control: chunks lighting up as they start, sections filling in as they complete. The system never interrupts for code failures or technical decisions — it handles those silently. When the build finishes, instead of a satisfaction scorecard, the Executor presents what the user can now do: "You should now be able to open the app and see your items sorted by urgency, with overdue ones highlighted. The bulk import flow is live — try dragging a CSV file onto the page." Concrete, experience-mapped guidance they can go try immediately.

Throughout, they feel like they have a co-founder who remembers everything, never forgets context, and translates their vision into reality without them needing to learn to code. This isn't a metaphor — the system actually remembers past conversations, recalls their preferences and prior decisions, and carries lessons learned on one project to another. When they return after a week and say "let's revisit the sorting," the system knows what they discussed last time and picks up where they left off.

---

## 2. The Experience

### 2.1 First Run / Onboarding {#first-run}

The user installs the fctry plugin via Claude Code's plugin installer. On first run of any `/fctry` command, the system checks for required tools (ripgrep, ast-grep, gh CLI, MCP servers). If any are missing, the system shows a clear message listing what's missing and how to install it, then stops. This takes under 5 seconds.

Once tools are present, the system checks whether the user's Claude Code settings include deny rules for sensitive credential paths. If not, it recommends a baseline set — `~/.ssh/**`, `~/.aws/**`, `~/.gnupg/**`, `~/.config/gh/**`, `~/.git-credentials`, `~/.docker/config.json`, `~/Library/Keychains/**` — explaining that fctry's Executor has filesystem access during autonomous builds and these paths contain credentials that should never be read. The user can accept all, select which to add, or skip. This is especially important because fctry targets non-coders who may not understand credential exposure risks. After the credential check, the system is ready. There's no account setup, no further configuration file to edit, no initialization step beyond installing the plugin. The user can immediately run `/fctry:init` to start their first spec.

For projects that existed before the version registry was introduced, the migration hook silently seeds `.fctry/config.json` with default version types the first time any command runs — the same defaults that `/fctry:init` would create for a new project. The user sees no prompt or interruption; the registry simply appears alongside the existing spec.

**Plugin version upgrades.** When the fctry plugin updates to a newer version, existing projects may need their infrastructure files updated — new `.gitignore` entries for newly-introduced ephemeral files, missing spec frontmatter fields (like `synopsis` or `plugin-version`), config.json schema extensions (new keys with default values), and a refreshed CLAUDE.md. The migration hook (which already handles directory layout migration) detects this by comparing the project's `formatVersion` in `.fctry/config.json` against the current plugin version. If the project's format version is behind, all needed changes are applied in a single cumulative pass — not version by version — and the user sees a compact inline summary: "↑ Upgraded from v0.15 → v0.20: synopsis block added to spec, 2 .gitignore entries, CLAUDE.md refreshed." Then their command runs normally. The upgrade is purely additive: new fields and entries are added, existing values are never overwritten. Spec frontmatter gains missing fields with sensible defaults (e.g., `synopsis` derived from the spec's title and opening paragraph). Config.json gains missing keys without disturbing existing settings. The `.gitignore` gains new entries without reordering or removing existing ones. Custom entries the user added manually are always preserved. After upgrading, the `formatVersion` is set to the current plugin version.

### 2.2 Core Flow: From Idea to Spec {#core-flow}

The user has an idea for a software project. They open Claude Code in the project directory (or an empty directory if it's greenfield) and type `/fctry:init`.

**Step 1: State assessment (5-15 seconds).** The State Owner agent scans the directory. If code exists, it identifies the tech stack, reads any existing spec or README, and classifies the project (greenfield, has code, has docs, has spec). It produces a briefing that grounds the interview. The user sees: "Classified as greenfield" or "Found existing React app with README but no spec" or "Found spec.md last updated 3 days ago, code last updated yesterday — spec may be ahead."

**Step 2: The interview (5-20 minutes).** The Interviewer agent starts the conversation. It asks: "What is this system? What does it do? Who is it for?" The user describes their vision in plain language. The Interviewer follows up with clarifying questions based on the user's answers:

- "You mentioned a list of items — what information does each item show?"
- "When you say 'sorted by urgency,' how does the system know what's urgent?"
- "What happens when someone opens this for the first time?"
- "When did this go from 'interesting idea' to 'something you actually need'?" (surfaces the value inflection point that reveals what matters most)
- "If you had to describe this project to someone else in one sentence, what would you say?" (reveals the user's mental model vs. what the spec captures — gaps indicate under-specified sections)

The conversation is natural. The user can answer in paragraphs or fragments. The Interviewer adapts. At any point, the user can type `save and pause` and the interview state is saved. They can resume later by typing `/fctry:init --resume`.

When the interview feels complete, the Interviewer asks: "Anything else you want to cover?" If the user says no, the interview ends.

**Step 3: Spec, scenario, version registry, and project instructions generation (30-90 seconds).** The Scenario Crafter writes 5-10 scenarios covering the core flows described in the interview. Then the Spec Writer synthesizes the interview transcript, State Owner briefing, and scenarios into a complete NLSpec v2 document. Both agents write to the `.fctry/` directory: `.fctry/spec.md` and `.fctry/scenarios.md`. The Spec Writer also generates the project synopsis — structured frontmatter fields capturing the project's identity at multiple levels of detail: a short description (one line, under 80 characters), a medium description (2-3 sentences covering purpose, audience, and approach), a README-length description (one paragraph), plus tech stack, architectural patterns, and project goals. These are derived from the interview and written into the spec's YAML frontmatter as the `synopsis` block. The system also seeds the version registry in `.fctry/config.json` with two default version types: the external project version (starting at 0.1.0) and the internal spec version (starting at 0.1), each with initial propagation targets (spec frontmatter for the spec version). The Spec Writer also creates `CLAUDE.md` at the project root with evergreen project instructions: the factory contract (spec and scenario file paths, agent authority, scenario validation approach), a command quick-reference table, an explanation of the `.fctry/` directory and its contents, workflow guidance for working within the factory model, a description of what scenarios are and how they're used, and a `# Compact Instructions` section that tells Claude what to preserve during auto-compaction (spec and scenario file paths, build checkpoint state in `.fctry/state.json`, scenario satisfaction scores, active section and workflow step, and the current build plan if one exists). This evergreen layer gives Claude Code the context it needs to respect the factory model in any future session, even outside of fctry commands, and ensures that critical factory state survives context compaction. On successful completion of init (spec and scenarios both written), the Spec Writer transitions the spec status from `draft` to `active`.

**Step 4: Review.** The user sees a summary:

```
Spec created: .fctry/spec.md (7 sections, 2,400 words)
Scenarios created: .fctry/scenarios.md (8 scenarios)
Version registry seeded: .fctry/config.json (external 0.1.0, spec 0.1)
Project instructions created: CLAUDE.md (evergreen factory context)

Project Synopsis:
  Short:  Task manager for teams who hate project management tools
  Medium: TaskFlow is a lightweight task manager that lets small teams
          track work without the overhead of traditional project management.
          It focuses on speed and simplicity — no sprints, no story points,
          just tasks that flow from idea to done.
  README: TaskFlow is a lightweight task management app for small teams who
          find traditional project management tools overwhelming. It provides
          a single shared board where tasks flow from idea to done with
          minimal ceremony — no sprints, no story points, no status meetings.
          Built for teams of 2-8 who want to stay aligned without the
          overhead. Desktop-first web app with real-time sync.
  Stack:  [Node.js, SQLite, WebSocket]
  Patterns: [event-driven, offline-first]
  Goals:  [Replace sticky notes for small teams, Zero-config task tracking]

Next steps:
- Review the spec
- Run /fctry:evolve <section> to refine
- Run /fctry:execute to start the build
```

The user opens the spec. It reads like a clear, coherent document — not a form, not a template with blanks filled in. Every section has a number and an alias. The user can point to any section and reference it in future commands.

### 2.3 Multi-Session Interviews {#multi-session}

During an interview (either init or evolve), the user can type `save and pause` at any point. The system immediately saves the interview state (transcript so far, questions asked, topics covered, next intended question) and responds. The saved state uses explicit uncertainty markers: questions the user hasn't answered yet are marked OPEN, assumptions the Interviewer made from context are marked ASSUMED (so the user can validate them on resume), and information the user referenced but didn't provide is marked MISSING. This prevents the Interviewer from silently resolving ambiguity during the pause — when the user resumes, they see exactly what's settled and what isn't.

```
Interview state saved. Resume anytime with /fctry:init --resume.
```

When the user returns (hours, days, or weeks later) and types `/fctry:init --resume`, the Interviewer reads the saved state and picks up exactly where they left off:

```
Resuming interview from earlier...
Last we talked, you described the core list view. You mentioned items are sorted by urgency. I was about to ask: how does the system determine urgency?
```

The user continues the conversation. The Interviewer never asks questions already answered. The experience feels like talking to someone with perfect memory.

This memory extends beyond a single paused interview. When a completed evolve or init conversation ends, the system saves a structured digest to the global memory store (`~/.fctry/memory.md`). On future sessions — even weeks or months later — the Interviewer reads relevant digests and references past conversations naturally. The user doesn't just resume a paused interview; they continue a relationship with a system that remembers what they've discussed, what they decided, and what they were uncertain about. The "perfect memory" aspiration applies across all conversations, not just within one interview arc.

If the user types `/fctry:init` without `--resume` when a saved state exists, the system asks: "I found a saved interview in progress. Resume or start fresh?"

### 2.4 Evolving an Existing Spec {#evolve-flow}

The user has a spec. They want to add a feature or change something. They type `/fctry:evolve <section>` where `<section>` is either a number (e.g., `2.2`) or an alias (e.g., `core-flow`).

**Step 1: State assessment (5-15 seconds).** The State Owner scans the current codebase and reads the spec. It produces a briefing: "Spec last updated 2 days ago. Code last updated 1 hour ago. Section 2.2 (core-flow) describes a list view sorted by urgency. Code implements sorting by date. Drift detected."

**Step 2: Targeted interview (2-10 minutes).** The Interviewer focuses the conversation on the specified section. Before starting, it reads relevant conversation digests from the global memory store (`~/.fctry/memory.md`) — past discussions about this section, decisions the user made, topics they were hesitant about. This context lets the Interviewer reference prior conversations: "Last time we discussed this section, you mentioned wanting to keep the sorting simple — has that changed?" The Interviewer also checks for relevant decision records that might inform the current conversation.

The user describes the change. The Interviewer asks follow-up questions specific to the change. The conversation is shorter and more focused than a full init interview.

**Step 3: Update synthesis (15-45 seconds).** The Scenario Crafter updates or adds scenarios relevant to the change. The Spec Writer updates the specified section and any related sections. It does NOT rewrite the entire spec — only the parts affected by the change. The Spec Writer also regenerates the project synopsis in the spec frontmatter — updating the short, medium, and README descriptions, tech stack, patterns, and goals to reflect the current state of the project after the evolve. This ensures the synopsis always matches the spec's current content. The spec version in the version registry auto-increments, and all propagation targets for the spec version are updated. If `.fctry/config.json` doesn't exist yet (e.g., a project created before the version registry was introduced), the system creates it with default version types before incrementing — the evolve never silently skips version tracking. If the spec's status was `stable`, the Spec Writer transitions it to `active` — any evolve that touches the spec reopens it for further iteration.

**Step 4: Diff and review.** The user sees:

```
Spec updated: .fctry/spec.md (spec 1.3 → 1.4)

Changes:
- Section 2.2 (core-flow): Updated sorting logic from date to urgency
- Section 3.3 (rules): Added urgency calculation rule
- Scenarios: Added "Sorting by Urgency Happy Path"
- Synopsis: Updated (short, medium, readme, goals)

Unchanged:
- All other sections remain as-is

Project Synopsis:
  Short:  Task manager for teams who hate project management tools
  Medium: TaskFlow is a lightweight task manager that lets small teams
          track work with urgency-based sorting and minimal ceremony.
          Speed and simplicity over process — tasks flow from idea to done.
  README: [full paragraph]
  Stack:  [Node.js, SQLite, WebSocket]
  Patterns: [event-driven, offline-first]
  Goals:  [Replace sticky notes for small teams, Zero-config task tracking,
           Urgency-driven prioritization]

Next steps:
- Run /fctry:execute to build the new behavior
- Run /fctry:review to confirm alignment
```

The user can see exactly what changed and what to do next. The spec remains coherent. Sections that weren't affected are untouched.

**Async evolve via the viewer.** The user can also submit evolve ideas through the spec viewer's async inbox — typing something like "make onboarding faster" or "add a dark mode toggle." The system queues the idea, identifies affected sections, and prepares context so the next `/fctry:evolve` conversation starts informed. This happens in the background, even during builds. When the user is ready to discuss the idea in Claude Code, the prep work is already done.

If the State Owner detected drift (code and spec disagree), the system surfaces the conflict before the interview:

```
Drift detected: Section 2.2 says items are sorted by urgency, but the code sorts by date. Which is more current?
- The spec (update the code to match)
- The code (update the spec to match)
- Neither (I'll describe what I want)
```

The user chooses. The system proceeds accordingly.

### 2.5 Incorporating References {#ref-flow}

The user sees a design, article, or product that inspires part of their vision. They type `/fctry:ref <section> <url>` (targeted mode) or `/fctry:ref <url>` (open mode).

**Targeted mode (`/fctry:ref 2.3 https://example.com`):**

The State Owner scans the project (5-15 seconds). In parallel, the Researcher or Visual Translator agent fetches and interprets the URL. If it's a web page, the Researcher extracts the relevant experience patterns. If it's a screenshot or design file, the Visual Translator describes what it sees in experience language.

The Spec Writer updates the specified section to incorporate the reference. It adds an entry to section 5.2 (Experience References) linking to the stored asset and describing the interpretation. The user sees:

```
Reference incorporated into section 2.3 (secondary-flow).

Added to spec:
- Section 2.3: Bulk import flow inspired by Notion's CSV import UX
- Section 5.2: Reference to .fctry/references/notion-import.png

Changes:
- Section 2.3 now describes drag-and-drop upload, progress indicator, and preview-before-commit pattern

Next steps:
- Run /fctry:evolve 2.3 to refine the new content
- Run /fctry:execute to build
```

**Open mode (`/fctry:ref https://example.com`):**

The system interprets the reference, then asks clarifying questions to understand where it applies:

```
I see this design uses a sidebar navigation pattern with collapsible sections.
Which part of your spec does this relate to?
- The main navigation (section 2.2)
- The settings panel (section 2.5)
- Something not yet in the spec
```

The user chooses. The system updates accordingly.

**Bare invocation with inbox (`/fctry:ref` with no arguments).** If the user runs `/fctry:ref` without a URL and processed reference items exist in the inbox, the system presents them as numbered options — each showing the page title and, if the user added a note when submitting, the note indented below. The user picks one or more (comma-separated for batch selection), or enters a new URL instead. For each selected reference, the system uses the pre-analyzed data (title, excerpt, note) as starting context — no re-fetch needed. Batch selections run the ref workflow for each reference in sequence, with the Spec Writer batching all updates into one pass. If no processed references exist in the inbox, the system prompts for a URL. This closes the loop on async references: the inbox says "ready for /fctry:ref," and bare `/fctry:ref` picks them up directly.

**Async references via the viewer.** The user can also drop URLs into the spec viewer's async inbox at any time — even during a build. The system fetches and analyzes each URL immediately in experience language, queuing the interpretation for incorporation. When the user next runs `/fctry:ref` (with or without arguments) or `/fctry:evolve`, the reference analysis is already complete and ready to weave into the spec.

### 2.6 Reviewing Alignment {#review-flow}

The user wants to check whether the spec and codebase are aligned. They type `/fctry:review`.

**Step 1: Deep state assessment (10-30 seconds).** The State Owner scans the codebase, reads the spec, reads the changelog, and identifies:
- Sections of the spec that have no corresponding code
- Code that implements things not in the spec
- Sections where the spec and code describe different behavior (drift), with a severity assessment — small drift (a renamed variable, a minor behavior tweak) vs. large drift (an entire flow reimplemented, multiple files diverging from the spec)
- How recently each section was updated (both in the spec and in the code)

The State Owner also performs experience-level analysis: it reconstructs what the user can currently do from the code — reverse-engineering experience stories from the implementation — and compares those stories to the spec. Gaps in either direction surface as experience drift: capabilities the code provides that the spec doesn't describe, or experiences the spec promises that the code can't deliver. This catches drift that structural comparison misses — for example, "the code lets users bulk-import via drag-and-drop, but the spec only describes single-file upload."

The severity assessment influences how drift is presented: high-severity drift appears first with prominent recommendations; low-severity drift appears later with lighter-touch suggestions. Related drifts are grouped by section rather than listed individually — if five files under `src/viewer/` all drifted from `#spec-viewer`, the user sees one grouped item, not five.

**Selective scanning.** Before performing a deep comparison for any section, the State Owner applies two skip filters that eliminate redundant work:

1. **Freshness skip.** If a section's most recent changelog entry is newer than the most recent git commit touching any file in that section's code neighborhood, the section is definitively ready-to-build — no code has changed since the spec was last written for it. The State Owner writes `ready-to-build` to the readiness map and moves on without reading the section content or scanning code. This eliminates the most common waste: reviewing sections the Spec Writer just authored minutes ago.

2. **Semantic stability skip.** For sections that have been lightly edited since their last review (a sentence reworded, a bullet reordered), the State Owner compares the section's current embedding against its stored embedding from the last review. If the cosine similarity exceeds the stability threshold, the section's meaning hasn't meaningfully changed — the previous readiness assessment still holds. The State Owner carries forward the stored readiness and skips the deep comparison.

Sections that pass neither filter get a full deep comparison as before. The status line shows scan progress during the assessment (e.g., `scanning 8/32 sections`), so the user can see the optimization at work — but the review output itself reports only findings, not what was skipped. Silence means the section was either skipped (unchanged) or scanned and found aligned.

**Step 2: Gap analysis.** The Spec Writer produces a report organized by what the user should **do**, not by what went wrong. Two action-oriented headings:

- **Decisions Needed** — items where code and spec disagree and the user must choose which is correct. This includes both "code ahead" situations (code implements behavior the spec doesn't describe) and "diverged" situations (code and spec describe different behavior). Each item shows what the spec says vs what the code does, plus inline action choices.
- **Ready to Build** — items where the spec describes features the code hasn't implemented yet. These don't need individual decisions — they all need the same action (build). Presented as a collapsed count with section alias list, not individual numbered entries.

```
## Gap Analysis — {Project Name}

### Decisions Needed

(1) `#core-flow` (2.2) — Code and spec disagree
    Spec says: "Items sorted by relevance"
    Code does: "Items sorted by date"
    → Update spec  /  Rebuild code  /  Discuss

(2) `#rules` (3.3) — Undocumented behavior
    Code implements tool validation logic not described in spec.
    → Run /fctry:evolve rules to document

### Ready to Build

4 sections ready to build: #ref-flow, #async-inbox, #offline, #export.
Run /fctry:execute to build.

Approve all? Or select by number to discuss individual items.
```

The vocabulary matches the viewer's readiness pills — "ready-to-build" and "undocumented" appear in both places, so the user never needs to mentally translate between surfaces.

The review also checks whether the spec's status field reflects reality. If the spec says `draft` but scenarios and a complete spec exist, the system recommends transitioning to `active`. If the spec says `active` but full scenario satisfaction has been achieved with no drift detected, the system recommends transitioning to `stable`. If the spec says `stable` but drift has been detected or scenarios are no longer fully satisfied, the system recommends transitioning to `active`. These corrections appear as numbered recommendations alongside the other gap analysis items.

The user sees exactly where the spec and reality diverge and what to do about it. The review → evolve → execute progression forms a natural loop: observe what drifted, update the spec to match intent, then build from the updated spec. The gap analysis positions the user clearly in this loop — every heading tells them the action, not the diagnosis.

**Step 3: Project instructions audit.** CLAUDE.md is created at init with evergreen content and enriched at execute with build-specific content. The Spec Writer audits both layers against the current spec and codebase. For the evergreen layer (created at init), it checks: spec and scenario file paths, the factory contract, the command quick-reference table, the `.fctry/` directory guide, workflow guidance, and the scenario explanation. For the build layer (added at execute), it checks: the current build plan, convergence order, versioning rules, repo structure, and architecture notes. If no build layer exists yet (execute hasn't been run), the audit covers only the evergreen layer. The user sees:

```
Project Instructions Drift (CLAUDE.md):

(1) Spec path — CLAUDE.md says "project-spec.md" but spec is at ".fctry/spec.md"
    Recommendation: Update path in CLAUDE.md

(2) Convergence order — CLAUDE.md lists Phase 2 viewer as pending, but viewer is shipped
    Recommendation: Update convergence order to match spec section 6.2

(3) Repo structure — CLAUDE.md describes src/api/ directory that no longer exists
    Recommendation: Update structure section to reflect current codebase

```

If no CLAUDE.md issues are found, skip this section entirely — silence means alignment. CLAUDE.md updates are presented as numbered recommendations alongside the spec drift items. The user approves or rejects each one. Approved changes are applied directly to CLAUDE.md.

### 2.7 Executing the Build {#execute-flow}

The user has a spec and wants to build from it. They type `/fctry:execute`. The spec's status remains `active` throughout the build — there is no `building` status value. The build's in-progress state is tracked separately in the build run (see `.fctry/state.json`), which is transient and cleared when the build completes or a new plan starts.

**Step 1: State assessment and scenario evaluation (10-30 seconds).** The State Owner scans the codebase and evaluates scenario satisfaction. For each scenario in the scenarios file, it determines: fully satisfied, partially satisfied, or not satisfied. It produces a briefing showing the current state and satisfaction score (e.g., "5 of 8 scenarios fully satisfied, 2 partially, 1 not satisfied"). The briefing includes an approximate codebase size in context-relevant terms (estimated token count or a small/medium/large classification) so the Executor can calibrate chunk granularity — small projects get fewer, larger chunks while large projects get more granular decomposition.

**Step 1.5: Execution priority check.** The Executor checks for execution priorities — first in `.fctry/config.json` (per-project), then in `~/.fctry/config.json` (global). If neither exists, it asks the user to rank three priorities:

```
Before I propose a plan, how should I prioritize the execution strategy?

Rank these in order of importance:

- Speed — run chunks concurrently, minimize wall-clock time (uses more tokens)
- Token efficiency — run chunks sequentially, reuse context (slower but cheaper)
- Reliability — conservative steps, avoid conflicts between concurrent work (safest)

(1) Speed > Reliability > Token Efficiency (fast builds, aggressive retries)
(2) Token Efficiency > Reliability > Speed (lean builds, conservative retries)
(3) Reliability > Speed > Token Efficiency (safe builds, thorough verification)
(4) Custom ranking
```

The user picks a ranking. The Executor stores it in `~/.fctry/config.json` (global default) and uses it immediately. On subsequent runs, the stored priorities are used without re-asking. The user can change priorities at any time by telling the Executor to update them.

**Step 1.75: Version target discovery (first execute only, 5-10 seconds).** On the first `/fctry:execute` for a project, the Executor scans the codebase for version-bearing files — `package.json`, `setup.py`, `Cargo.toml`, README badges, manifest files, and any file containing the current external version string. It proposes additions to the version registry's propagation targets:

```
Found version references — adding to version registry:
- package.json → version field
- README.md → badge URL (contains 0.1.0)

(1) Add all (recommended)
(2) Select which to add
(3) Skip — I'll configure later
```

The user approves, and the registry now knows everywhere the external version appears. On subsequent execute runs, the Executor checks for new files containing the version string and suggests additions if found.

**Step 1.9: Precomputed section dependency graph.** The spec index precomputes cross-reference relationships and scenario overlap between sections at index time, producing a dependency graph that the Executor consumes directly rather than re-deriving from the spec text. The graph identifies which sections reference each other (via alias cross-references in spec text), which sections share scenarios (from scenario-to-section mappings), and which sections form natural clusters (groups with high internal cross-reference density and low external coupling). The Executor uses this graph to determine chunk boundaries (sections in the same cluster tend to belong in the same chunk), identify dependency edges between chunks (cross-cluster references become chunk dependencies), and detect sections that are highly connected (likely to cause cascading changes if modified). The graph is cached in the spec-index SQLite database and rebuilt only when section content changes. For the first build of a project, the graph is computed as part of the State Owner's initial scan.

**Step 2: Build plan proposal (15-60 seconds).** The Executor reads the briefing, the spec, and the precomputed dependency graph, identifies the gaps, and proposes a build plan. The Executor filters to sections marked as `ready-to-execute` or `ready-to-build` in the readiness index — sections flagged as `undocumented` or `draft` are excluded from the plan and surfaced as "not ready to build yet" with a recommendation to run `/fctry:evolve` first. The plan is chunked into discrete work units, each focused on satisfying one or more scenarios. Before proposing chunks, the Executor characterizes the overall plan as one of five **phase types** — Capability (adding net-new user-facing ability), Hardening (improving reliability and scenario satisfaction), Refactor (restructuring for clarity and maintainability), Integration (making components work together end-to-end), or Polish (improving UX coherence and ergonomics) — and states this characterization at the top of the plan with a one-sentence explanation. This framing tells the user what kind of work they're approving before they read the chunk list. The plan shows the execution strategy — shaped by the user's execution priorities — including the execution order, how dependencies between chunks are handled, and how the priorities influenced these choices. The Executor also enriches the project's CLAUDE.md (which was created at init with evergreen factory context) with build-specific content: the approved build plan, architecture notes derived from implementation decisions, convergence order, and versioning rules. This enrichment happens once at the start of each execute run, adding a build layer on top of the existing evergreen layer. The user sees:

```
Build plan:

Phase type: Capability — this plan adds three net-new user-facing abilities that
don't exist yet. None of these chunks modify existing behavior.

Chunk 1: Implement urgency-based sorting (satisfies scenario "Sorting by Urgency Happy Path")
  - Affects: Section 2.2 (core-flow), Section 3.3 (rules)
  - Estimated time: 5-10 minutes

Chunk 2: Add bulk import flow (satisfies scenarios "Bulk Import Happy Path", "Bulk Import with Errors")
  - Affects: Section 2.5 (ref-flow)
  - Estimated time: 10-20 minutes

Chunk 3: Build spec viewer UI (satisfies scenario "User views spec in browser")
  - Affects: Section 2.9 (spec-viewer)
  - Depends on: Chunk 1 (shared utility code)
  - Estimated time: 20-40 minutes

Execution strategy (based on your priorities: speed > reliability > token efficiency):
- Order: Chunks 1 and 2 first (no dependency between them), then Chunk 3 (depends on Chunk 1).
- Failure approach: Aggressive retries — if a chunk fails, try a different approach immediately.
- Each chunk gets a commit referencing satisfied scenarios.

Approve this plan? (yes / revise / cancel)
```

**Plan scope framing.** When the plan includes more work than can fit in a single session, or when the user's energy level is uncertain, the Executor offers three scope variants — minimal (the smallest coherent subset that delivers visible progress), balanced (the recommended plan), and maximal (everything that could be done including stretch goals). Each variant shows which scenarios it would satisfy and the estimated effort. The user picks the scope that matches their situation. This prevents the all-or-nothing dynamic where the user either approves a large plan they can't finish or cancels entirely.

The user can approve the plan as-is, ask for revisions, or cancel. This is the only approval gate. Once approved, the system executes the entire plan autonomously.

**Step 3: Autonomous execution.** After approval, the Executor builds all chunks in dependency order. The user does not approve individual chunks. The system handles code failures, test failures, and rearchitecting decisions silently. If a chunk fails, the Executor retries with an adjusted approach. If the retry fails, it tries a different approach. When a failure leads to a successful rearchitect or a retry succeeds with a different approach, the Executor records a build lesson as a side effect (see `#capabilities` 3.1). The user is never interrupted for technical problems. The Executor emits typed lifecycle events as work progresses — chunk started, chunk completed, chunk failed, chunk retrying, section started, section completed, scenario evaluated — which feed the activity feed in mission control (see section 2.9). After each chunk completes, the Observer agent automatically verifies the output: checking that expected files exist, the viewer renders correctly if applicable, and the build artifacts match expectations. When chunks produce structured outputs (generated configs, derived data, formatted content), the Observer runs a fact-sheet verification pass that cross-checks claims in the output against the source material — catching hallucinated config values, misquoted spec text, or inconsistent data before the chunk is committed. For UI-affecting chunks, the Observer uses structural diffing (comparing before/after DOM structure rather than pixel screenshots) to verify that changes landed correctly — a cheaper and more reliable signal than visual comparison for most verification tasks. The Observer emits its own verification events to the activity feed (e.g., "chunk 3 verified: DAG renders correctly, section colors match lifecycle state"). The build loop is: execute chunk, emit lifecycle event, Observer verifies, emit verification event, next chunk. When system-level tools are available, the Observer can also detect and handle blocking system dialogs (permission prompts, save panels, install confirmations) that would otherwise stall autonomous execution.

The execution priorities shape failure behavior and context flow. Speed-first priorities favor best-effort execution: if a chunk fails after exhausting retries, the Executor moves on and reports the gap in the experience report. Reliability-first priorities favor fail-fast execution: a persistent failure in a foundational chunk stops the build early rather than building on shaky ground. Token-efficiency-first priorities favor conservative retries with minimal context overhead. These behaviors emerge from the priorities — the user never configures "failure policies" directly.

The Executor manages context flow between dependent chunks autonomously. When chunk 3 depends on chunk 1, the Executor decides how much context from chunk 1's work carries forward — full transcript, a structured summary, or a fresh start with only the artifacts. This decision is guided by execution priorities: token-efficiency-first favors minimal context carryover, reliability-first favors rich context to avoid rework, speed-first favors summarized context that's fast to process. The user doesn't see or configure this — it's an autonomous decision that affects build quality and cost behind the scenes.

**Context-aware execution with budget gating.** The Executor treats the context window as a finite resource, ensuring that context pressure never degrades build quality. Each chunk operates with sufficient context to do its work well, regardless of how many chunks preceded it. The system structures work to create natural context boundaries — checkpoint state persists through files (`.fctry/state.json`, git commits, CLAUDE.md) rather than conversation history, so the build remains sharp across any number of chunks. When the Executor detects that a build requires unusual context management — a chunk too large for one context window, or a dependency chain that would accumulate excessive state — it calls this out in the build plan. Otherwise, context management is invisible: it's just how the system works. The compact instructions in CLAUDE.md guide what's preserved if auto-compaction occurs mid-build, and the build checkpoint ensures that even a full context clear results in a resumable build, not a lost one. **Context budget gate:** when context usage exceeds ~75%, the Executor completes the current chunk cleanly rather than starting a new one — writing a full checkpoint (including reasoning context dump) and signaling that the build should resume in a fresh session. This prevents compaction-degraded builds where later chunks execute with progressively less context fidelity. The 75% threshold leaves room for the current chunk to complete its work, Observer verification, and the commit cycle without triggering compaction. The user sees this as "build paused at a clean boundary" in the experience report, with a recommendation to run `/fctry:execute` to resume.

**Background-worker execution (future direction).** Today, builds execute within a single Claude Code session's context window — the Executor manages context pressure through chunking, checkpointing, and fidelity modes. An alternative architecture spawns each chunk as an independent background worker with a fresh context window, inverting the problem from "manage scarcity" to "create abundance." Each worker reasons about its chunk with full context instead of competing for space in a shared window. The orchestrating session stays thin — planning, monitoring, and relaying experience questions — while the cognitive load of execution distributes across workers. This pattern (proven by Dispatch, a Claude Code skill for background worker orchestration) is a future evolution path for the Executor, not a current requirement. The tradeoffs are real: independent workers lack shared state between chunks (fctry's context-carrying chunks need richer coordination than isolated workers provide), and multi-worker builds require filesystem-based IPC for experience questions (vs. the current in-session flow). The Executor may evolve toward this model as tooling matures.

**Self-guiding tool responses.** When the spec index or Observer returns query results during a build, the response includes next-step hints — brief suggestions for what the agent should do with the results. For example, a spec-index query returning a section with three unresolved cross-references appends "3 unresolved cross-refs — consider loading sections X, Y, Z before proceeding." An Observer verdict appends "verification passed — chunk ready to commit" or "verification failed on viewer rendering — re-check CSS changes before retrying." These hints are advisory, not mandatory — agents can ignore them — but they reduce the reasoning steps agents need to determine what to do next, improving both speed and accuracy in multi-step workflows. The hints are generated from the tool's own structural knowledge (the index knows about cross-references; the Observer knows about verification patterns) rather than from the agent's conversation context.

The Executor also acts as a build coordinator, monitoring overall build health rather than just executing chunks in order. It watches for stuck chunks (no progress for an extended period), detects when a chunk's repeated failures suggest a deeper issue (spec ambiguity rather than a code bug), and rebalances work when the dependency graph allows — for example, pulling forward an independent chunk while a stuck chunk is reconsidered. The user sees the effect as better build outcomes and smarter recovery, not as an explicit coordination layer.

**Anti-rationalization Stop hook.** During autonomous execution, a prompt-based Stop hook evaluates the Executor's responses for premature completion signals — patterns like "this is good enough," "the rest is out of scope," "this can be addressed in a follow-up," or declaring a chunk complete when the plan's acceptance criteria aren't met. When detected, the hook forces continuation rather than allowing the Executor to stop. This structural enforcement layer complements the instruction-level anti-rationalization design in agent files: instructions counter rationalization through persuasion (authority framing, scarcity framing), while the Stop hook fires at the decision point and is harder to override through context pressure. The hook is active only during the autonomous build phase (Step 3) — not during plan proposal or user interaction.

The system resurfaces to the user only for **experience-level questions** — when the spec is ambiguous or contradictory in a way that affects what the user sees or does. For example: "The spec says the list is sorted by urgency, but doesn't describe how urgency is determined for items without a due date. Should those items appear at the top (most urgent) or bottom (least urgent)?" The user answers, and execution resumes.

During execution, the spec viewer's mission control shows real-time progress (see section 2.9) and the project dashboard reflects the build in progress with a live progress indicator. In the terminal, the status line shows chunk progress. The user can watch the build happen without being asked to make decisions about it.

**Convergence milestones.** When the build plan spans multiple convergence phases (e.g., core command loop, then viewer, then mission control), the Executor presents milestone reports at phase boundaries — non-blocking snapshots of what the user can now try before the next layer builds on top. For example, after the core command loop chunks complete: "Core commands are working. You should now be able to run /fctry:init and complete an interview. The viewer and mission control are building next." The user can try the system at this point, but the build continues unless they explicitly stop it. Milestones give the user natural validation points without imposing approval gates. If a milestone reveals a problem ("the interview flow doesn't feel right"), the user can stop the build and evolve the spec before the next phase builds on a flawed foundation.

**Build checkpointing.** As each chunk completes, the Executor persists the build state — which chunks are done, their outcomes, the current dependency graph position, and the approved plan reference. When a build is interrupted mid-chunk (session crash, context exhaustion, user closes laptop), the checkpoint preserves both structural state and a reasoning context dump — the key decisions made so far, the approach rationale, and any unresolved considerations from the interrupted chunk. This means resumption starts with richer context than the structural checkpoint alone: the new session knows not just what was done, but why and what was being attempted. The checkpoint survives session death. When the user returns and runs `/fctry:execute` again, the system detects the incomplete build:

```
Found incomplete build (3/7 chunks done, started 2 hours ago).

Completed:
- Chunk 1: Urgency sorting ✓
- Chunk 2: Bulk import ✓
- Chunk 3: Spec viewer layout ✓

Remaining:
- Chunk 4: WebSocket updates (depends on Chunk 3 ✓)
- Chunk 5: Change history
- Chunk 6: Mission control
- Chunk 7: Async inbox (depends on Chunk 6)

(1) Resume from Chunk 4 (recommended)
(2) Start fresh with a new plan
(3) Cancel
```

The user picks by number. Resuming skips completed chunks entirely — no re-execution, no re-evaluation. The Executor picks up at the next unfinished chunk in dependency order. If the spec changed between sessions (the user ran `/fctry:evolve` on a completed section), the Executor detects the change and flags it: "Chunk 2 (bulk import) completed, but section 2.5 changed since then. (1) Rebuild Chunk 2 with new spec, (2) Keep old result, continue from Chunk 4." The checkpoint is stored in `.fctry/state.json` as a `buildRun` object alongside the existing workflow state.

**Step 4: Experience report.** When the build completes (all plan chunks finished and scenarios evaluated), the Executor presents the results as an experience report — not a satisfaction scorecard. Instead of "34 of 42 satisfied," the user sees what they can now do:

```
Build complete.

Here's what you should now be able to do:

- Open the app and see your items sorted by urgency, with overdue ones highlighted in red.
  The most urgent items appear first.

- Drag a CSV file onto the import area. You'll see a progress bar, then a preview of
  what will be imported. Click "Import" to confirm or "Cancel" to discard.

- Open /fctry:view and see the spec rendered in your browser with the sidebar
  showing all sections. Changes from this build are highlighted in the change history.

Go try these out. If something doesn't match your vision, run /fctry:evolve
to describe what you'd like to change.
```

The experience report maps completed work back to concrete things the user can see, touch, and try — not to scenario IDs or satisfaction percentages. This is what the user cares about. When significant retries occurred during the build, the report optionally surfaces them in experience language — e.g., "The sorting implementation took three approaches before finding one that satisfied the scenario" — adding transparency without technical detail. The user gets a sense of how hard the system worked, not what code it wrote.

**Chunk context model.** Each chunk in the build plan is either **isolated** (clean context, no dependency on prior chunk outputs) or **context-carrying** (requires injected results from completed predecessor chunks). The Executor labels each chunk type in the plan so the user can see which chunks run independently and which wait for injected context. Isolated chunks are like contractors working from the spec alone; context-carrying chunks are like team members who need to see what the previous person built before they can continue. The label also informs context management: isolated chunks can use fresh context windows, while context-carrying chunks need prior results injected.

**Experience questions as a named build state.** When the Executor encounters a spec ambiguity that affects what the user sees or does, the build enters a **paused** state — not just an inline resurfacing event, but a named state visible in mission control. The state records the question, which chunks are blocked on the answer, and when the question was surfaced. The viewer displays the question prominently (a pulsing indicator in mission control, the quoted question text, and a list of blocked chunks). The build remains paused until the user answers in Claude Code, at which point the Executor records the answer, clears the paused state, and resumes dependent chunks.

**Version tagging via registry.** The Executor reads the version registry from `.fctry/config.json` to manage all versioning during the build. Each successful chunk gets a commit with a message referencing satisfied scenarios. The external version's patch auto-increments per the registry's rules, and the Executor updates all declared propagation targets (e.g., `package.json`, spec frontmatter, README badges) atomically with each version change. When the full plan completes, the Executor generates a **release summary** and presents it alongside the version decision:

```
Release Summary:
  Headline: Items now sort by urgency, with overdue ones highlighted and bulk import live
  Highlights:
    - You can now drag a CSV file onto the import area and preview what will be imported
    - Items appear sorted by urgency; overdue items are highlighted in red
    - The spec viewer shows change history with diffs for this build
  Deltas:
    - #core-flow (2.2): Urgency-based sorting with overdue highlighting
    - #ref-flow (2.5): Bulk import flow with preview-before-confirm
    - #spec-viewer (2.9): Change history timeline with diff view
  Migration: None

Version: Current is 0.1.5 (from version registry). This completes the full plan — recommend minor version bump.

Suggested version: 0.2.0
Choose:
1. Tag as 0.2.0 now (updates all 3 propagation targets)
2. Skip tagging
3. Suggest different version
```

The release summary appears every time the Executor suggests a minor or major version bump — the user sees what changed in experience terms before deciding how to version it. The release summary also feeds the changelog entry for tagged versions so the version history reads as a narrative of experience shifts, not just a list of commits. At significant experience milestones, the Executor may suggest a major version bump with rationale (e.g., "All critical scenarios satisfied — first production-ready version"). The user approves or declines by number. All version changes — patch, minor, major — propagate to every declared target automatically.

### 2.8 Navigating by Section {#navigate-sections}

Every section of the spec has two identifiers:
- A number (e.g., `2.2`, `3.3.1`)
- A stable alias (e.g., `#core-flow`, `#rules`)

Both appear in the table of contents. Both work in commands:
- `/fctry:evolve core-flow` and `/fctry:evolve 2.2` do the same thing
- `/fctry:ref 2.5 https://example.com` and `/fctry:ref ref-flow https://example.com` do the same thing

Aliases are human-readable slugs derived from section titles. Numbers follow standard outline numbering. Both are stable across spec updates — if a section is renamed, its number stays the same and its alias is updated in a way that preserves recognizability (e.g., `#core-flow` might become `#core-list-flow` if the section title changes, but never `#section-2-2`).

The user never has to remember whether something is "section 2.2" or "the core flow" — either works.

### 2.9 Live Spec Viewer {#spec-viewer}

The spec viewer is a single multi-project-aware server that serves all fctry projects from one URL. Rather than running a separate server per project, a single instance maintains a global project registry and lets the user switch between projects from a sidebar.

**Server lifecycle.** The viewer auto-starts silently whenever the user works with a project that has a spec. On every prompt, a plugin hook checks for `.fctry/spec.md` and ensures the viewer server is running — starting it if needed, or registering the current project with an already-running server. The server launches on a free port (starting at 3850), writes its PID and port to `~/.fctry/viewer.pid` and `~/.fctry/viewer.port.json` (global, not per-project), and runs quietly — no browser tab opens, no output interrupts the user's work. If no spec exists, the hook is a no-op. If the viewer is already running but was started from a different plugin root (e.g., an older plugin cache directory after a version update), the hook kills the stale viewer and restarts it from the current plugin root — so the viewer always runs the same code version as the rest of the plugin. All path comparisons (plugin root, project directories) use canonicalized paths — resolving symlinks and filesystem case — so that `/Users/mike/Code/project` and `/Users/mike/code/project` are recognized as the same directory on case-insensitive filesystems. Without this, the hook can mistakenly kill and restart the viewer or register duplicate projects.

The server persists across Claude Code sessions. Since it serves all projects, stopping it when one session ends would disrupt monitoring of other projects. The server self-heals: if it crashes or is killed, the next `UserPromptSubmit` hook detects the missing process and restarts it automatically. The user can stop it explicitly with `/fctry:stop`.

**Singleton enforcement.** Exactly one viewer process runs at a time. Before starting, the server checks for an existing instance — first by reading the port file, then by health-checking ports in the default range via HTTP. If a healthy viewer responds, the new process registers its project with the existing server and exits immediately. No second process is spawned. Cleanup is PID-aware: when a process exits, it only removes PID and port files that belong to its own process ID, so one process exiting never orphans another. The global project registry (`~/.fctry/projects.json`) is loaded into memory before the first project is registered, so registration (which triggers a save) never clobbers entries from prior sessions.

**Project registration.** When `/fctry:init` creates a new spec, the system automatically registers the project in `~/.fctry/projects.json` — a global registry of all fctry projects. Each entry records the canonicalized project path, name (from spec frontmatter), and the timestamp of last activity. The hook also registers the current project on every prompt, so projects that existed before multi-project support are picked up automatically the first time the user works in them. Path canonicalization ensures that the same project is never registered twice under different path casings. Projects can be removed from the registry manually or via `/fctry:stop <project>`.

The user types `/fctry:view` to open the viewer in their browser, navigated to the current project. If the viewer is already running (which it usually is, thanks to auto-start), the command opens the browser to the existing URL with the current project selected. If it's not running, it starts the server and opens the browser.

**Kanban as primary interface.** The viewer's landing page is a kanban board — not a static dashboard. A quick-add input sits above the board — always visible on landing without scrolling, so the user can drop an idea immediately. Below it, projects appear as cards in priority columns: **Inbox** (new, unprocessed), **Now** (active focus), **Next** (coming up), **Later** (can wait), and **Satisfied** (all scenarios passing, auto-populated). The user drags project cards between columns to prioritize, and drags within columns to order. Each card displays the project name, spec status badge (draft/active/stable), a readiness bar, readiness pills (per-category breakdown), inbox queue depth, build progress (if running), untracked change count, and a distinct accent color derived from the project name or set in `.fctry/config.json`. Clicking a project card's header drills into that project's section-level kanban; clicking the card body opens a detail panel (see below). Inbox cards maintain uniform compact height regardless of content length — long URLs and multi-paragraph text are truncated with line clamping so all cards in a column share consistent visual density. Kanban columns grow to their natural height and the page scrolls freely — columns are not confined to a fixed viewport region with internal scroll. This keeps the full board visible as a single scrollable surface rather than creating nested scroll containers.

**Recursive kanban drill-down.** The kanban pattern repeats at every level of the spec hierarchy — same columns, same drag interaction, same visual language:

- **Level 1: Projects** — all registered fctry projects as cards in priority columns. The user sees their portfolio and decides which project to work on.
- **Level 2: Sections or Scenarios** — inside a project, cards represent either spec sections (`#core-flow`, `#spec-viewer`) or user scenarios ("I create a spec from scratch," "I watch a build happen"). A toggle switches between groupings; priority assignments are independent per grouping. Section cards show readiness color and claim progress (e.g., "12/15" for Now sections with claim-level assessment). Scenario cards show which sections they touch.
- **Level 3: Claims / sub-features** — inside a section, each distinct behavior described in the spec is a card. "WebSocket reconnect," "keyboard shortcuts," "readiness filtering with scroll preservation" — each independently prioritizable. This level is opt-in; the user drills in only when they want fine-grained control.

At every level, two interactions coexist on every card: clicking a card's **header** drills down into the next kanban level, while clicking the card's **body** opens a slide-out detail panel from the right edge of the viewport (see below). Navigation uses a breadcrumb trail (e.g., "Projects > MyApp > #spec-viewer") that is always visible. Clicking any breadcrumb segment navigates back to that level. Drill-down feels like zooming in, not navigating away — the same kanban interface at every depth.

**Inbox items as inbox cards.** When the user submits an evolve idea, reference URL, or feature request through the quick-add input (see below), the system processes it in the background and creates a card in the **Inbox** column at the appropriate kanban level. If the idea maps to existing sections, the card appears at the section level. If it's a new capability, the card appears at the project level. Each inbox card shows the idea text (truncated with line clamping to match the compact height of surrounding cards), type badge (evolve/reference/feature), and affected sections. Inbox cards are project-level — they remain visible in the Inbox column regardless of whether the user is viewing Sections or Scenarios grouping. Toggling between views never causes inbox cards to vanish. The user drags inbox cards into Now/Next/Later to prioritize them. When `/fctry:evolve` or `/fctry:ref` runs, inbox cards relevant to the target section are surfaced as conversation context. After incorporation, the card moves to Satisfied.

**Card detail panel.** Clicking any card's body (not its header) opens a slide-out detail panel from the right edge of the viewport. The panel is a reusable pattern that works across all kanban levels and card types — the user accesses rich content without disrupting the board layout. Panel content varies by card type: section cards show the full heading, alias, readiness status, and all claims listed; inbox cards show the full untruncated content text, type, affected sections, and timestamp; scenario cards show the full title, validates list, and status; claim cards show the full claim text. Only one detail panel is open at a time — clicking a different card's body replaces the panel content. Clicking outside the panel or pressing Escape closes it. This pattern provides access to content that would break card density if shown inline — long descriptions, diagrams, full claim lists — while keeping the kanban compact and scannable. **Depth-tiered section content:** within the detail panel, section content renders at three tiers — overview (heading, alias, readiness, one-line summary), detail (full claims list, cross-references, readiness breakdown), and deep-dive (full spec text, diagrams, scenario coverage). The panel opens at the detail tier by default; the user clicks to expand to deep-dive or collapse to overview. This tiering prevents information overload when scanning many sections while preserving access to full content on demand.

**Priority persistence.** Kanban positions are stored in `.fctry/config.json` under a `priority` key — an ordered array per column per level. Sections not listed default to Next. Satisfied is computed from readiness, not stored. The Executor, State Owner, and viewer all read from this configuration.

**Project sidebar.** Within the spec view for a single project, the left side includes a project switcher above the ToC/History tabs — a compact list of all registered projects. Each entry shows the project name and spec status badge. The currently active project is highlighted. Clicking a different project performs a full context switch — the spec content, ToC, history, inbox, and mission control all swap to the selected project's data. The WebSocket reconnects to that project's data stream. The switch is fast (under 1 second) because the server already has all project data loaded. A "back to kanban" link at the top of the switcher returns to the project-level kanban view.

**Three-column layout.** The viewer uses a persistent three-column layout:

- **Left rail** — Tabbed between **ToC** (default), **History**, **Lessons**, and **Memory**. Above the tabs, a row of **readiness stat pills** shows the per-category section counts: each pill displays a readiness label and count (e.g., "aligned 25", "ready-to-build 8", "draft 5"), color-coded to match the TOC readiness indicators. Categories with zero sections are hidden. The pills auto-refresh whenever the spec changes (triggered by WebSocket spec-update events) — counts stay current as the spec evolves, with no manual refresh needed. The ToC tab shows the table of contents with readiness color indicators. The History tab shows the change timeline (see below). The Lessons tab shows per-project build learnings grouped by section. The Memory tab shows the global memory panel (see `#details` (2.11)). When new changelog entries arrive while the user is on another tab, a dot badge appears on the History tab so they know something changed. Switching to that tab clears the badge. The same badge pattern applies to Lessons and Memory tabs.
- **Main content** — The spec rendered as a clean, readable document.
- **Right rail** — The async inbox (see below). Open by default, collapsible to a thin strip or icon. Clicking the collapsed strip expands it back. The inbox is always accessible without navigating away from the spec.

**Readiness filtering.** Each readiness stat pill is a clickable filter. Clicking "ready-to-build (8)" filters the view to show only the 8 ready-to-build sections — non-matching sections collapse in the content area, the TOC highlights only matching entries and dims the rest, and a subtle indicator (e.g., "Showing 8 of 42 sections") confirms the filter is active. The matching sections render fully (headings, text, lists, tables) — it reads like a focused subset of the spec. Clicking the active pill again clears the filter and restores the full view; the user's scroll position within the full spec is preserved on clear. Only one readiness filter can be active at a time. The filter state is purely client-side — it does not affect the server or other viewers.

On screens narrower than 768px, the layout collapses to content-only with a hamburger menu. The left rail (ToC/History/Lessons/Memory tabs, readiness pills) and inbox become slide-in overlays that dismiss on tap-outside.

**Live updates.** As agents work, the spec updates in real-time via WebSocket. The user sees sections change as they're written. No need to refresh.

**Section highlighting.** When an agent is working on a specific section (e.g., Spec Writer updating section 2.2 during an evolve), that section is highlighted in the left rail's ToC and the document scrolls to it. The user can watch the work happen.

**Change history.** The History tab in the left rail (inspired by Log4brains ADR viewer) shows a vertical timeline of recent changes. Each entry shows the timestamp, which sections changed, and a one-line summary (e.g., "Updated core-flow to add urgency sorting"). Clicking an entry expands to show the changelog description of what changed. The change history reads from the changelog file; if no changelog exists yet (e.g., before the first `/fctry:evolve`), the tab shows "No changelog yet."

**Zero-build rendering.** The viewer uses a Docsify-style approach: markdown renders directly in the browser, no build step needed. The server just serves the markdown and a lightweight JS client that handles rendering and WebSocket updates.

**Mission control during builds.** When a `/fctry:execute` build is running, the viewer transforms into a live mission control view. The centerpiece is a visual dependency graph — the approved build plan rendered as an interactive DAG where chunks are nodes and dependency relationships are edges. Each chunk node shows an explicit lifecycle state — planned, active, retrying, completed, or failed — with color and animation reflecting the state so the user always knows where things stand. Nodes light up as chunks start, pulse during active work, and settle into a completed state as they finish. Dependency edges show which chunks are waiting and what they're waiting for. The graph updates in real-time as the build progresses — the user watches their plan come to life as a visual pipeline, not just a text list. When a chunk retries, the user sees the current attempt (e.g., "attempt 2 of 3") rather than invisible retries. Sections in the ToC tab light up as agents work on them and change appearance when they're done. As chunks complete, the spec content itself fills in progressively — sections that were "ready-to-build" (described but unbuilt) transition visually to "aligned" or "satisfied," and the full spec structure is visible from the start with sections updating as the build brings them to life. Concurrent chunks show side-by-side progress. A connection status indicator shows whether the WebSocket connection is live, reconnecting, or disconnected — so the user knows if what they're seeing is current or stale. A context health indicator sits alongside the connection status, showing the current chunk's context state: isolation mode, approximate usage, and last checkpoint timestamp. On hover or click, the indicator expands to show a **context attribution breakdown** — not just "75% used" but a categorized split: how much context is occupied by spec content, code references, tool output, agent state, and conversation history. This breakdown helps the user understand *what* is consuming context, not just how much. The indicator is small and unobtrusive — it doesn't compete with the dependency graph or activity feed for attention. During short builds that fit in one context window, the indicator shows a simple healthy state. During longer builds, it shows context boundaries being managed. The activity feed shows typed events with semantic meaning: agent started section, agent completed section, scenario evaluated, chunk started, chunk retrying, chunk completed, chunk failed, chunk verified, verification failed, tool calls to external services (e.g., "chunk 3 fetching docs from Context7," "Researcher crawling URL via Firecrawl," "Observer verified chunk 3: DAG renders correctly"), context lifecycle transitions (e.g., "checkpointed before chunk 4," "new context for chunk 5," "compacted — build state preserved"), and **compaction boundary events** — when auto-compaction fires during a build, the activity feed shows it as a typed event ("context compacted — build state preserved, continuing from chunk N") so the user understands why there's a brief pause and can verify that build continuity was maintained. Lifecycle events come from the Executor; verification events come from the Observer; context events come from the Executor's resource management. Together they form a complete picture of the build's progress, health, and resource management. This replaces generic "file changed" notifications with events that map to what the user cares about. The user can filter the activity feed by event type — show only chunk lifecycle events, only scenario evaluations, or only external tool calls — to cut through noise during busy parallel builds. **Named event alerts** surface important events above the noise: when a chunk retries more than twice, when a verification fails, or when context compacts, the activity feed pins the event with a visual accent so the user sees it immediately even if they're scrolled away or filtering. Alert rules are built-in (not user-configurable) and tuned to surface events that might change the user's decision to let the build continue vs. intervene. The user watches the build happen in real-time without needing to be in the terminal. If the system resurfaces an experience question for the user (see section 2.7), the viewer shows the question prominently so the user can switch to Claude Code to answer it.

**Structured interchange rendering.** When agents emit structured interchange alongside their conversational output, the viewer renders it as interactive UI rather than raw text. During `/fctry:review`, findings appear as cards with severity indicators, evidence expandable on click, and recommendation links to specific actions. During `/fctry:execute`, the build plan renders as the existing DAG visualization, but individual chunks now carry structured action items and acceptance criteria. During `/fctry:evolve`, the diff summary renders as a structured change list where each changed section is clickable to show the inline diff. Across all commands, actions render as a checklist in the right rail — the user can see at a glance what the system recommends doing next. Each item in the interchange supports an expand affordance: the viewer shows a concise summary by default, with full detail (hydrated evidence, complete rationale, full diff) available on click. This means the viewer can show compressed summaries that are scannable without losing access to the detail underneath. Tool calls within interchange cards get **semantic step rendering** — each tool invocation is classified as one of: file_read, code_edit, command_exec, search, agent_spawn, or external_tool — and rendered with a type-appropriate visual treatment: code edits show inline diffs, file reads show syntax-highlighted excerpts, bash commands show terminal-styled output, and agent spawns show the subagent's purpose and result. This classification comes from the interchange payload, not from parsing raw tool output — the agent categorizes its own tool usage as part of interchange emission.

**Automatic spec diagramming.** Each spec section that has a natural visual representation gets an auto-generated diagram, rendered via Mermaid.js (loaded from CDN, same pattern as marked.js and DOMPurify). Five diagram types are supported:

- **Entity relationship diagrams** — auto-generated from `#entities` (3.2) by parsing bold entity names and relationship verbs in the text. Shows how tracked objects connect (spec document → scenarios, build plan → build run → chunks, etc.).
- **User flow diagrams** — auto-generated from section 2 experience narratives (`#core-flow`, `#evolve-flow`, `#ref-flow`, `#review-flow`, `#execute-flow`). Each section's step-by-step narrative maps to a flowchart with decision points, branches, and outcomes.
- **Agent pipeline diagrams** — auto-generated from the command-agent table in SKILL.md. Shows which agents run for each command, their ordering, and parallel execution markers.
- **Convergence phase diagrams** — auto-generated from `#convergence-strategy` (6.2) by parsing phase markers. Shows the system's growth trajectory as a timeline or layered diagram.
- **Section dependency neighborhood diagrams** — auto-generated by parsing cross-references (`{#alias}` anchors, "see section N.N" mentions) between spec sections, supplemented by a **semantic ring** that shows sections with high embedding similarity (cosine similarity above a threshold) even when no explicit cross-reference exists. Each section's diagram shows its immediate neighborhood: outgoing references and incoming references (structural edges), plus semantically similar sections (semantic edges, visually distinct — dashed lines or lighter color). Sections that are structurally distant but semantically related (e.g., `#error-handling` (2.10) and `#rules` (3.3)) appear as neighbors. The semantic ring uses the existing `section_embeddings` table in the spec index — no additional embedding computation needed.

Three diagram types are fully deterministic (agent pipeline, section dependencies, convergence phases — generated by parsing structured data and cross-references). Two require LLM-assisted generation (entity relationships and user flows — generated by the Spec Writer as a side effect of writing or updating the relevant sections). All diagram definitions are cached in the spec-index SQLite database alongside section content hashes, and regenerated only when the source section's content actually changes. **Mermaid CSS class collision guard:** all Mermaid-generated SVGs use namespaced CSS classes (prefixed with `fctry-mermaid-`) to prevent diagram styles from bleeding into the surrounding page — without this, Mermaid's default class names can conflict with the viewer's own styles, causing broken layouts after diagram render.

**Per-section diagram toggle.** Sections with an available diagram show a small diagram icon in the section heading bar. Clicking the icon swaps the section's text content for the rendered Mermaid diagram. Clicking again restores the text. The toggle is instant (diagrams are pre-rendered from cached definitions). The icon is absent for sections without diagrams. Pressing `d` toggles the current section (the one in the scroll viewport). A global "show all as diagrams" toggle switches every diagram-capable section simultaneously — providing a visual overview of the entire spec. **Diagram zoom controls:** complex diagrams (dependency neighborhoods with many nodes, large entity relationship diagrams) include pan/zoom/reset controls — scroll to zoom, drag to pan, a reset button returns to fit-to-container. Small diagrams that fit in the container without scrolling show no controls.

**Diagram theme synchronization.** Mermaid bakes colors into SVG at render time, so diagrams must be re-rendered when the theme changes. The viewer stores diagram source alongside rendered output and re-renders with dark-appropriate `themeVariables` (dark node fills, light text, muted edges) when the user toggles dark mode. A brief fade transition on the diagram container masks the re-render flash.

**Event history on reconnect.** When the user opens the viewer mid-build (or reconnects after a browser tab was closed), they immediately see the full history of what's happened so far — not just future events. The server maintains a buffer of recent build events with sequence numbers. New connections receive the complete event history as a batch, then switch to live streaming. If the client detects a gap in sequence numbers (events missed during disconnection), it requests backfill. The user never joins a build in progress and wonders "what did I miss?"

**Build log export.** After a build completes, mission control offers a downloadable build log — a structured record of every event, chunk lifecycle transition, and scenario evaluation from the build run. The user can save this for reference or share it with collaborators to show what the system did.

**Async inbox.** The right rail accepts three types of input that are processed in the background — even during builds:

- **Evolve ideas** (e.g., "make onboarding faster") — The system identifies affected spec sections and prepares context so the next `/fctry:evolve` conversation in Claude Code starts informed.
- **References** (URLs) — The system fetches and analyzes the URL immediately in experience language, queuing the interpretation for the next `/fctry:ref` or `/fctry:evolve`.
- **New features** (e.g., "add dark mode") — The system scopes the idea against the existing spec, identifies where it would live, and estimates impact on existing sections.

The inbox is a queue, not a conversation. The user drops items in; the system processes them asynchronously. When the user is ready to discuss an item in Claude Code, the analysis is already done. This means the factory never idles — builds, reference analysis, and evolve prep all run concurrently.

**Inbox consumption.** When the user runs `/fctry:evolve` or `/fctry:ref`, the system checks `inbox.json` for pending or processed items relevant to the target section before starting the interview. If relevant items exist, the system surfaces them: "You have 2 queued ideas for this section — incorporate them? (1) Yes, use them as context (2) No, start fresh." When incorporated, the Interviewer uses the queued items and their analysis as conversation context — the user doesn't need to re-describe ideas they already dropped in the inbox. After the evolve or ref completes, consumed inbox items are marked as incorporated and archived from the active queue.

**Quick-add input.** The right rail evolves from a full inbox panel to a slim, always-accessible quick-add input — a compact text field with a type selector (evolve/reference/feature) and a submit button. The user types an idea or pastes a URL and submits. The item is processed in the background and appears as a inbox card in the kanban. The quick-add input is always visible alongside the spec without requiring a panel toggle or navigation. On mobile, it's accessible as a slide-in overlay.

**Read-only spec, input-capable inbox.** The spec itself is read-only in the viewer — all spec changes happen through `/fctry` commands, never through browser editing. The quick-add input is the only input surface, and it feeds into the kanban's Inbox column rather than editing the spec directly.

**Agent-authoritative readiness.** The viewer's readiness display — pills, ToC color indicators, dashboard cards — reads from `state.json`'s `sectionReadiness` map, which the State Owner writes during every scan and the Executor updates after each build chunk. The viewer never independently recomputes readiness from heuristics. If `state.json` has no `sectionReadiness` data (e.g., first load before any command has run), the viewer falls back to a bootstrap heuristic that uses only structural analysis (section number prefix for meta vs. buildable) and basic code-directory detection — no project-specific hints. This ensures that readiness is accurate for any project regardless of language, framework, or code structure. The status line, the viewer, and the Executor all read from the same source, so they always agree.

**Bidirectional observation.** The viewer is not just a human-facing UI — it is also an observable surface for agents. Humans observe through the browser (dashboard and spec view); agents observe through API queries (`/health`, `/api/dashboard`, `/api/build-status`, `/api/build-log`, `/readiness.json`) and browser automation (screenshots, DOM inspection, computed style checks). The Observer agent reads `.fctry/viewer/port.json` to discover the viewer's address, then uses browser automation tools or API calls to verify that the viewer renders correctly, that the activity feed receives events, and that mission control reflects the build state accurately. This means the system can verify its own outputs — the Observer checks that what the user would see matches what the spec describes.

**Dark mode.** The viewer supports dark mode via a comprehensive CSS custom property system based on a 12-step gray scale (Radix Slate Dark) with semantic token mappings. Dark mode activates automatically when the user's system preference is `prefers-color-scheme: dark`, with no flash of light theme on load (an inline script in `<head>` applies the theme before first paint). A manual toggle in the viewer header overrides the system preference; the choice persists in `localStorage`. Every surface uses the token system: kanban cards, spec content, modals, toasts, search overlays, mission control DAG, activity feed, interchange cards, and readiness pills. Accent colors (per-project identity) are desaturated and lightened in dark mode to maintain contrast. Code blocks use a dark syntax highlighting theme (One Dark Pro palette). Shadows are replaced with subtle border differentiation or background lightening for elevation. The dark token set includes ~30 semantic variables mapping to primitive scale steps for backgrounds (app, surface, element, hover, active), borders (subtle, default, strong), text (primary, secondary, muted), and accents (solid, hover, text).

**Visual polish.** Several visual details elevate the viewer from functional to refined:

- **Skeleton loading** — loading states show an animated shimmer gradient rather than italic "Loading..." text. The shimmer respects `prefers-reduced-motion` (falling back to a gentle pulse). Skeleton containers carry `aria-busy="true"` for accessibility.
- **Syntax highlighting** — code blocks in the rendered spec show syntax-highlighted content using a minimal 4-color palette: keyword (purple), string (green), comment (gray), default (off-white in dark mode, dark gray in light mode). This applies to both the spec view and code excerpts in interchange semantic step cards.
- **Toast notifications** — update notifications and system messages use styled toasts with a colored left border indicating severity (success green, error red, warning amber, info blue), a dark surface background, and auto-dismiss with a shrinking progress bar. Toasts slide in from the bottom-right.
- **Fuzzy search with semantic ranking** — the `Cmd+K` search modal uses fuzzy matching (ranking by relevance, not just string containment). When the spec index has active embeddings, search results are additionally ranked by semantic similarity to the query — a search for "reconnect" surfaces `#spec-viewer` even if the word "reconnect" doesn't appear in its heading, because the section's content is semantically related. Results are grouped by section with keyboard navigation (arrow keys, Enter, Escape). The modal has a backdrop blur overlay. In dark mode, the modal uses the dark surface token with subtle borders.
- **Activity feed sizing** — the activity feed in mission control is no longer height-capped at 150px. It flexes with the mission control layout to accommodate builds with many events.

**Cross-project portability.** The viewer works with any project where fctry is installed as a plugin — not just inside the fctry repository itself. It requires Node.js on the host machine. npm dependencies (express, ws, chokidar) are installed automatically the first time the viewer starts, so there's no manual setup step after plugin installation. Because the viewer is a single multi-project server, installing fctry in a new project and running `/fctry:init` automatically makes that project available in the viewer sidebar alongside all other projects.

The viewer runs in the background persistently. The user can close the browser tab and reopen `/fctry:view` anytime to get back to it. The server persists across sessions and self-heals if it crashes (the next `UserPromptSubmit` hook restarts it). The user can stop it manually with `/fctry:stop`.

### 2.10 What Happens When Things Go Wrong {#error-handling}

| What Went Wrong | What the User Sees | What They Can Do |
|----------------|-------------------|-----------------|
| Required tool missing (rg, sg, gh, MCP server) | Clear message: "Missing required tool: ripgrep (rg). Install with: brew install ripgrep" | Install the tool and re-run the command |
| Interview resumption fails (state file corrupted) | "Saved interview state is unreadable. Start fresh?" | Approve to start a new interview |
| Reference URL unreachable | "Could not fetch https://example.com — check the URL or try again later." | Fix the URL or skip the reference |
| Spec-code conflict detected during evolve | "Drift detected: spec says X, code does Y. Which is current? (1) Spec is current, (2) Code is current, (3) Neither — I'll describe what I want" | Choose by number or natural language |
| Execute chunk fails (code doesn't compile, tests fail) | The agent handles this silently — retrying, adjusting approach, or rearchitecting as needed. The user is never interrupted for code failures. If a chunk remains unsatisfied after exhausting approaches, the experience report notes it: "Bulk import is partially working — file upload works but the preview step isn't rendering correctly yet." | Nothing during the build — address gaps after the experience report via `/fctry:evolve` |
| Spec ambiguity discovered during build | The build pauses. Mission control shows a pulsing indicator with the question: "The spec says the list is sorted by urgency, but doesn't describe how urgency is determined for items without a due date. Should those items appear (1) at the top, or (2) at the bottom?" The blocked chunks are listed. | Answer the experience question in Claude Code; the build resumes automatically |
| User references nonexistent section | "/fctry:evolve 9.9 — section 9.9 not found. Did you mean 2.9 (spec-viewer)?" | Use the suggested section or check the table of contents |
| Spec viewer port conflict | "Port 3850 in use. Trying 3851..." (auto-increment until a free port is found) | Nothing — the system handles it |
| Viewer server crashed | The next `UserPromptSubmit` hook detects the missing process and restarts the server automatically. The user sees nothing unless they had the viewer open — in which case the browser shows the connection status as "reconnecting" and recovers when the server comes back | Nothing — self-heals on next prompt |
| User runs execute before init | "No spec found. Run /fctry:init first to create a spec." | Run init |
| Git repository not found during execute | Progress reports show completion and satisfaction without git-specific information (no commits, no version tags) | Nothing — build proceeds normally |
| Agent attempts to skip workflow step | "Workflow error: State Owner must run before Interviewer can proceed. (1) Run State Owner scan now (recommended), (2) Skip (not recommended), (3) Abort" | Choose by number |
| Mermaid diagram fails to render | The diagram toggle shows the section as text with a subtle "diagram unavailable" indicator. No error dialog or blocking state. | Nothing — the section remains readable as text. The diagram will regenerate on the next spec write. |
| Dark mode flash on load | An inline `<script>` in `<head>` reads `localStorage` and applies `data-theme` before first paint. If both localStorage and system preference are absent, the viewer defaults to light mode. | Nothing — the flash prevention is automatic. |
| File write touches spec-covered code | "This file is covered by `#status-line` (2.12). Want to update the spec first? (1) Run /fctry:evolve status-line, (2) Continue — I'll reconcile later" | Choose by number; choosing (2) increments the untracked changes counter |
| Execute targets section with `undocumented` readiness | "Section 2.3 (multi-session) has undocumented code behavior — code exists but the spec doesn't describe it. Run /fctry:evolve 2.3 first." | Run evolve for that section |
| Incomplete build found on execute | "Found incomplete build (3/7 chunks done, started 2 hours ago). (1) Resume from Chunk 4, (2) Start fresh, (3) Cancel." If a chunk was interrupted mid-execution, the checkpoint includes a reasoning context dump so the resumed chunk starts with the prior attempt's decisions and rationale, not just structural state. | Choose by number |
| Spec changed for completed chunk during resume | "Chunk 2 (bulk import) completed, but section 2.5 changed since then. (1) Rebuild Chunk 2, (2) Keep old result, continue" | Choose by number |
| Migration fails (permissions, disk full, file in use) | "Migration to .fctry/ failed: [reason]. Your original files are unchanged. Fix the issue and re-run, or move files manually." | Fix the underlying issue (permissions, disk space) and re-run the command |

Errors are conversational, specific, and actionable. The system never shows stack traces or internal agent errors to the user.

### 2.11 The Details That Matter {#details}

**Interview pacing.** The Interviewer asks one question at a time. It waits for the user's full answer before asking the next question. It never bombards the user with multiple questions at once.

**Numbered questions and choices.** When any agent presents multiple options to the user (interview questions, priority rankings, version decisions, error recovery), all options are numbered in the format "(1) First option, (2) Second option, (3) Third option." The user can respond with just the number (e.g., "1") or with natural language (e.g., "the first one" or "let's do the grouped work"). The system understands both formats.

**Viewer keyboard shortcuts.** The viewer supports keyboard shortcuts for efficient navigation: `?` opens the shortcuts help overlay, `Cmd+K` opens fuzzy search, `1`/`2`/`3`/`4` switch between ToC, History, Lessons, and Memory tabs, `]` toggles the right rail, `a` toggles change annotations, `d` toggles the current section between text and diagram view, and arrow keys navigate sections. When a readiness filter is active, `d` toggles diagrams only for visible sections.

**Spec readability.** The generated spec reads like a human wrote it. Sentences flow naturally. There are no template placeholders like "{insert details here}" or "{TODO}". If a section can't be filled in from the interview, the Spec Writer either asks a clarifying question or leaves the section appropriately scoped (e.g., "The details of X are left to the coding agent" in section 6.4).

**Change summaries.** After every spec update, the user sees a summary of what changed, what was added, and what stayed the same. The summary is concise (5-10 lines max) and uses section aliases, not just numbers.

**Progress feedback during execution.** During autonomous builds, the terminal status line shows chunk progress (see section 2.12). The spec viewer's mission control provides richer real-time visibility: the active chunk, completed sections, and dependency status (see section 2.9). The user does not receive per-chunk completion messages or approval prompts — progress is ambient, not interruptive.

**Post-build experience report.** When the build completes, the Executor presents an experience report that maps completed work to concrete things the user can now do. The report uses plain language and describes the experience, not the code: "You should now be able to open the app and see your items sorted by urgency" — not "Implemented sortByUrgency function in list-utils.ts." If some scenarios remain unsatisfied, the report describes what's working and what isn't in experience terms, with recommendations for next steps (usually `/fctry:evolve` to clarify the spec).

**Commit and version format.** Each chunk commit message follows the format: "Implement [feature description] (satisfies scenario '[scenario name]')". All version numbers come from the version registry — never hardcoded or computed ad-hoc. Patch versions are auto-tagged with each successful chunk (0.1.1, 0.1.2, etc.) and propagated to all declared targets. Minor and major version tags include the version number and, for major versions, a rationale (e.g., "1.0.0 — First production-ready version: all critical scenarios satisfied"). When a version changes, every propagation target in the registry is updated atomically alongside the git tag. Git operations (branching, merging, commit strategy) happen autonomously during the build — the user gets a clean history without making technical decisions about it.

**Release summary format.** When the Executor suggests a minor or major version bump at plan completion, it generates a release summary with four parts:

- **Headline**: One sentence describing the experience shift (e.g., "Items now sort by urgency with overdue highlighting and bulk import is live"). Written in experience language — what the user can now do, not what code changed.
- **Highlights**: A bullet list of user-visible outcomes — concrete things the user can try right now, each described as an action ("You can now drag a CSV file onto the import area and preview what will be imported").
- **Deltas**: The affected spec sections listed by alias and number, each with a one-line description of what changed (e.g., "#core-flow (2.2): Urgency-based sorting with overdue highlighting"). This shows which parts of the spec moved forward.
- **Migration**: If the build changed behavior that affects existing data or workflows, migration steps are listed here. If nothing breaks backward compatibility, this field shows "None."

The release summary feeds the changelog entry for the tagged version, so the version history tells a story of experience shifts rather than just listing commits. Minor version release notes tell the story of the convergence phase they complete ("the viewer era"); major version release notes describe the full experience arc the system has achieved.

**Structured interchange principles.** The structured interchange that agents emit follows three principles: (1) **Typed sections** — findings, actions, and release summaries use consistent schemas across all commands, so the viewer can render them with a single set of UI components regardless of which command produced them. (2) **Cross-referenced IDs** — every finding, action, and proposal has a stable ID (e.g., `FND-001`, `ACT-003`) and items reference each other, so the viewer can draw connections (this finding motivates that action, this action resolves that finding). (3) **Expandable by default** — the interchange includes both a summary (always visible) and detail (visible on expand), following the same pattern as the output depth tiering: the terminal shows the summary, the viewer shows the summary with expand affordances for detail. The expand pattern means agents can include rich evidence and rationale without inflating the terminal output — the detail exists in the interchange, available in the viewer, invisible in the CLI.

**Changelog format.** The changelog at `.fctry/changelog.md` (read by State Owner and displayed in the spec viewer) uses a structured markdown format with ISO 8601 timestamps, the command that triggered the change, and a parenthetical summary:

```
## 2026-02-16T12:25:00Z — /fctry:evolve status-line (symbol-based layout, derived next step)
- Spec version: 1.6 → 1.7
- `#status-line` (2.12): Rewrote section — symbol prefixes, derived next step priority chain

## 2026-02-15T20:00:00Z — /fctry:evolve (CLAUDE.md best practices and evergreen instructions)
- Spec version: 1.5 → 1.6
- `#core-flow` (2.2): Init Step 3 now creates CLAUDE.md with evergreen factory context

## 2026-02-11T09:00:00Z — /fctry:init
- Initial spec created (all sections)
```

Each entry header includes the ISO 8601 timestamp, the `/fctry` command that produced the change, and a short parenthetical summary. Entries list spec version transitions and affected sections identified by both alias and number. The changelog appends; it never overwrites.

**Spec status transitions.** The spec's status (`draft`, `active`, `stable`) transitions automatically — no user confirmation is needed. The Spec Writer transitions `draft` to `active` when init completes, and `stable` to `active` when an evolve touches the spec. The State Owner transitions `active` to `stable` when full scenario satisfaction is achieved with no drift detected. The `/fctry:review` command detects stale statuses (e.g., a spec marked `stable` that has drift) and offers corrections retroactively. There is no `building` status — build-in-progress is tracked separately in the build run state.

**Build learnings visibility.** Build lessons work silently — the CLI never shows "applied lesson X" or interrupts with lesson notifications. The value of lessons is that they influence decisions invisibly. But the spec viewer provides a browsable lessons panel: accessible via a tab or toggle (not prominent on the main view), showing lessons grouped by section alias with timestamps and summaries. The panel is read-only and informational — it lets the user see what the system has learned about their project without reading the raw markdown. When a section is selected in the viewer and has associated lessons, a subtle indicator shows the lesson count.

**Memory visibility.** The viewer provides a memory panel where the user can browse the system's accumulated knowledge. Entries are grouped by type — conversation digests, decision records, cross-project lessons, user preferences — with timestamps and source project names. Each entry is expandable to show full content. The user can edit entries inline (to correct mistakes) and delete entries they don't want. The memory panel is accessible from a global location in the viewer (not per-project, since memory is global). When the Interviewer references a past conversation during an evolve, the referenced digest is linkable in the viewer so the user can verify what the system remembers.

**Upgrade communication.** After a plugin version upgrade applies changes to a project, the user sees a compact inline summary in the CLI: "↑ Upgraded from v0.15 → v0.20: synopsis block added to spec, 2 .gitignore entries, CLAUDE.md refreshed. Try /fctry:view to see new kanban board." The summary lists concrete changes and ends with one actionable suggestion for a new capability to try. In the viewer, recently-upgraded projects show a brief "↑ upgraded" badge on their project card that clears after the first session. Projects that haven't been opened since the plugin updated show a subtle "update available" indicator. The status line shows a brief upgrade indicator (arrow-up icon) on the first prompt after upgrade, which clears after that prompt completes. All three surfaces (CLI, viewer, status line) work together: the CLI gives the full summary, the viewer gives persistent visibility across projects, and the status line gives ambient awareness.

**Tool validation on startup.** The first time any command runs in a session, the system checks for required tools. If all are present, the check is silent. If any are missing, the check fails loudly with installation instructions. Subsequent commands in the same session skip the check.

**Keyboard-friendly viewer.** In the spec viewer, the user can press `?` to see keyboard shortcuts, `Cmd/Ctrl+K` to open section search, `1`/`2`/`3`/`4` to switch left-rail tabs (ToC/History/Lessons/Memory), `]` to toggle the right-rail inbox, `a` to toggle inline change annotations on/off, and arrow keys to navigate sections in the ToC.

### 2.12 Terminal Status Line {#status-line}

While working in the terminal, the user sees a two-line status display at the bottom of Claude Code that shows where they are and what to do next — at a glance, without switching to the browser viewer. Each field uses an icon prefix to save horizontal space and make fields scannable without reading labels. Icons are Material Design Icons (Supplementary PUA-A range, which survives Claude Code's BMP PUA filter) — requires a Nerd Font in the terminal. See `references/statusline-key.md` for the full icon legend.

**Row 1 — Project identity.** The project name with the external version from the version registry appended (e.g., `fctry 0.6.1`), the current git branch (branch icon), the spec version from the registry (document icon), and context window usage (half-circle icon). Fields are separated by a dim `│` character. This row answers: "What project am I in and how much context is left?"

Example: `fctry 0.6.1 │ [branch] main │ [doc] 1.7 │ [ctx] 45%`

**Row 2 — Current activity.** The current fctry command (e.g., `evolve`), chunk progress during builds (play icon, e.g., `3+1/8`), the active spec section being worked on (e.g., `#core-flow (2.2)`), scenario satisfaction (check icon, e.g., `34/42`), section readiness as a single fraction of ready sections over total (shield icon, e.g., `35/42`), untracked change count (alert icon), and a recommended next step (chevron icon). The retry indicator `(rN)` appears when a chunk has retried at least once — e.g., `2(r2)/4` meaning two chunks complete, the current one on its second attempt, out of four total. This row answers: "What's happening right now and what should I do next?"

Example (active): `evolve │ #status-line (2.12) │ [check] 34/42 │ [shield] 35/42 │ [next] /fctry:execute`
Example (build with retry): `execute │ [play] 2(r2)/4 │ #core-flow │ [check] 34/42 │ [shield] 35/42`
Example (review scan): `review │ scanning 8/32 │ [check] 34/42 │ [shield] 35/42`
Example (idle): `[check] 34/42 │ [shield] 35/42 │ [next] /fctry:execute to satisfy remaining scenarios`

During `/fctry:review`, the status line shows scan progress alongside the command name — e.g., `scanning 8/32` — so the user can see how many sections require deep comparison vs. how many were skipped by freshness or semantic stability filters. The fraction updates in real-time as the State Owner works through sections.

**Icon legend:**

| Name | Meaning |
|------|---------|
| branch | Git branch |
| document | Spec version |
| half-circle | Context window usage |
| check | Scenario satisfaction count |
| shield | Section readiness (ready / total) |
| alert | Untracked changes outside fctry |
| play | Build chunk progress |
| `(rN)` | Retry indicator — chunk is on its Nth attempt (shown only when N > 1) |
| arrow-up | Plugin upgrade applied (shown once after upgrade, then clears) |
| chevron | Recommended next step |

The specific glyphs are defined in the status line script and documented in `references/statusline-key.md`. The spec describes icons by name so the implementation can change icon sets without a spec update.

**Derived next step.** When no agent has set an explicit next step and no command is active, the status line derives a contextual recommendation from the current project state. The derivation follows a priority chain:

1. Untracked changes exist → `/fctry:evolve to update spec with recent changes`
2. All scenarios satisfied → `All scenarios satisfied! /fctry:review to confirm`
3. Ready-to-build sections exist → `/fctry:execute to build ready-to-build sections`
4. Unsatisfied scenarios remain → `/fctry:execute to satisfy remaining scenarios`
5. Draft sections exist → `/fctry:evolve to flesh out draft sections`
6. Fallback → `/fctry:evolve to refine, or /fctry:execute to build`

When an agent has explicitly set a next step (via the state file), that takes priority over the derived recommendation. During an active command, the next step is suppressed (the command name is visible instead).

**Context percentage calibration.** The displayed percentage is normalized against Claude Code's auto-compact threshold (~84% of the total context window) rather than the raw window size. This makes the status line's number match Claude Code's own "Context left until auto-compact" display — so when CC says 60% left, the status line shows 40%, and both numbers agree. Without this calibration, the status line would show a lower number than CC reports, confusing users who see both.

**Readiness as a single fraction.** Readiness is displayed as one aggregated fraction: the count of sections that are `aligned`, `ready-to-execute`, `satisfied`, or `deferred` over the total section count. This is more scannable than a multi-category breakdown — the user sees "35 out of 42 sections are in good shape" at a glance. For the full breakdown by readiness category, the user runs `/fctry:review` or opens the spec viewer.

**Graceful degradation.** Every field hides when its data source is unavailable. If no spec exists, no `.fctry/` directory, or no git repository — the status line still appears with whatever is available. At minimum, the user always sees the project name and context window percentage. A fresh project with no spec shows just those two fields plus a next-step recommendation to run `/fctry:init`. As the user works with fctry, more fields appear naturally.

**Color coding.** Context window percentage turns green below 70%, yellow at 70-89%, and red at 90%+. Scenario satisfaction and section readiness use the same color scale: green when the ratio is 80%+ (most satisfied/ready), yellow at 50-79%, red below 50%. Untracked changes are always yellow. The active section name appears in magenta so it stands out. The current command name appears in cyan.

**Auto-activation.** The status line configures itself automatically via a plugin hook — the user never runs a setup command or edits configuration files. The first time any fctry command runs in a project, the hook ensures the project's Claude Code settings include the status line. Subsequent runs are a no-op unless the status line path has gone stale (e.g., after a plugin version update moves the cache directory) — in that case, the hook detects the stale path and updates it in place. The hook also syncs the global Claude Code settings alongside project settings, so the status line stays correct across all projects. The user simply starts working and the status line appears.

**Fresh every session.** The state file is cleared on session start via a plugin hook, so the status line never shows stale data from a previous session. As agents work during the current session, they write their progress to the shared state file and the status line reflects it. When the Spec Writer starts working on a section, the status line shows it. When the Executor completes a build chunk and updates scenario satisfaction, the numbers change. The status line is a passive observer — it reads state but never writes it.

**Scenarios appear only after evaluation.** The scenario count is hidden until scenarios have actually been evaluated (not merely counted). When scenarios exist but satisfaction is zero (unevaluated), the count appears dimmed (e.g., `42`) without the satisfied/total fraction. Once an agent evaluates satisfaction and records a score, the full fraction appears with color-coded feedback (e.g., `34/42`).

**Untracked changes awareness.** When files are modified outside of fctry commands and those files cover spec sections, the status line shows the untracked count with an alert icon. This gentle indicator reminds the user to reconcile changes via `/fctry:evolve` or `/fctry:review` — without interrupting their flow.

---

## 3. System Behavior

### 3.1 Core Capabilities {#capabilities}

**Progressive disclosure via shared references.** The plugin loads only the files needed for each command. Shared concepts (factory philosophy, experience language, holdout sets, numbered options, alias resolution, error conventions) are defined once in `references/` and referenced by agent and command files, keeping per-invocation token usage low while maintaining consistency.

**Conversational spec creation.** The system conducts an interview, asks follow-up questions based on user responses, and synthesizes answers into a complete NLSpec v2 document. It adapts to the user's communication style (paragraphs, fragments, bullet points) and never requires form-filling.

**Multi-session continuity.** The system saves interview state when the user types `save and pause` and resumes exactly where it left off when the user types `--resume`. It remembers all prior context (questions asked, topics covered, user's answers) and never asks the same question twice.

**Targeted spec evolution.** The system updates specific sections of the spec in response to user requests, leaving unaffected sections unchanged. It shows precise diffs after every update so the user can see exactly what changed.

**Conflict-aware updates.** When the system detects drift (spec and code describe different behavior), it surfaces the conflict before updating and asks the user to resolve it. It uses signals like commit recency, changelog entries, and code-spec alignment to determine which is more current.

**Reference interpretation.** The system fetches external URLs, interprets them in experience language (not technical language), and incorporates them into the spec as experience references. For web pages, it extracts interaction patterns and design principles. For screenshots and designs, it describes what the user sees and does.

**Gap analysis.** The system compares the spec to the codebase and identifies where they diverge: sections with no code, code with no spec coverage, and sections where they disagree. It produces a report with specific recommendations (which sections to update, which to review, which to build).

**Scenario-driven build planning.** The system reads the scenario holdout set, evaluates current satisfaction, identifies gaps, and proposes a build plan chunked by scenario impact. It presents the plan to the user for approval before executing.

**Autonomous execution.** After the user approves a build plan, the system executes all chunks autonomously in dependency order. The system handles code failures, retries, and rearchitecting silently. It resurfaces to the user only for experience-level questions where the spec is ambiguous or contradictory. When the build completes, the system presents an experience report describing what the user can now do, not a satisfaction scorecard.

**Build checkpoint and resume.** As each chunk completes, the system persists the build state so it survives session death, context exhaustion, or user interruption. When the user returns and runs `/fctry:execute` with an incomplete build on file, the system offers to resume from where it left off — skipping completed chunks entirely. If the spec changed for a completed section between sessions, the system flags the change and asks whether to rebuild that chunk or keep the old result.

**Build coordination.** During autonomous execution, the system monitors overall build health — detecting stuck chunks, identifying when repeated failures suggest spec ambiguity rather than code bugs, and rebalancing work across the dependency graph when possible. The coordination is invisible to the user; they see it as better build outcomes and faster recovery from problems.

**Convergence milestones.** When a build spans multiple convergence phases, the system presents non-blocking milestone reports at phase boundaries — snapshots of what the user can now try before the next layer builds. The user can validate the system at natural breakpoints without the build pausing for approval.

**Visual dependency graph.** During builds, the spec viewer renders the approved plan as an interactive DAG where chunk nodes light up through their lifecycle states and dependency edges show the execution order. The user watches their build plan come to life as a visual pipeline.

**Semantic dependency discovery.** When the State Owner builds a dependency neighborhood for a targeted command — determining which sections are relevant beyond the explicitly targeted one — it supplements structural cross-references (`{#alias}` anchors, "see section N.N" mentions) with the top-N semantically similar sections from the spec index's embedding table (above a cosine similarity threshold). This catches implicit dependencies that aren't linked by explicit cross-references: two sections about similar concepts that never reference each other are still surfaced as potentially relevant. The semantic dimension is advisory — the State Owner includes semantically related sections in its relevance manifest for downstream agents to consider, but structural cross-references remain the primary dependency signal for chunk boundary decisions.

**Version registry and propagation.** The system maintains a version registry in `.fctry/config.json` that declares what versions a project tracks (one external, one or more internal), where each version appears (propagation targets), how each version increments (rules), and how internal changes ripple to the external version (relationship rules). Seeded automatically at init, enriched via auto-discovery at first execute, and fully automated from then on — the user never manually bumps versions. When a version changes, every declared propagation target is updated atomically. When a git repository exists, the system commits after each completed chunk with a message referencing satisfied scenarios, auto-tags each chunk with an incremented patch version from the registry, and suggests minor/major version bumps at appropriate milestones. Projects without git receive the same build experience minus version control operations.

**Cross-session build learnings.** The system accumulates codebase-specific lessons across build sessions. Four events trigger lesson recording: (1) the Executor rearchitects after a failure, (2) a retry succeeds with a different approach, (3) a pattern consistently works for the project's tech stack, or (4) the user answers an experience question that reveals project-specific domain knowledge. Each lesson is recorded in `.fctry/lessons.md` — a structured, append-only, git-tracked artifact alongside the spec and scenarios. Each entry includes a section alias tag, the context (what was attempted), the outcome (what failed or succeeded), and the lesson (what to do differently). **Learning maturation lifecycle:** new lessons start with a `candidate` status and a confidence score of 1. When the State Owner encounters a candidate lesson that is confirmed by a subsequent build session (the same pattern holds), the lesson's confidence increments and status graduates to `active` after reaching a confidence threshold of 3 confirmations. Only `active` lessons are injected into the State Owner's briefing; `candidate` lessons are visible in the viewer's lessons panel (marked as provisional) but don't influence builds. If a subsequent session contradicts a candidate lesson, its confidence decrements — lessons that reach zero confidence are pruned. This prevents one-off flukes from becoming permanent build knowledge. The State Owner consults this file at scan time, matching active lessons to the current command by section alias tag and injecting relevant ones into its briefing. Lessons work silently — the user doesn't see "the system applied lesson X" in the CLI — but the viewer provides a browsable lessons panel so the user can see what the system has learned about their project, with candidate lessons visually distinct from active ones. Lessons are pruned when stale: the State Owner checks the changelog for section rewrites since each lesson's timestamp, and removes lessons whose referenced section has been significantly rewritten. When the file exceeds 50 entries, the State Owner compacts the oldest entries into summaries.

**Cross-session memory.** The system accumulates four types of knowledge across sessions in a global memory store at `~/.fctry/memory.md`: conversation digests (structured summaries scoped to topic shifts within evolve/init conversations — not one digest per session, but one per distinct topic or section discussed, so the Interviewer can recall specific past discussions without all-or-nothing inclusion of a large session digest), decision records (drift resolutions, experience question answers, and recurring choices — proposed as defaults with confirmation on recall, never auto-applied), cross-project lessons (codebase-agnostic patterns learned on one project that apply to others, surfaced only when the State Owner detects structural similarity — same section type, comparable tech stack, similar dependency pattern), and user preference signals (communication style, detail preferences, working patterns — synced to Claude Code's auto-memory so they persist in the standard `MEMORY.md` system). The memory store is viewable and editable — the viewer provides a memory panel where the user can browse entries grouped by type, correct mistakes, and delete entries. Memory works alongside the existing per-project build lessons (`lessons.md`): lessons are project-scoped and section-tagged for build-specific knowledge, memory is global and user/pattern-scoped for cross-cutting knowledge that transcends any single project.

**Addressable sections.** Every section of the spec has both a number (e.g., `2.2`) and a stable alias (e.g., `#core-flow`). Both work in commands. The system resolves aliases to sections and suggests corrections if the user references a nonexistent section.

**Change tracking.** The system maintains a changelog of every spec update, recording the timestamp, affected sections, and a one-line summary. The changelog is append-only and machine-readable so agents can read the history of spec evolution.

**Tool validation.** The system checks for required tools (ripgrep, ast-grep, gh CLI, MCP servers) on first command invocation. If any are missing, it fails early with clear installation instructions. It never runs a command that will fail later due to missing dependencies.

**Recursive kanban interface.** The viewer's primary surface is a kanban board that repeats at every level of the spec hierarchy: projects → sections/scenarios → claims/sub-features. The user drags cards between priority columns (Inbox, Now, Next, Later, Satisfied) to prioritize work. Kanban position drives State Owner assessment depth (claim-level for Now, coarse for Later), Executor build ordering, and review granularity. At level 2, a toggle switches between section-grouped and scenario-grouped views. Inbox items land as inbox cards at the appropriate level. The kanban replaces the static dashboard as the landing page — it's the same information but interactive and prioritizable.

**Automatic spec diagramming.** The viewer auto-generates five types of Mermaid diagrams from spec content: entity relationships (from `#entities`), user flows (from section 2 narratives), agent pipeline (from command-agent table), convergence phases (from `#convergence-strategy`), and section dependency neighborhoods (from cross-references). Each section with an available diagram has a per-section toggle (icon click or `d` shortcut) that swaps between text and diagram views. A global toggle shows all diagrams at once. Diagrams are cached in the spec-index DB and regenerated only when source content changes.

**Live spec viewer.** The system serves specs as a local web UI via a single multi-project-aware server. Within the spec view, the user can switch between all registered fctry projects from a sidebar without opening separate browser tabs. The viewer updates specs in real-time via WebSocket as agents work, highlights the section currently being edited, displays change history with diffs, and supports dark mode (system-detected with manual override). Code blocks show syntax highlighting. The viewer is read-only and requires no build step.

**Workflow enforcement.** The system tracks which workflow step is active and which steps have completed for the current command. Agents validate that prerequisites have run before proceeding — the Interviewer won't start without a State Owner briefing, the Spec Writer won't run before the domain agents complete. If a step is skipped, the system surfaces a numbered error with options to run the missing step, skip it, or abort.

**Structured spec index.** The system maintains a structured index of the spec backed by section aliases embedded in headings and an SQLite cache. Agents can query the index to load only the sections they need (instead of reading the full spec), resolve cross-references, and find sections by content. The markdown file remains the source of truth; the SQLite database auto-rebuilds from the markdown whenever the spec changes. The index tracks its own staleness: it records which spec version it was built from and computes a quantified staleness metric (how many spec revisions behind). When an agent queries a stale index, the response includes a prescriptive recovery hint — "index is 3 spec versions behind, rebuild recommended" — rather than silently returning outdated results. This self-awareness lets agents make informed decisions about whether to trust cached results or trigger a rebuild.

**Token-efficient browser verification.** The Observer can use a code-execution browser architecture (single tool running Python in a persistent namespace with browser functions) instead of multi-tool browser MCP servers. This approach sends only extracted data back to the LLM — not full page snapshots — achieving 3-6x token efficiency for the same verification tasks. The persistent namespace means variables survive across verification steps (take screenshot, check element, compare state), enabling multi-step verification workflows without losing intermediate results.

**Tiered observation detail.** The Observer selects the cheapest observation level that answers the question, operating at three tiers: summary (page title, key content counts, overall structure — ~100 tokens), structural (DOM hierarchy, element presence/absence, accessibility tree — ~500 tokens), and full (complete DOM, computed styles, screenshot — ~2000+ tokens). Simple verifications ("does the page load?", "is the element present?") use summary tier. Layout and interaction verifications ("does the kanban render three columns?") use structural tier. Visual verifications ("does the dark mode theme apply correctly?") use full tier. The Observer auto-selects the tier based on what's being checked; agents requesting ad-hoc observation can specify a tier. This prevents spending verification tokens on questions that don't require full page state.

**State Owner reality index.** The State Owner produces a self-assessed confidence score alongside each briefing — a simple three-level indicator (high, medium, low) reflecting how well it understands the current codebase state. High confidence: the State Owner read the relevant files, the spec index is fresh, and recent git history is clear. Medium confidence: some files were skipped (too large, binary), the spec index is stale, or the codebase has significant areas the State Owner hasn't scanned recently. Low confidence: major portions of the codebase are unknown, or the last scan was many sessions ago. The reality index appears in the briefing header so downstream agents (and the user) can calibrate how much to trust the State Owner's findings. A low-confidence briefing prompts the Executor to factor in higher verification depth for chunks in unknown territory.

**Minimal code context injection.** When agents read code for comparison or analysis, they extract the minimal relevant unit — a function, class, or type definition via ast-grep — rather than the full file. Direct callees, referenced types, and the immediate import context are included; surrounding code that doesn't affect the analysis is excluded. This applies to the State Owner during drift detection, the Executor during build planning, and the Observer during verification. For spec sections and stable documents, agents use semantic retrieval (embedding similarity) to find relevant content. For code — symbols, call graphs, function definitions, file structure — agents use deterministic search (rg, ast-grep) exclusively. Vector-only retrieval for code is prohibited because it can miss exact contracts and precise symbol references.

**Semantic section fingerprinting.** The spec index computes and stores embedding vectors for each spec section using a local language model (ONNX Runtime). These fingerprints enable the State Owner to detect whether a section's meaning has changed — not just its text — allowing review to skip sections whose meaning is stable even after light edits. Fingerprints are computed on the write path (when the Spec Writer updates a section) so review pays no embedding cost for unchanged sections.

**Automatic section readiness tracking.** The State Owner automatically assesses the readiness of each spec section during every scan. Readiness values range from `draft` (incomplete) through `aligned` (spec and code match) to `satisfied` (scenarios passing). The State Owner writes per-section readiness to `state.json` as the authoritative source — a `sectionReadiness` map keyed by section alias (e.g., `{ "core-flow": "aligned", "first-run": "ready-to-build" }`), alongside the existing aggregate `readinessSummary`. All downstream consumers — the status line, the viewer, the Executor — read from `state.json`. This ensures consistency: the status line and viewer always show the same readiness because they read from the same agent-assessed source, not independent heuristics. During builds, the Executor updates per-section readiness in `state.json` after each chunk completes — marking covered sections as `aligned` (or `satisfied` if scenarios pass) — so the viewer reflects build progress in real-time. A lightweight bootstrap heuristic exists for the initial assessment before any agent has scanned: it uses structural analysis (section number prefix for meta vs. buildable categories) and basic code-directory detection. This heuristic contains no project-specific hints — it works identically for any codebase. Once the State Owner runs, its deeper analysis supersedes the heuristic entirely. Structural headings are excluded from assessment: parent containers (e.g., "## 2. The Experience" which groups subsections), unnumbered headings without aliases (Table of Contents, appendices), and unnumbered sub-headings within sections. All numbered leaf sections are assessed regardless of whether they have aliases. Meta-concept sections — those in NLSpec v2 categories 1 (Vision), 4 (Boundaries), 5 (Reference), and 6 (Satisfaction) — are automatically classified as `aligned` when they have content, because these categories describe principles, constraints, and convergence criteria rather than buildable code features. Only categories 2 (Experience) and 3 (System Behavior) are checked for related code. This classification is derived from the spec's own structure (section number prefix) rather than maintained in a hardcoded alias list, so it works for any project regardless of how many sections have aliases.

**Structured agent interchange.** Agents emit structured data alongside their conversational CLI output. Every agent output has two representations: a conversational summary for the terminal (what the user reads) and a structured interchange document for the viewer (what the viewer renders as rich UI). The structured interchange uses a consistent envelope with typed sections — findings (friction, drift, quality signals with evidence refs), actions (atomic next steps with priority and acceptance criteria), and command-specific payloads (release summaries, build events, gap analysis items). The viewer parses the interchange to render interactive views: clickable action checklists, finding cards with expandable evidence, proposal selectors for adopt workflows, and patch viewers with inline diffs. The terminal never shows raw structured data — it always presents the conversational summary. For command output (findings, actions, diffs, release summaries), the viewer renders from the structured interchange rather than displaying prose. For the spec content itself, the viewer continues to render markdown directly — the interchange covers ephemeral command output, not the persistent spec document. This separation lets agents optimize for both audiences simultaneously: concise for the terminal, rich for the viewer.

**Untracked change detection.** When file writes happen outside of fctry commands and those files map to spec-covered sections, a PostToolUse hook detects the change and surfaces a nudge asking the user if they want to update the spec first. The nudge is non-blocking — the user can dismiss it and reconcile later via `/fctry:review`.

**Self-improvement loop (future direction).** The system is designed to observe its own execution patterns — retry rates, token usage, drift frequency, session friction — and propose improvements to its own configuration, prompts, and hooks. Rather than requiring the user to tune the system manually, a future `/fctry:reflect` command would analyze recent session behavior and suggest specific changes: adjust a hook timeout that causes frequent failures, tighten a section of the spec that causes repeated experience questions during builds, propose a global config change that would reduce chunk retry rates. The system would examine its own behavior using the same findings/proposals pattern as `/fctry:review` — but turned inward. The cross-session memory system provides the foundation for this — conversation digests, decision records, and cross-project lessons are the raw data that `/fctry:reflect` would analyze to identify patterns and propose improvements. This direction extends fctry from a user-directed tool to one that improves with use.

**Spec update suggestions from observed changes.** When drift is detected — either through untracked changes or during `/fctry:review` — the system doesn't just flag the drift, it proposes a specific spec update. Instead of "drift detected in `#core-flow` (2.2)," the user sees: "Suggest updating section 2.2 to describe items sorted by date, based on changes in `src/list/sort.ts`." The suggestion is concrete and actionable — the user can approve it directly or use it as a starting point for `/fctry:evolve`. Related changes are grouped: if several files under the same section drifted, the system proposes one coherent update that covers all of them.

**Async viewer inbox with command consumption.** The spec viewer accepts evolve ideas, reference URLs, and new feature proposals at any time. The system processes these in the background — fetching and analyzing references, identifying affected sections for evolve ideas, scoping new features against the existing spec. Processed items are ready for the user when they next run a fctry command. When `/fctry:evolve` or `/fctry:ref` runs, the system checks the inbox for relevant items and offers to incorporate them as conversation context — so the user doesn't re-describe ideas they already queued. The inbox operates independently of the current build or command.

**Build mission control.** During autonomous builds, the spec viewer transforms into a mission control view showing real-time progress. Each chunk displays an explicit lifecycle state (planned, active, retrying, completed, failed) with retry visibility (current attempt number). The activity feed shows typed events (agent started section, chunk retrying, scenario evaluated, chunk verified, etc.) rather than generic file-change notifications. A connection status indicator shows whether the live feed is current or stale. Sections light up in the table of contents as the agent works on them.

**Build self-verification.** Agents can observe their own outputs through the Observer agent. After each build chunk completes, the Observer automatically checks the result — verifying that expected files exist, the viewer renders correctly if applicable, and build artifacts match expectations. Any agent can invoke the Observer on demand: the State Owner checks viewer health, the Spec Writer verifies a live update rendered, the Executor verifies chunk output. The Observer uses browser automation, API queries, and file system inspection depending on what tools are available, degrading gracefully from full browser-based verification to API-only to file-only inspection.

**Context lifecycle management.** The system treats the context window as a finite resource and manages it proactively. Build state persists through files (`.fctry/state.json`, git commits, CLAUDE.md) rather than conversation history, ensuring that context compaction or session boundaries never lose critical state. During spec evolution workflows (init, evolve, ref), intermediate agent outputs — the State Owner's briefing, the Interviewer's captured answers, the Researcher's findings — are persisted to the state file as they complete, so that if context compaction occurs mid-workflow, the next agent reads from disk rather than depending on conversation history alone. The Spec Writer creates evergreen compact instructions in CLAUDE.md at init, guiding what Claude preserves during auto-compaction: spec paths, build checkpoints, scenario satisfaction, and active workflow state. During builds, the Executor structures work to create natural context boundaries so each chunk operates with sufficient context regardless of how many preceded it. Mission control surfaces context health as a persistent indicator and context lifecycle transitions as typed events in the activity feed. When a build requires unusual context management (oversized chunks, non-default isolation strategies), the Executor calls it out in the build plan. Otherwise, context management is invisible — the user sees consistent build quality and trusts the system is managing itself.

### 3.2 Things the System Keeps Track Of {#entities}

The system keeps track of:

- **Spec document** — The canonical NLSpec v2 file stored at `.fctry/spec.md`. Contains seven sections (vision, experience, behavior, boundaries, references, satisfaction). Each section has a number and an alias. Updated by the Spec Writer agent. The spec's frontmatter includes a version number (e.g., 1.0) that represents the spec document version, distinct from the project's semantic version. The frontmatter also carries a status field with three values: `draft` (initial creation, spec being written for the first time), `active` (spec and scenarios are written, the spec is being iterated on or built from), and `stable` (full scenario satisfaction achieved with no drift detected). Status transitions are fully automatic — no user confirmation needed. `draft` to `active` is owned by the Spec Writer at init completion; `active` to `stable` is owned by the State Owner when satisfaction and drift conditions are met; `stable` to `active` is owned by the Spec Writer when any evolve changes the spec. There is no `building` status — build-in-progress is transient state tracked in the build run, not the spec lifecycle.

- **Scenarios** — The holdout set of user stories stored at `.fctry/scenarios.md`, organized by feature. Each feature is a named experience ("I describe my vision and get a complete spec") with its own scenarios grouped by priority tier (Critical, Edge Cases, Polish). Features are clustered into four categories: Core Workflow, Build, Viewer, and System Quality. Each feature declares dependencies on other features. Scenarios are never shown to the coding agent during development (holdout property). Evaluated by LLM-as-judge for satisfaction. Updated by the Scenario Crafter agent.

- **Interview state** — When the user pauses an interview, the system saves the transcript so far, questions asked, topics covered, and the next intended question — with explicit uncertainty markers (OPEN for unanswered questions, ASSUMED for inferences the Interviewer made, MISSING for referenced but unprovided information). Stored at `.fctry/interview-state.md`. Deleted when the interview completes.

- **Changelog** — A timestamped log of every spec update stored at `.fctry/changelog.md`. Each entry records the date, time, affected sections (by number and alias), and a one-line summary. Append-only. Machine-readable (markdown format). Read by the State Owner to understand spec evolution trajectory.

- **State briefing** — Produced by the State Owner at the start of every command. Describes project classification (greenfield, has code, has docs, has spec), current scenario satisfaction, detected drift, recent changes (from changelog and git log), recommended next steps, and a relevance manifest — the specific files and sections that matter for the current command, so that subsequent agents (and session resumption) can load targeted context rather than scanning everything. Consumed by all other agents to ground their work in reality.

- **Visual references** — Screenshots, design files, or images stored in `.fctry/references/`. Each has a corresponding entry in section 5.2 of the spec with an experience-language interpretation. Linked from the spec so the coding agent can see both the image and the description.

- **Codebase size estimate** — An approximate measure of the project's codebase in context-relevant terms (estimated token count, file count, or a classification like small/medium/large). Computed by the State Owner during each scan. Used by the Executor to calibrate build plan granularity and by the status line as a project health indicator.

- **Execution priorities** — A ranked ordering of three concerns — speed, token efficiency, and reliability — that guide the Executor's choices about failure behavior, retry strategy, verification depth, and context management. Stored globally in `~/.fctry/config.json` as `{ "executionPriorities": ["speed", "reliability", "token-efficiency"] }` (example ranking). Per-project overrides use the same format in `.fctry/config.json` alongside the version registry. Resolution order: per-project config → global config → prompt user. Set once on first `/fctry:execute` if not already configured. The priorities tell the agent what to optimize for, and the agent chooses the strategy that best serves those priorities.

- **Build plan** — Produced by the Executor during `/fctry:execute`. Describes the proposed work as discrete chunks, each tied to one or more scenarios. Includes estimated time per chunk, a dependency graph (some chunks must happen before others), an execution strategy shaped by the user's priorities (execution order, failure approach, verification depth), and a clear explanation of how the priorities influenced the strategy. Approved by the user once before autonomous execution begins.

- **Build run** — A first-class object representing a single `/fctry:execute` invocation after plan approval. Contains a run ID, start time, a reference to the approved plan, a chunk tree (showing chunk dependencies, lifecycle states, and retry counts per chunk), overall status (running, completed, or partial), and duration. The build run is the entity that mission control observes — it's what connects the plan to the live progress the user sees. Referenced by the experience report at the end of the build. Persisted in `.fctry/state.json` as a `buildRun` object so that incomplete builds survive session death and can be resumed. Cleared when the build completes or the user starts a fresh plan.

- **Build checkpoint** — The state of a build run at a point in time: which chunks are completed (with their outcomes), which are pending, the position in the dependency graph, and a reference to the approved plan. Written after each chunk completes. Used to resume builds that were interrupted by session death, context exhaustion, or user interruption. The checkpoint also records which spec version each completed chunk was built against, so the Executor can detect if the spec changed for a completed section and offer to rebuild that chunk.

- **Version registry** — A declarative model of what versions a project tracks, where they appear, and how they change. Lives in `.fctry/config.json` under a `versions` key alongside execution priorities. Contains **version types** (one external, one or more internal), **propagation targets** (which files and locations each version appears in), **increment rules** (when each version type bumps), and **relationship rules** (how internal version changes ripple to the external version). The external version is the project's public-facing semver — what users, consumers, and release notes reference. Internal versions track internal artifacts: the spec version (spec document evolution), and any project-specific versions discovered or declared (API version, schema version, etc.). Seeded at init with two default types (external at 0.1.0, spec at 0.1). Enriched at first execute when the Executor auto-discovers version-bearing files and proposes propagation targets. Fully automated from then on — the user never manually bumps versions.

- **Project format version** — A version marker in `.fctry/config.json` (under `formatVersion`) recording which fctry plugin version's conventions the project follows. Set to the current plugin version at init; updated after each upgrade. This is the anchor for all upgrade logic — the system compares it against the running plugin version to determine what infrastructure changes are needed. Distinct from the external version (the project's public semver) and the spec version (the document's revision count).

- **Tool availability** — The set of required tools (ripgrep, ast-grep, gh CLI, MCP servers) and their presence on the system. Checked on first command invocation. Cached for the session so subsequent commands don't re-check.

- **Section addressing map** — The mapping from section aliases (e.g., `#core-flow`) to section numbers (e.g., `2.2`). Updated whenever the spec structure changes. Used to resolve user references like `/fctry:evolve core-flow` to the actual section.

- **Project instructions (CLAUDE.md)** — A three-layer document stored at the project root. The evergreen layer is created by the Spec Writer during `/fctry:init` and contains content that remains valid across the entire project lifecycle: the factory contract (spec and scenario file paths, agent authority, scenario validation approach), a command quick-reference table, a guide to the `.fctry/` directory and its contents, workflow guidance for working within the factory model, and a description of what scenarios are and how they're used. The compact instructions layer is also created at init as a `# Compact Instructions` section, telling Claude what to preserve during auto-compaction: spec and scenario file paths, build checkpoint state in `.fctry/state.json`, scenario satisfaction scores, active section and workflow step, and the current build plan if one exists. This is a static, evergreen set of preservation rules — it doesn't change per phase because what matters for a factory project is stable. In unusual builds, the Executor may append phase-specific compact instructions and call this out in the build plan. The build layer is added by the Executor during `/fctry:execute` and contains content specific to the current build: the approved build plan, convergence order, versioning rules, and project-specific architecture notes. The build layer is refreshed on each execute run as plans and architecture evolve. All three layers are audited by the Spec Writer during `/fctry:review` — the evergreen and compact instructions layers are always auditable (they exist from init onward), while the build layer is audited only after execute has been run at least once.

- **Project registry** — A global list of all fctry projects stored at `~/.fctry/projects.json`. Each entry records the project path, name (from spec frontmatter), and last activity timestamp. Auto-populated when `/fctry:init` creates a spec and when the `UserPromptSubmit` hook runs in a project with an existing spec. Consumed by the viewer server to populate the project sidebar. Projects can be removed manually or via `/fctry:stop <project>`.

- **Spec viewer state** — The currently highlighted section (if an agent is working on it), the active change history entry (if the user is viewing a diff), and the WebSocket connection status. The viewer server's PID and port are stored globally at `~/.fctry/viewer.pid` and `~/.fctry/viewer.port.json` (since the server is shared across all projects). Per-project viewer ephemera (logs) remain in `.fctry/viewer/`. Agents discover the viewer's address by reading `~/.fctry/viewer.port.json` — the Observer uses this for API queries and browser automation against the running viewer. Ephemeral — cleared when the viewer stops.

- **Verification verdict** — A tight pass/fail result produced by the Observer for a specific check. Contains the check description, the result (pass or fail), evidence (screenshots, API responses, file contents), and whether the check passed on first attempt or after retry. Verification verdicts are emitted as events to the activity feed and aggregated in the build run.

- **Observation report** — A broad scan result produced by the Observer. Contains what was checked, what was seen, and findings with evidence (screenshots, API responses). Used when an agent requests a general observation rather than a specific verification — for example, "look at the viewer and tell me what you see."

- **Verification audit trail** — A structured record of all Observer checks during a build run, produced via executable markdown verification. Each entry links evidence (screenshots, command outputs) to the check that produced it. Downloadable alongside the build log for post-build review.

- **Memory store** — A global file at `~/.fctry/memory.md` containing four types of cross-session knowledge. Each entry has a type, timestamp, source context (project name and command that produced it), and content. Each entry type has a token ceiling to keep memory compact and scannable. **Conversation digests** (max ~300 tokens each) are structured documents summarizing what was discussed during an evolve or init: section aliases discussed, questions asked with answers, decisions made with rationale, and open threads requiring follow-up. Tagged with the project name and section alias so the Interviewer can find relevant context for future conversations about the same section. The structured format ensures digests are quick to consume during scans rather than open-ended narratives. **Decision records** (max ~150 tokens each) capture choices the user made (drift resolutions, experience question answers, priority rankings) with enough context to propose them as defaults next time the same pattern appears. Decision records support supersession: when a new decision covers the same structural pattern as an existing one, the old record is marked superseded with temporal metadata — a `superseded_by` reference linking to the replacement record and a `superseded_at` timestamp. This makes the audit trail navigable: the user (or the system) can trace the chain of decisions for a given pattern and query "what was the decision at time T." Superseded records are preserved in the file but excluded from active recall. **Cross-project lessons** (max ~200 tokens each) capture codebase-agnostic patterns (e.g., "CSS grid doesn't work for kanban layouts in this framework") tagged with the structural context where they were learned — section type, tech stack, dependency pattern — surfaced on other projects only when structural similarity is detected. **User preference signals** (max ~50 tokens each) capture observed patterns in how the user works (briefing detail level, tendency toward specific options, communication style), synced to Claude Code's `MEMORY.md` once stable (consistent across 3+ interactions). Read by the State Owner at scan time alongside per-project lessons, subject to a total injection budget of ~2000 tokens per scan — the State Owner selects the most relevant entries within this budget using a fused multi-signal ranking algorithm: each entry is scored across three signals simultaneously — section alias match to the current command (strongest signal), recency, and memory type (decision records weighted highest, then cross-project lessons, then digests, then preferences) — with scores combined via weighted sum rather than sequential filtering. A diversity penalty ensures no single section dominates the injection window: after selecting the top-scoring entry, subsequent entries from the same section receive a diminishing score so that entries from other relevant sections get representation. Readable and editable by the user via the viewer's memory panel. Distinct from per-project build lessons (`lessons.md`): lessons are project-scoped build knowledge, memory is global cross-cutting knowledge.

- **Build lesson** — A single entry in `.fctry/lessons.md` recording codebase-specific knowledge from a build. Contains a section alias tag (e.g., `#core-flow`), a timestamp, a maturation status (`candidate` or `active`), a confidence score (integer, starts at 1, graduates to `active` at 3), the context (what was attempted and why), the outcome (what failed or succeeded), and the lesson (what to do differently next time). Written by the Executor as a side effect of four triggers: failure-then-rearchitect, retry-with-different-approach, consistent-pattern-discovery, and experience-question-answer. New lessons start as `candidate` with confidence 1. When the State Owner encounters a candidate lesson confirmed in a subsequent build (same pattern holds), confidence increments. At confidence 3, the lesson graduates to `active`. Contradicted lessons decrement; confidence 0 → pruned. Only `active` lessons are injected into the State Owner's briefing — `candidate` lessons are visible in the viewer's lessons panel but don't influence builds. Read by the State Owner at scan time — matched to the current command by section alias tag (deterministic, not similarity-based). Distinct from build traces (per-run ephemera) — lessons are cumulative, git-tracked, and persist indefinitely until pruned. A lesson is stale when the section it references has been significantly rewritten since the lesson's timestamp (determined by checking the changelog). Stale lessons are pruned silently by the State Owner. When the file exceeds 50 entries, the State Owner compacts the oldest `active` entries into section-grouped summaries (candidate entries are simply pruned at this threshold).

- **Build trace** — A per-build structured artifact written to `.fctry/build-trace-{runId}.md` when a build completes (or partially completes). Records chunk execution order, chunk types (isolated vs context-carrying), outcomes (completed, failed, retried), duration, affected spec sections, and the experience report. Unlike the changelog (which tracks spec evolution) or the viewer log (which tracks runtime events), the build trace captures what actually happened during a single build run in a compact, parseable format. The State Owner reads the most recent build trace on the next scan to understand what was built and what succeeded or failed — avoiding redundant re-analysis. Build traces are not git-tracked (ephemeral), but persist across sessions so the State Owner can reference them.

- **Experience question** — A named build state representing a spec ambiguity that blocks dependent chunks. Contains the question text, the timestamp it was surfaced, the chunks blocked on the answer, and (once answered) the user's response. Written to `.fctry/state.json` under `buildRun.pendingQuestion` when the Executor encounters an ambiguity. Cleared when the user answers. Mission control displays pending questions prominently. This makes the build's dependency on user input explicit and visible, rather than an informal inline resurfacing.

- **Phase type** — A characterization of the overall build plan inferred by the Executor during plan generation. One of five values: Capability (net-new user-facing ability), Hardening (improving reliability and scenario satisfaction), Refactor (restructuring for clarity and maintainability), Integration (making components work together end-to-end), or Polish (improving UX coherence and ergonomics). Inferred from the readiness distribution and character of included sections — never declared by the user. Not stored or persisted: derived fresh each time a build plan is generated. Shown in the build plan to explain why the plan looks the way it does, and shapes how the release summary headline is framed.

- **Workflow state** — Tracked in `.fctry/state.json`. Records the current command, the active workflow step (e.g., `state-owner-briefing`, `interviewer`, `spec-writer`), completed steps for the current command, and the last agent that ran. Used by agents to validate prerequisites before proceeding. Cleared on session start.

- **Spec index (SQLite)** — A structured cache of the spec stored at `.fctry/spec.db`. Contains a `sections` table (alias, number, heading, content, parent section, word count, last updated — where `last_updated` is a per-section modification timestamp set when that specific section's content changes, not a rebuild timestamp) and a `changelog_entries` table (timestamp, affected sections, summary). The database also stores per-section content hashes and embedding vectors. A `section_embeddings` table stores the section alias, a content hash of the section's markdown, the embedding vector (384-dimensional, computed locally via a small language model running on-device through ONNX Runtime — no external API calls, no network dependency), the model identifier, and a timestamp. Embeddings are recomputed only when a section's content hash changes, so unchanged sections incur zero embedding cost. If the model identifier changes (model upgrade), all stored embeddings are invalidated and recomputed on next access. The index also tracks staleness: it records the spec version it was built from (from spec frontmatter) and exposes a staleness metric (spec versions behind). Query responses from a stale index include a prescriptive hint (e.g., "index built from spec 3.34, current spec is 3.36 — rebuild recommended") so agents can decide whether to trust cached data or trigger a rebuild. Auto-rebuilds from the markdown spec whenever the file changes. Enables agents to query individual sections without loading the full spec, resolve cross-references, search by content, and compare section meaning across revisions. The markdown file is always the source of truth — the database is a derived cache that can be deleted and rebuilt at any time.

- **Section readiness index** — Per-section readiness metadata. The authoritative source is `state.json`, which stores both a `sectionReadiness` map (alias → readiness value, e.g., `{ "core-flow": "aligned", "first-run": "ready-to-build" }`) and an aggregate `readinessSummary` (e.g., `{ "aligned": 28, "ready-to-build": 5 }`). Each section has a readiness value: `draft` (content incomplete), `undocumented` (code exists but spec doesn't describe it — needs a decision), `ready-to-build` (spec describes it but code doesn't exist — needs a build), `partial` (code exists but doesn't cover all behaviors described in the spec — only assigned to sections with claim-level assessment data, i.e., Now-priority sections), `aligned` (spec and code match), `ready-to-execute` (aligned and dependencies satisfied), `satisfied` (scenarios passing), or `deferred` (intentionally postponed — not buildable now but not a problem, counted as "ready" in aggregation). The readiness vocabulary matches the gap analysis headings — `undocumented` maps to "Decisions Needed", `ready-to-build` maps to "Ready to Build" — so the same terms appear in the viewer pills, the review output, and the status line. Partial readiness includes a claim count (e.g., `partial 30/40`) so the viewer and Executor know how much remains. Written by the State Owner during every scan and updated by the Executor after each build chunk completes. All downstream consumers — the status line, the viewer (section color-coding, readiness pills, dashboard cards), and the Executor (build plan filtering) — read from `state.json`. The SQLite cache also stores readiness for agent queries, but `state.json` is the single source of truth that all display surfaces consume.

- **Section priority** — A per-section priority assignment stored in `.fctry/config.json` under a `priority` key. Contains ordered arrays per column (`now`, `next`, `later`) at each kanban level (project, section, claim). Sections not listed default to `next`. The `satisfied` column is computed from readiness, not stored. Read by the Executor to order build chunks, by the State Owner to determine assessment depth (claim-level for Now, standard for Next, coarse for Later), and by the viewer to render kanban boards. Updated when the user drags cards in the kanban. Persists across sessions.

- **Diagram definition** — A cached Mermaid diagram source string for a spec section. Stored in the spec-index SQLite database alongside the section's content hash. Five types: entity relationship, user flow, agent pipeline, convergence phase, and section dependency neighborhood. Three types are generated deterministically by parsing structured data (agent pipeline from SKILL.md, section dependencies from cross-reference patterns, convergence phases from phase markers). Two types are generated by the Spec Writer as a side effect of writing the relevant sections (entity relationships from bold terms and relationship verbs, user flows from step narratives). Regenerated only when the source section's content hash changes. The viewer renders diagram definitions via Mermaid.js from CDN. If a definition is missing or stale, the diagram toggle is hidden for that section.

- **Untracked changes** — A count of files modified outside of fctry commands that map to spec-covered sections. Tracked in `.fctry/state.json` as `untrackedChanges` (an array of `{file, section, timestamp}` entries). Written by the PostToolUse hook when it detects a relevant file write. Cleared when the user runs `/fctry:review` or `/fctry:evolve` for the affected section.

- **Viewer inbox queue** — Items submitted through the spec viewer's async inbox. Each item has a type (evolve idea, reference URL, or new feature), the raw input from the user, a processing status (pending, processing, processed, error), and the system's analysis (affected sections, experience-language interpretation, scope assessment). Stored in `.fctry/inbox.json` as a separate file from session state (survives across sessions, not cleared on session start). Processed asynchronously in the background. Consumed when the user runs the corresponding fctry command.

- **Architecture snapshot** — A persistent brief of the project's codebase structure, stored at `.fctry/architecture.md`. Records module layout, key file roles, public contracts, and structural invariants — the stable facts about a codebase that don't change on every commit. Maintained by the State Owner: updated when structural changes are detected (new modules, renamed exports, major refactors) and read at the start of every scan as a starting point so agents don't re-derive known structure from scratch. Versioned against the git commit it reflects so staleness is detectable — if the snapshot's commit is behind HEAD and structural files have changed, the State Owner refreshes it before proceeding. Can be deleted and regenerated at any time (the codebase is the source of truth). For new projects, the snapshot is created during the first State Owner scan. For existing projects, it's created on the first command invocation after the feature ships.

- **Agent interchange document** — A structured data payload emitted by agents alongside their conversational output. Contains a meta block (timestamp, command, output tier), a status block (ok/fail, summary), and command-specific typed sections: `findings[]` (category, impact, evidence refs, section relevance), `actions[]` (type, target section, summary, priority, acceptance criteria), and optional `release` (headline, highlights, deltas, migration). Each item has a stable ID (e.g., `FND-001`, `ACT-003`) for cross-referencing — a finding can reference the action that resolves it, an action can reference the finding that motivates it. Tool calls within findings carry a semantic step type (`file_read`, `code_edit`, `command_exec`, `search`, `agent_spawn`, `external_tool`) so the viewer can render type-appropriate cards — inline diffs for edits, syntax-highlighted excerpts for reads, terminal-styled output for commands. During `/fctry:execute`, chunk actions carry a structured shape similar to a waterfall item: start time, duration, dependencies, and lifecycle state — enabling the DAG visualization to render directly from interchange data rather than requiring a separate state mapping. The interchange is emitted once per agent output and flows to the viewer via WebSocket. Not persisted to disk (ephemeral, same as WebSocket events). The viewer renders it into interactive UI; the terminal ignores it.

### 3.3 Rules and Logic {#rules}

**Agent sequencing enforcement.** The State Owner always runs first, before any other agent acts. This is not merely documented — it's enforced. Each agent checks `workflowStep` and `completedSteps` in the state file before proceeding. If the State Owner hasn't produced a briefing, the agent surfaces a numbered error: "(1) Run State Owner scan now (recommended), (2) Skip (not recommended), (3) Abort." The system tracks workflow state across all agents for the duration of the command.

**Prescriptive error messages.** When an agent encounters a workflow violation or prerequisite failure, the error message tells the agent (or user) exactly what to do next — not just what went wrong. "State Owner must run before Interviewer can proceed. Run the State Owner scan first, then retry." is better than "Prerequisite missing: state-owner-scan." Every numbered error option includes the concrete action, not just a label. This principle extends to all error surfaces: tool validation errors include installation commands, section-not-found errors suggest the closest match, version mismatches name the fix command. The error is the recovery plan.

**Command complexity scaling.** The agent pipeline adapts its depth to the scope of the command. For targeted operations that affect a single section with no cross-section dependencies — a one-section `/fctry:evolve`, a small `/fctry:ref` — the pipeline runs lighter: the State Owner produces a relevance manifest and readiness check (no deep codebase scan), the Scenario Crafter runs an impact check (any scenarios affected?) rather than a full scenario authoring pass, and intermediate agent outputs are leaner. For broad operations — `/fctry:init`, multi-section restructures, full `/fctry:review` — the pipeline runs at full depth. The system determines scope from the command arguments and the State Owner's initial assessment. The user never configures pipeline depth directly — it's an automatic response to the work being done.

**Complexity-aware chunk verification.** During `/fctry:execute`, the Executor assesses each chunk's complexity and varies Observer verification depth accordingly. Trivial chunks (label changes, config tweaks, single-file additions) receive lightweight verification — the Observer confirms the change landed without a full behavioral check. Structural chunks (new subsystems, schema changes, cross-module refactors) receive full Observer treatment including browser verification when a viewer surface is affected. Complexity is determined from structural signals: number of spec sections touched, dependency depth in the chunk graph, estimated line-count delta, and whether the chunk introduces new files or modifies public contracts. This avoids spending verification tokens on changes where the probability of silent failure is low, while concentrating verification effort where it matters most.

**Output depth tiering.** Agent outputs scale in depth with the task tier. For patch-tier operations (targeted single-section edits, minor corrections), agents produce minimal outputs: the State Owner emits a relevance manifest, the Spec Writer emits a diff summary. Prose is limited to a status summary and section refs — no narrative. For feature-tier operations (multi-section changes, new capabilities), agents produce standard outputs: full briefings, scenario updates, detailed diffs. Brief narrative is allowed alongside per-section change descriptions. For architecture-tier operations (restructures, convergence strategy changes, full inits), agents produce comprehensive outputs: deep analysis, complete scenario authoring, experience-level impact assessment. Full narrative with structured findings, with detail behind expandable IDs. The tier is derived from the command and scope — `/fctry:evolve core-flow` with a small change is patch-tier; `/fctry:init` is architecture-tier. This tiering applies to all agents in the pipeline and prevents heavyweight analysis for lightweight changes.

**Sibling-aware structured outputs.** When agents write or update multiple peer items — scenarios within a feature, sections within a category, claims within a section — they process all siblings in a single structured pass. The prompt includes all sibling titles and summaries so each output is written in context of its peers, not independently. This produces more distinctive scenario titles (each scenario name contrasts with its siblings rather than being generically descriptive), more coherent section descriptions (sections in the same category complement rather than overlap), and better relative readiness assessments (the State Owner calibrates its judgment across siblings rather than evaluating each in isolation). The principle: labeling peers together produces better labels than labeling each alone.

**Structured intermediate reasoning for concise outputs.** When agents produce concise outputs that compress complex reasoning into short text — scenario titles, section summaries, changelog entries, readiness labels — the structured schema includes intermediate reasoning fields that are computed but not persisted. For scenario titles: `experienceContext` (what the user is doing) + `distinguishingBehavior` (what makes this scenario unique among siblings) + `title` (the final concise title). For section summaries: `keyCapability` + `distinctionFromSiblings` + `summary`. Only the final field appears in the output; the intermediate fields guide the model's reasoning path toward more precise results. This is a lightweight prompt engineering discipline, not an architectural pattern — it applies wherever agents compress reasoning into labels.

**Concise agent output.** Agents produce outputs composed of decisions, findings, diffs, and risks. Step-by-step narration of reasoning, meta-commentary on the agent's own process, restatements of the request, and "here's what I'm about to do" preambles are omitted. The user reads results, not process. This rule applies to all agent outputs — State Owner briefings, Interviewer summaries, Spec Writer diffs, Executor plans, Observer verdicts. Silence on a topic means no findings; agents don't explain what they didn't find.

**Token economy output rules.** Extends the concise output rule with specific constraints on how agents handle evidence and repetition. Each rule applies in specific contexts — agents select the appropriate technique for their output type:

- **Reference-first evidence.** When citing evidence (log entries, file contents, command outputs), agents include a reference ID and a short note — never the raw content. The viewer hydrates references into full excerpts for display. This prevents agents from pasting large blocks of context into their output. Applies to: State Owner briefings (cite file paths and line numbers), Observer verdicts (cite evidence IDs), Executor plans (reference spec sections by alias).
- **Delta-first output.** When describing changes, agents prefer diffs over full reprints. A spec update shows what changed, not the full section. A config change shows the delta, not the full config. A code comparison shows the relevant function, not the full file. This applies to all agent outputs: State Owner briefings, Spec Writer diffs, Executor plans, Observer verdicts.
- **No duplicate context.** Each entity (project identity, phase type, repo state, spec version) is described once in its canonical location. Subsequent references use IDs or shorthand. The State Owner briefing describes the repo state once; the Executor plan references it, not re-describes it. The spec version appears in the meta block once; agents don't restate it.
- **Stats-extraction for briefings.** Agent briefings use summary counts and categorized tallies over exhaustive details — "5 sections drifted, 3 code-ahead, 2 ready-to-build" over listing every aligned section. Interchange findings cards use severity counts over raw evidence dumps.
- **Structure-only for interchange.** Interchange documents emit schema (field names, types, relationships) without payload bodies. The viewer hydrates from source files on demand. This keeps interchange lightweight for WebSocket transmission.
- **Failure-focus for verdicts.** Observer verdicts report only what failed, with evidence. Passing checks emit a pass count — "4/4 passed" — not individual pass descriptions. When everything passes, the verdict is a single line.

**Structured interchange emission.** Every agent that produces user-facing output also emits a structured interchange document. The interchange is generated from the same analysis that produces the conversational output — agents don't do separate work for the two formats. The output depth tier determines the interchange's density: patch-tier operations emit minimal interchange (status and actions only), feature-tier operations emit standard interchange (findings and actions), architecture-tier operations emit comprehensive interchange (findings, actions, release, and detailed evidence). The interchange flows to the viewer via WebSocket as a single event per agent output. If the viewer is not running or not connected, the interchange is silently discarded — it is not queued or persisted.

**Rationalization-resistant instruction design.** Agent instruction files (the markdown files in `agents/` and `commands/`) are authored and maintained using a TDD-inspired methodology: pressure-test the instruction by running scenarios where the agent is likely to skip or shortcut (RED), write the instruction to address observed failure modes (GREEN), close rationalization loopholes by adding explicit counter-arguments for common bypass reasoning (REFACTOR). Each agent instruction file includes trigger-only descriptions in its frontmatter — what the agent is for and when to invoke it — with no workflow summaries that the model could follow as a shortcut instead of reading the full content (the Description Trap). Known rationalization patterns (e.g., "this task is too simple for the full process," "I already know enough to skip the scan," "the overhead isn't worth it for this change") are countered with explicit enforcement language using authority framing (institutional policy, not suggestions), commitment devices (requiring explicit acknowledgment before proceeding past gates), and scarcity framing (what is lost by skipping — context, accuracy, auditability — not just what is gained by following). During autonomous builds, a structural enforcement layer reinforces the instruction-level design: a prompt-based Stop hook evaluates Executor responses for premature completion signals and forces continuation when detected. Instructions counter rationalization through persuasion; the Stop hook fires at the decision point and is harder to override through context pressure. Two complementary layers, neither sufficient alone.

**Lesson management.** Build lessons follow five rules: (1) **Write triggers are side effects, not steps.** The Executor records a lesson as part of the existing failure/retry/rearchitect path — there is no "record lesson" step in the build loop. Experience question answers are recorded immediately after the user responds. (2) **Section alias tagging is mandatory.** Every lesson must be tagged with at least one section alias. The State Owner matches lessons to the current command by alias, so untagged lessons are invisible. (3) **Staleness is changelog-derived.** A lesson is stale when the changelog shows the referenced section was rewritten (not just tweaked) after the lesson's timestamp. A section that hasn't been rewritten keeps its lessons regardless of age. (4) **Deduplication by context.** If the Executor encounters the same failure pattern for the same section in a subsequent build, it updates the existing lesson's outcome and increments its confidence rather than appending a duplicate. (5) **Atomic compaction writes.** When the State Owner consolidates or compacts lessons, the operation writes to a temporary file then atomically renames to the target path, preventing corruption if interrupted mid-write. The same atomic write discipline applies to all memory store operations (global memory file compaction, consolidation, pruning).

**Memory authority model.** The global memory store distinguishes between two authority levels: **user-authored** entries (preferences the user explicitly stated, instructions the user gave, corrections the user made) and **agent-derived** entries (patterns the system inferred, digests the system wrote, lessons the system recorded). User-authored entries always win conflicts — if a user preference contradicts an agent-derived observation, the user preference governs. Agent-derived entries can be overridden or deleted by the user via the viewer's memory panel; user-authored entries can only be modified by the user. The authority tag (`user` or `agent`) is recorded on each entry. This separation prevents the system from gradually overriding explicit user preferences with its own inferred patterns.

**Memory lifecycle.** The global memory store (`~/.fctry/memory.md`) follows eight rules: (1) **Conversation digests are written at topic boundaries.** During evolve or init conversations, the system produces a compact structured summary (~300 tokens max each) scoped to each distinct topic shift — when the conversation moves from one section to another, or when a significant decision point is reached. Each digest covers: section aliases discussed, questions asked with answers, decisions made with rationale, and open threads requiring follow-up. This per-topic granularity (rather than one digest per session) produces smaller, more targeted digests that the selection algorithm can pick individually — a long evolve session covering three sections produces three digests, not one bloated one. Digests are appended to the memory store as a side effect, not a separate step. (2) **Decision records are written at choice points.** When the user resolves a drift conflict, answers an experience question, or makes a recurring choice, the decision is recorded with its context. On recall, the system proposes the remembered decision as the default option: "(1) [remembered choice] (your previous preference) (2) [alternative]." The user always confirms — decisions are never auto-applied. (3) **Decision supersession with temporal metadata.** When the State Owner encounters a new decision record that covers the same structural pattern as an existing one (same section alias, same decision type), the old record is marked superseded with a `superseded_by` reference linking to the replacement and a `superseded_at` timestamp. This creates a navigable chain: the user (or system) can trace the full decision history for a given pattern and answer "what was the decision at time T." Superseded records are preserved in the file for audit trail but excluded from active recall. Only the most recent decision for a given pattern is proposed as a default. (4) **Cross-project lessons require structural matching.** A lesson learned on project A is only surfaced on project B when the State Owner detects structural similarity — same section type, comparable tech stack, similar dependency pattern. The source project is always named when a cross-project lesson is surfaced. Broad injection is prohibited. (5) **User preferences sync to MEMORY.md.** When fctry observes a stable user preference (consistent across 3+ interactions), it writes it to Claude Code's auto-memory (`MEMORY.md`) so it persists in the standard Claude memory system. fctry also reads `MEMORY.md` at scan time and incorporates existing preferences into its briefings. (6) **Type-differentiated staleness.** Different memory types have different lifespans. Conversation digests are pruned when the changelog shows the referenced section was significantly rewritten since the digest's timestamp — the same rule as build lessons. Decision records are pruned when the structural pattern they cover no longer occurs (or when superseded). Cross-project lessons are never auto-pruned — they require either structural mismatch detection (the tech stack or section type they reference no longer exists in any active project) or explicit user deletion via the viewer. User preferences are pruned only when contradicted by newer observations. (7) **Token-budgeted injection with diversity.** The State Owner injects memory content into its briefing within a total budget of ~2000 tokens per scan. A fused multi-signal ranking algorithm scores each entry across three signals simultaneously — (a) section alias match to the current command (strongest signal), (b) recency, (c) memory type (decision records weighted highest, then cross-project lessons, then conversation digests, then preferences) — with scores combined via weighted sum rather than sequential filtering. After selecting the top-scoring entry, a diversity penalty diminishes subsequent entries from the same section, ensuring no single section dominates the injection window and entries from other relevant sections get representation. Entries that don't fit within the budget are silently excluded. This prevents memory from consuming unbounded context window space as the store grows while ensuring breadth of recall across sections. (8) **Consolidation.** When the State Owner detects that conversation digests or decision records about the same structural pattern have accumulated significant density (5+ entries about the same section type across 3+ projects), it consolidates them into a single cross-project lesson that captures the synthesized pattern. The original entries are marked as consolidated (preserved for audit, excluded from recall). This is the mechanism by which project-specific observations become cross-project knowledge — not through broad injection, but through observed density. The user can also delete entries directly via the viewer's memory panel.

**No keyword-based complexity heuristics.** When assessing task complexity, chunk verification depth, or pipeline scaling, the system uses structural signals — spec index metadata (section count, dependency graph, cross-reference density), State Owner briefings (readiness categories, drift severity), changelog recency, and estimated line-count deltas — never keyword matching against prompt text. Keyword-based scoring (weighting prompts by the presence of words like "auth," "database," or "refactor") is fragile, context-blind, and produces false confidence. A prompt mentioning "database" might be a one-line config change; a prompt mentioning "button" might require a cross-cutting architectural decision. Structural signals reflect what the system actually knows about the task's scope; keywords reflect what the user happened to type.

**Upgrade safety invariants.** Plugin version upgrades follow three rules: (1) **Additive only** — upgrades add missing fields, entries, and keys but never overwrite existing values. A user's custom .gitignore entries, non-default config settings, and authored frontmatter are always preserved. (2) **Cumulative single pass** — when a project skips multiple plugin versions, all changes are applied in one pass by comparing the project's `formatVersion` against the current plugin version. No intermediate version states are visible. (3) **Never lose data** — if the upgrade cannot determine whether a change is safe (e.g., a field exists with an unexpected type), it skips that change and notes it in the summary. The upgrade is a strict superset operation: the post-upgrade state contains everything from the pre-upgrade state plus additions. The migration hook handles both the legacy directory layout migration and ongoing format upgrades in a single synchronous pass — layout migration first (if needed), then format upgrade (if needed).

**Fail-open for infrastructure subsystems.** Infrastructure subsystems — the spec index, the status line, the viewer, the Observer, hooks, and staleness tracking — proceed without blocking when they encounter errors. A stale spec index returns results with a staleness hint rather than refusing to answer. A viewer that can't connect to WebSocket still renders from the last known state. An Observer that can't reach the browser falls back to API-only or file-only verification. The spec index rebuild failing doesn't block the State Owner from reading the markdown directly. This principle extends to all derived infrastructure: any subsystem that exists to accelerate or enrich the core workflow (spec → build → verify) must never become a gate that prevents that workflow from proceeding. Errors are surfaced as hints, warnings, or degraded capability — never as hard stops. The core workflow (reading the spec, running commands, building chunks) always works even when every infrastructure subsystem is broken.

**Hook error isolation.** Each plugin hook runs independently — if one hook fails (throws, times out, or exits non-zero), subsequent hooks still execute. A failed hook logs the error but never blocks the user's prompt or other hooks in the sequence. This ensures that a broken `dev-link-ensure.sh` doesn't prevent `migrate.sh` or `ensure-config.sh` from running, and a failed `detect-untracked.js` doesn't block the user's next action. Hook failures are silent to the user unless the hook's own output indicates a problem.

**Spec status lifecycle.** The spec's status field has three values (`draft`, `active`, `stable`) and transitions automatically. The Spec Writer transitions `draft` to `active` when `/fctry:init` completes successfully (spec and scenarios both written). The Spec Writer transitions `stable` to `active` when any `/fctry:evolve` changes the spec. The State Owner transitions `active` to `stable` when it detects full scenario satisfaction and no drift during a scan. The `/fctry:review` command detects stale statuses — a spec marked `stable` with drift, or `draft` with a complete spec and scenarios — and surfaces corrections as numbered recommendations. All transitions are automatic and require no user confirmation. There is no `building` status; build-in-progress is tracked in the build run state (`buildRun` in `.fctry/state.json`), which is transient and separate from the spec lifecycle.

**Execution priority resolution.** When the Executor builds a plan, it resolves execution priorities in order: (1) per-project `.fctry/config.json`, (2) global `~/.fctry/config.json`, (3) prompt the user. Per-project overrides are complete replacements, not merges — if a project has priorities set, the global priorities are ignored entirely for that project. The resolved priorities are shown in the build plan so the user always knows which priorities are active and where they came from.

**Priority-driven assessment depth.** The State Owner scales its readiness assessment granularity based on the section's kanban priority. **Now** sections receive claim-level assessment: each distinct behavior described in the spec text is individually verified against the code. A section with 30 of 40 behaviors implemented is marked `partial (30/40)` rather than falsely `aligned`. **Next** sections receive standard assessment (section-level comparison). **Later** sections receive coarse assessment (category-level — "code exists for this area"). This naturally allocates the token budget to the sections the user cares about most. Sections without a priority assignment (not in any kanban column) default to Next-level assessment.

**Partial readiness value.** When a Now section has claim-level assessment data showing incomplete implementation, it receives a readiness value of `partial` with a claim count (e.g., `partial 30/40`). This sits between `ready-to-build` (nothing built) and `aligned` (everything matches). The viewer renders partial readiness with a progress indicator on the kanban card and a distinct color in the ToC. The Executor treats partial sections as buildable — it builds only the missing claims rather than re-doing the entire section. The `partial` value appears only for sections with claim-level data (Now priority); sections assessed at coarser granularity use the existing vocabulary.

**Section readiness gating.** The Executor only includes sections with readiness of `aligned`, `ready-to-execute`, `partial`, or `ready-to-build` in build plans. Sections marked `draft` or `undocumented` are excluded and surfaced to the user with a recommendation to run `/fctry:evolve` before building. This prevents building from incomplete or stale spec sections.

**Evolve preservation rule.** When updating a spec, the Spec Writer changes only the sections affected by the update. Unaffected sections remain byte-for-byte identical. This prevents accumulation of unintended drift over multiple updates.

**Scenario holdout rule.** Scenarios are stored in a separate file from the spec. The coding agent (invoked during execute) never sees the scenarios during development. Scenarios are used only for post-hoc satisfaction evaluation. This prevents the agent from "teaching to the test."

**Plan approval rule.** The Executor never begins a build without user approval of the build plan. Plan approval is the single gate — once approved, the system executes autonomously. The user is not consulted for individual chunks, retries, or rearchitecting decisions. The system resurfaces only for experience-level questions where the spec is ambiguous or contradictory.

**Section stability rule.** Section numbers are stable across spec updates. If a section is added, it gets the next available number in its parent section. If a section is removed, its number is retired (never reused). Aliases can change if section titles change, but changes preserve recognizability (e.g., `#core-flow` → `#core-list-flow`, never `#section-2-2`).

**Changelog append-only rule.** The changelog is never edited or rewritten. Entries are always appended. This ensures the full history of spec evolution is preserved for agent analysis.

**Project instructions currency rule.** During `/fctry:review`, the Spec Writer audits CLAUDE.md against the current spec and codebase. Since CLAUDE.md is created at init, it always exists by the time review runs. The audit covers three layers independently. The evergreen layer is checked for: spec and scenario file paths, factory contract accuracy, command quick-reference completeness, `.fctry/` directory guide accuracy, and workflow guidance currency. The compact instructions layer is checked for: preservation of the correct file paths, inclusion of build checkpoint state, scenario satisfaction, active section and workflow step fields — the stable set that should always be present. The build layer (present only after execute has been run) is checked for: current build plan accuracy, convergence order currency, versioning rules, repo structure accuracy, and architecture notes. Drifted items from any layer are presented as numbered recommendations alongside spec drift. CLAUDE.md is not audited during other commands — only review.

**Drift detection signals.** The State Owner determines drift by comparing: (1) the spec's description of behavior, (2) the code's actual behavior (inferred via static analysis and recent commits), (3) the changelog (which sections changed recently), and (4) git log (when available — commit messages and timestamps provide additional evidence of code evolution). If the spec says X, the code does Y, and the changelog shows section X was updated more recently than the code, the spec is ahead. If the code was updated more recently (via git commits or file modification times), the code is ahead. If they diverged at similar times, it's a conflict requiring user resolution with numbered options.

**Drift severity.** Not all drift is equal. The State Owner assesses drift severity based on the scope and magnitude of divergence: how many files changed, how much behavior differs, and how central the affected section is to the user experience. Low-severity drift (a minor tweak in one file) produces a gentle indicator — it appears in `/fctry:review` but doesn't surface proactively. High-severity drift (multiple files diverging from a core section) surfaces prominently during `/fctry:evolve` and in the status line's untracked changes count. The system's response is proportional to the drift — small changes get small nudges, large divergences get urgent recommendations.

**Gap analysis grouping.** During `/fctry:review`, the gap analysis groups findings by action type rather than listing them in a flat sequence. **Drift** items (code ahead, diverged) appear first — these need a decision about which source is correct. **Unbuilt** items (spec ahead) appear separately — these simply need a build. The unbuilt section includes an aggregate count and a single recommendation to run `/fctry:execute`. Each item is numbered sequentially across both groups so the user can reference any item by number.

**Reference interpretation rule.** When incorporating a reference, the Researcher or Visual Translator describes it in experience language (what the user sees, does, feels), never in technical language (which framework it uses, how it's built). The Spec Writer incorporates the experience description, not the technical details.

**Tool validation fail-fast rule.** If a required tool is missing, the system stops immediately with a clear error message and installation instructions. It never attempts to run a command that will fail later due to missing dependencies.

**Scenario satisfaction scoring.** For each scenario, the State Owner evaluates satisfaction on a three-point scale: fully satisfied (the scenario plays out exactly as described), partially satisfied (the scenario mostly works but has gaps or rough edges), not satisfied (the scenario doesn't work or is missing implementation). The overall satisfaction score is the fraction of scenarios that are fully satisfied.

**Chunk failure handling.** If a build chunk fails (code doesn't compile, tests fail, scenario satisfaction doesn't improve), the Executor handles it autonomously — retrying with adjusted approaches, rearchitecting if necessary, or moving on to other chunks while the problem is reconsidered. The user is never interrupted for code failures. If a chunk remains unsatisfied after the Executor has exhausted its approaches, the experience report describes what's working and what isn't. Version tags are only created for successful chunks. The execution priorities shape failure behavior: speed-first priorities favor best-effort execution (move past failed chunks, report gaps at the end), reliability-first priorities favor fail-fast execution (pause dependent chunks early when a foundational chunk persistently fails rather than building on shaky ground), and token-efficiency-first priorities favor conservative retries with minimal context overhead.

**Build checkpoint persistence.** After each chunk completes, the Executor writes the build state to `.fctry/state.json` as a `buildRun` object. This includes: which chunks completed (with outcomes and the spec version they were built against), which are pending, the approved plan reference, and the position in the dependency graph. On the next `/fctry:execute` invocation, the Executor checks for an incomplete `buildRun` and offers to resume. Resuming skips completed chunks entirely. If the spec changed for a section covered by a completed chunk, the Executor flags it and asks whether to rebuild or keep the old result. The `buildRun` is cleared when the build completes or the user chooses to start fresh.

**Convergence milestone rule.** When a build plan spans multiple convergence phases (as defined in section 6.2), the Executor presents a milestone report at each phase boundary. Milestones are non-blocking — the build continues automatically unless the user explicitly stops it. The milestone report describes what the user can now try in experience language. If the user stops the build at a milestone (because something doesn't feel right), they can evolve the spec and resume the build from the milestone rather than starting over.

**Phase type inference.** Before proposing a build plan, the Executor characterizes the plan as one of five phase types based on the readiness distribution and character of included sections: **Capability** (many `ready-to-build` sections — the plan primarily adds new abilities the user hasn't been able to do before), **Hardening** (many `aligned` sections with unsatisfied scenarios — the plan primarily improves reliability and scenario coverage of things that mostly work), **Refactor** (sections that have been repeatedly updated with `undocumented` indicators — the plan primarily restructures for clarity and maintainability), **Integration** (many `undocumented` sections — the plan primarily reconciles components that exist but don't work together yet), or **Polish** (a mix of small gaps across many sections in the UX flow — the plan primarily tightens coherence and ergonomics). The phase type is agent-inferred, never user-declared — the user describes the experience; the agent characterizes the work. It appears at the top of the build plan to explain why the plan looks the way it does ("this plan focuses on stabilizing existing capabilities before adding new ones") and shapes how the release summary headline is framed at plan completion. The phase type is not stored; it is derived fresh each time a plan is generated.

**Observer non-blocking verification.** The Observer's post-chunk verification does not halt the build. If a verification check fails, the Observer reports the failure as a verification event in the activity feed and includes it in the verification audit trail. The Executor decides what to do with the failure: if it indicates a cosmetic issue (a color slightly off, a label truncated), the build continues. If it indicates a functional problem that suggests spec ambiguity (the feature doesn't behave as described), the Executor may escalate to an experience question for the user. Verification failure is information, not a stop signal — unless the Executor judges the failure significant enough to warrant user input. Transient check failures (network timeout, browser not ready) trigger a single retry before being reported; the Observer distinguishes "failed after retry" from "passed on retry" in its events.

**Context fidelity between chunks.** The Executor autonomously manages how much context flows from a completed chunk to a dependent chunk, choosing from four named fidelity modes: full transcript (everything), trimmed transcript (full conversation with tool result bodies stubbed — preserves reasoning, reclaims ~50% of token budget), structured summary (key decisions and outcomes), or fresh start with artifacts only (clean context). The decision is guided by execution priorities: token-efficiency-first favors trimmed transcript or fresh start, reliability-first favors full or trimmed transcript, speed-first favors structured summary. This is entirely an implementation decision — the user never configures context fidelity directly.

**Context as a managed resource.** The system treats the context window as a finite resource that must not degrade build quality. Build state persists through files (`.fctry/state.json`, git commits, CLAUDE.md compact instructions) rather than depending on conversation history. This means context compaction, session boundaries, or even full context clears result in a recoverable state, not a lost one. The Executor structures work to create natural context boundaries so each chunk operates with sufficient context regardless of build length. When a build requires unusual context management — a chunk too large for one context window, or a dependency chain that would accumulate excessive state — the Executor calls this out in the build plan alongside the parallelization and git strategy. Otherwise, context management is invisible: consistent build quality is the signal, not explicit context events.

**Compact instructions stability rule.** The `# Compact Instructions` section in CLAUDE.md is created at init with a static, evergreen set of preservation rules covering the stable concerns of any factory project: spec and scenario file paths, build checkpoint state, scenario satisfaction, active section and workflow step, and the current build plan. This section does not change per phase or per command — what matters for a factory project is stable. In unusual builds, the Executor may append phase-specific compact instructions and calls this out in the build plan. The compact instructions are audited during `/fctry:review` alongside the other CLAUDE.md layers.

**Version registry rules.** All version management flows through the version registry in `.fctry/config.json`. Each version type has declared increment rules and propagation targets. When a version changes, the system updates every declared target automatically — the user never edits version numbers in individual files. For pre-existing projects that lack a `config.json`, the migration hook auto-seeds the registry with default version types on the next command run, and any agent that needs to update the registry (e.g., the Spec Writer during evolve) creates the file with defaults if it's missing rather than skipping the version update.

**External version increment rules.** The external (project) version follows semver. Patch versions auto-increment with each successful chunk commit (0.1.1, 0.1.2, etc.). Minor versions are suggested when a full execute plan completes successfully. Major versions are suggested at significant experience milestones (e.g., all critical scenarios satisfied, a major capability section fully implemented). User approval is required for minor and major version bumps. Projects start at 0.1.0 on the first successful execute chunk.

**Internal version increment rules.** The spec version increments automatically on every `/fctry:evolve` that changes the spec. Other internal versions (API version, schema version, etc.) increment according to their declared rules — typically when the spec sections they track are modified.

**Version relationship rules.** Relationships govern how internal version changes ripple to the external version. Default relationships: a major spec version change suggests an external minor bump (the spec is significantly different, so the project is too). These defaults are universal — they apply to any project without configuration. The user can add project-specific relationships (e.g., "API version major bump → external minor bump") during evolve or execute.

**Version registry migration.** Projects created before the version registry existed may have a spec but no `.fctry/config.json`. The migration hook detects this condition and silently seeds the registry with default version types (external 0.1.0, spec 0.1) — the same defaults that `/fctry:init` creates for new projects. Any agent that needs to update the registry (the Spec Writer during evolve, the Executor during execute) also handles a missing `config.json` by creating it with defaults before proceeding. The user never sees a prompt or error about a missing registry; the system self-heals.

**Version propagation targets.** Each version type declares where it appears — specific files and locations (e.g., `package.json` → `version` field, spec frontmatter → `spec-version`). The Executor auto-discovers targets during the first build by scanning for files containing version strings and proposes additions to the registry. Declared targets are updated atomically when a version changes — either all targets update or none do, preventing partial propagation.

**Commit timing rule.** One commit is created per completed chunk, immediately after scenario satisfaction is confirmed. The commit message format is: "Implement [feature description] (satisfies scenario '[scenario name]')". If multiple scenarios are satisfied by one chunk, all are listed in the commit message. Git operations (branching, merging, conflict resolution) happen autonomously during the build — the agent manages the git strategy proposed in the plan to produce a clean, linear history on the main branch.

### 3.4 External Connections {#external-connections}

| Connects To | What Flows | Direction | If Unavailable |
|-------------|-----------|-----------|---------------|
| GitHub (via gh CLI) | Repository metadata, issues, PRs, code search results | Inbound | Researcher agent can't fetch GitHub references; user sees error |
| Firecrawl MCP | Web page content (crawled and structured) | Inbound | Researcher falls back to basic HTTP fetch (less structured) |
| Context7 / DeepWiki MCP | Documentation and API reference content | Inbound | Researcher falls back to basic HTTP fetch |
| Playwright MCP | Live browser screenshots for interactive references | Inbound | Visual Translator can't capture live screenshots; user must provide static images |
| Chrome DevTools MCP | DOM inspection and interaction pattern analysis | Inbound | Visual Translator can't analyze interactive behavior; limited to static visual interpretation |
| Rodney (headless Chrome via DevTools Protocol) | Browser automation for Observer verification — screenshots, element existence/visibility checks, JS evaluation, accessibility tree inspection, visual stability checks | Inbound | Observer degrades from full browser verification to API-only or file-only inspection |
| Surf (computed style inspection) | Computed styles, network capture, page state queries, semantic locators, annotated screenshots for Observer | Inbound | Observer uses Rodney alone or degrades to API-only inspection |
| OpenBrowser MCP (code-execution browser automation) | Single `execute_code` tool running Python in a persistent namespace with browser functions — token-efficient alternative to Rodney/Surf for Observer verification (3-6x fewer tokens than Playwright/Chrome DevTools MCP per benchmark, because the LLM writes extraction logic instead of receiving full page snapshots). Supports navigation, interaction, JS evaluation, and screenshot capture. | Inbound | Observer falls back to Rodney/Surf or degrades to API-only inspection |
| Showboat (executable markdown verification) | Verification audit trails — executable markdown that links evidence (screenshots, command outputs) to checks | Bidirectional | Observer produces verification results without structured audit trails |
| Peekaboo (macOS screen capture + GUI automation via MCP) | System-wide screen capture, UI element detection via Accessibility APIs, application interaction for Observer verification of non-browser surfaces (native apps, terminal UIs, system dialogs) | Inbound | Observer falls back to browser-only verification (Rodney/Surf) or degrades further to API-only or file-only inspection |
| Local filesystem | Spec, scenarios, changelog, references, interview state, codebase | Bidirectional | N/A — system cannot operate without filesystem access |
| SQLite (spec index) | Section content, metadata, readiness, changelog entries | Bidirectional | Auto-rebuilds from markdown spec. If database is missing or corrupt, agents fall back to reading the full spec file directly. |
| WebSocket (spec viewer) | Real-time spec updates, section highlights, change events | Outbound | Spec viewer doesn't update live; user must refresh manually |

fctry is distributed as an Agent Skill conforming to the Agent Skills specification (https://agentskills.io/specification), the open standard adopted by Claude Code, Codex, Copilot, Cursor, and 20+ platforms. Skill management infrastructure such as skillserver (https://github.com/mudler/skillserver) represents the emerging discovery and curation layer for the ecosystem fctry participates in. This positions fctry not as a standalone tool but as a participant in a standardized skill ecosystem where skills can be published, discovered, and composed across platforms.

### 3.5 Performance Expectations {#performance}

**Startup.** Any `/fctry` command should respond within 5 seconds of invocation (tool validation + State Owner briefing).

**Interview flow.** The Interviewer should respond to each user answer within 2-5 seconds with the next question. No pauses longer than 5 seconds except when the user is typing.

**Spec generation.** After the interview completes, the Scenario Crafter and Spec Writer should produce the spec and scenarios within 90 seconds. The user sees a progress indicator ("Generating spec...") so they know the system is working.

**Spec updates (evolve, ref).** Updates to specific sections should complete within 45 seconds. The user sees the diff summary immediately after.

**Gap analysis (review).** The State Owner's deep state assessment should complete within 30 seconds for a full scan (all sections require deep comparison) and proportionally faster when freshness and semantic stability filters eliminate sections — a review immediately after a spec write may scan only the sections not just authored. The gap analysis report appears immediately after. Embedding computation for new or changed sections adds negligible latency (under 100ms per section with a local ONNX model).

**Build plan generation (execute).** The Executor should propose a build plan within 60 seconds of starting. The user sees the plan as soon as it's ready.

**Chunk execution.** Build chunks vary in duration (5-40 minutes depending on complexity). Chunks execute sequentially in dependency order. The spec viewer's mission control and the terminal status line provide ambient progress feedback so the user knows the system is working without being interrupted.

**Async inbox processing.** Reference URLs submitted through the viewer inbox should be fetched and analyzed within 60 seconds. Evolve idea scoping and new feature assessment should complete within 30 seconds. The user sees processing status in the inbox (pending, processing, processed, error).

**Spec viewer rendering.** The spec should render in the browser within 1 second of opening the URL. Updates via WebSocket should appear within 500ms of the change happening on disk.

**Section navigation.** Clicking a section in the table of contents should scroll to that section within 200ms. Searching for a section (Cmd/Ctrl+K) should show results within 500ms.

**Overall feel.** The system should feel responsive and conversational. The user should never wait more than 5 seconds without feedback (progress indicator, partial result, or status message).

---

## 4. Boundaries and Constraints

### 4.1 Scope {#scope}

**This spec covers:**

- The seven fctry commands (init, evolve, ref, review, execute, view, stop) and the user's experience of each
- The interview process (questions, answers, multi-session support, state persistence)
- Spec generation, evolution, and navigation (sections, aliases, diffs, changelog)
- Reference incorporation (URLs, screenshots, designs) and interpretation in experience language
- Gap analysis (spec vs. code, drift detection, conflict resolution)
- Build planning and execution (scenario-driven chunking, plan-gated autonomous execution, build checkpoint and resume)
- The live spec viewer (real-time updates, section highlighting, change history, keyboard navigation)
- Tool validation and error handling
- Agent orchestration (handoff protocol, sequencing, execution order)

**This spec does NOT cover:**

- The internal implementation of agents (their code, prompts, or LLM interactions) — those are left to the coding agent
- The NLSpec v2 template structure itself (that's a reference document, not part of fctry's user experience)
- Collaboration features (multiple users editing the same spec, permissions, access control) — v1 is single-user
- Deployment, hosting, or cloud sync (fctry runs locally as a Claude Code plugin)
- Integration with external project management tools (Jira, Linear, etc.) — out of scope for v1
- Git repository initialization or management (fctry integrates with git during execute when a repository exists, creating commits and version tags, but doesn't require git or initialize repositories — works identically without git, minus version control operations)

### 4.2 Platform and Environment {#platform}

| Dimension | Constraint |
|-----------|-----------|
| Platform | macOS or Linux (where Claude Code runs) |
| Runtime | Claude Code plugin (installed via `.claude-plugin/plugin.json`) |
| Devices | Desktop/laptop — command-line interface + browser for spec viewer |
| Connectivity | Requires internet for LLM API calls and external reference fetching (Researcher, Visual Translator). Spec generation and viewing work offline if references aren't needed. |
| Accounts | Single-user, local-first. No authentication, no cloud accounts. |
| Storage | Local filesystem. All fctry-generated files live in `.fctry/` directory (spec, scenarios, changelog, references, state, cache). SQLite database (`.fctry/spec.db`) is a derived cache for structured spec access — the markdown file is always the source of truth and the database can be deleted and rebuilt at any time. Only `CLAUDE.md` is stored at the project root. |

### 4.3 Directory Structure and Git Tracking {#directory-structure}

All fctry-generated files in target projects are organized within a `.fctry/` directory at the project root. Only `CLAUDE.md` (created at init, enriched at execute) lives at the project root.

**Directory layout:**

```
project-root/
├── .fctry/
│   ├── spec.md              # The canonical spec document
│   ├── scenarios.md         # Holdout scenario set
│   ├── changelog.md         # Timestamped spec update log
│   ├── lessons.md           # Cross-session build learnings (cumulative, git-tracked)
│   ├── references/          # Visual references (screenshots, designs)
│   ├── .gitignore           # Ignores ephemeral/state files
│   ├── config.json          # Per-project config (execution priorities, version registry)
│   ├── state.json           # Workflow state (ephemeral, cleared on session start)
│   ├── spec.db              # SQLite cache of spec index (derived, auto-rebuilds)
│   ├── inbox.json           # Async inbox queue (ephemeral, survives across sessions)
│   ├── interview-state.md   # Paused interview state (deleted when interview completes)
│   ├── build-trace-*.md     # Per-build structured artifact (ephemeral)
│   ├── architecture.md      # Codebase structure snapshot (ephemeral, maintained by State Owner)
│   ├── tool-check           # Tool validation cache (ephemeral)
│   ├── plugin-root          # Plugin root marker (ephemeral)
│   └── viewer/              # Viewer ephemera (logs only — PID/port are global)
│       └── viewer.log
└── CLAUDE.md                # Project instructions (only fctry file at root)
```

**Git tracking:**

The `.fctry/.gitignore` file excludes ephemeral and state files from version control:

```
# Ephemeral state and cache
state.json
spec.db
tool-check
plugin-root
interview-state.md
inbox.json
build-trace-*.md
architecture.md
viewer/
```

Everything not listed in `.gitignore` is tracked in git: the spec, scenarios, changelog, references directory, and the `.gitignore` itself. State files, caches, and viewer ephemera are ignored.

**Global directory (`~/.fctry/`).** Cross-project state lives outside any single repository at `~/.fctry/`. This includes the project registry (`projects.json`), global config (`config.json`), viewer runtime files (`viewer.pid`, `viewer.port.json`), and the global memory store (`memory.md`). The memory store contains conversation digests, decision records, cross-project lessons, and user preference signals that span all projects. It is never committed to any repository — it's private to the user's machine.

**Gitignore evolution.** When new ephemeral file types are introduced in a plugin update (e.g., `build-trace-*.md` and `architecture.md` were added in v0.18.0), the upgrade mechanism appends the new entries to the existing `.gitignore` without disturbing existing entries or their order. Custom entries the user added manually are preserved. This prevents users from accidentally committing ephemeral files that didn't exist when their project was created.

**Migration:**

When fctry detects an old directory layout (files like `{project-name}-spec.md`, `{project-name}-scenarios.md`, or `{project-name}-changelog.md` at the project root, or `.fctry-interview-state.json`, or `fctry-state.json`), it automatically migrates on the first command invocation. The user sees a summary:

```
Migrated to .fctry/ directory structure:
- {project-name}-spec.md → .fctry/spec.md
- {project-name}-scenarios.md → .fctry/scenarios.md
- {project-name}-changelog.md → .fctry/changelog.md
- fctry-state.json → .fctry/state.json
- .fctry-interview-state.json → .fctry/interview-state.md
- Created .fctry/.gitignore

Migration complete. Continuing with your command...
```

Note: `references/` at the root is NOT auto-migrated because the name is too generic — many projects have their own `references/` directory. The Visual Translator uses `.fctry/references/` for new content; old content at `references/` is left in place.

Migration runs automatically on the first command invocation — no approval prompt, no confirmation dialog. The user sees the summary above and the command continues. Old files are removed after successful migration. If the `.fctry/` directory already exists with some files (e.g., from a partial previous migration), the system moves only the files that still live at the old location and leaves existing `.fctry/` files untouched.

When the project is a git repository, the migration uses `git mv` for tracked files so git records the move as a rename rather than a delete-and-add. This preserves file history (e.g., `git log --follow .fctry/spec.md` traces back through the rename). Untracked files are moved with a regular file move.

### 4.4 Hard Constraints {#hard-constraints}

**Claude Code plugin model.** fctry must operate as a Claude Code plugin invoked via slash commands. It cannot be a standalone CLI tool or web service. This is non-negotiable because the target user is already using Claude Code and expects plugins to integrate seamlessly.

**Experience language only.** The spec must describe what users see, do, and feel — never databases, APIs, or implementation details. This is the foundation of the Software Factory model and cannot be compromised. If the spec describes implementation, the coding agent has no creative freedom and the model breaks down.

**Scenario holdout separation.** Scenarios must live in a separate file from the spec and must not be visible to the coding agent during development. This is the core of the convergence model. If scenarios are in the spec, the agent can "teach to the test" and satisfaction becomes meaningless.

**Plan-gated execution.** The Executor must never begin a build without explicit user approval of the build plan. Plan approval grants autonomous execution authority — the system executes all chunks without further approval, handling failures and rearchitecting silently. The user is consulted only for experience-level questions (spec ambiguity or contradiction). This is non-negotiable because the plan defines the scope and cost of the build; once the user approves that scope, per-chunk gates add friction without adding value.

**State Owner first.** Every command must consult the State Owner before any other agent acts. This grounds all decisions in reality and prevents spec updates that ignore the current state of the codebase. Without this, the system becomes speculative and disconnected from reality.

**No code review by humans.** The spec and scenarios are the contract. No human reviews the code. The coding agent's implementation is validated solely through scenario satisfaction. This is the Software Factory model's defining constraint. If humans review code, the model collapses into traditional development.

**Credential safety during autonomous execution.** The Executor has broad filesystem access during builds. Credential paths (`~/.ssh/**`, `~/.aws/**`, `~/.gnupg/**`, `~/.config/gh/**`, `~/.git-credentials`, `~/.docker/config.json`, `~/Library/Keychains/**`) must be protected via deny rules in Claude Code settings. fctry recommends these at first run and checks for their presence. This is especially important because fctry's target user — non-coders — may not understand what the Executor can access. No single layer (deny rules, agent instructions, sandboxing) is sufficient alone; defense in depth is the model.

### 4.5 Anti-Patterns {#anti-patterns}

**Must not become an IDE.** fctry is not a code editor, debugger, or integrated development environment. It operates at the spec level, not the code level. It must never offer features like "edit this function" or "set a breakpoint."

**Must not become a project management tool.** fctry is not Jira, Linear, or Asana. It tracks scenarios and spec sections, but it doesn't track tasks, sprints, or team velocity. It's a single-user spec authoring and build orchestration tool, not a collaboration platform.

**Must not silently overwrite.** Every spec update must be recorded in the changelog. Every change must be shown to the user. The system must never silently rewrite sections without the user knowing.

**Must not assume on conflicts.** When spec and code disagree, the system must surface the conflict and ask the user to resolve it. It must never assume the spec is right or the code is right without evidence (recency signals, changelog).

**Spec viewer must remain read-only.** The viewer is for observing, not editing. All changes must happen through `/fctry` commands. If the viewer allowed editing, it would bypass the agent orchestration and lose the conversational, approval-gated nature of the system.

**Must not skip tool validation.** If a required tool is missing, the system must fail immediately with installation instructions. It must never attempt to run a command that will fail later due to missing dependencies, leaving the user confused about what went wrong.

---

## 5. Reference and Prior Art

### 5.1 Inspirations {#inspirations}

- **StrongDM Software Factory** (https://factory.strongdm.ai/) — The philosophical foundation. Introduced the model of code not written by humans, code not reviewed by humans, tests as scenarios, and satisfaction over pass/fail. fctry translates this model into a practical system for non-coders.

- **Spec Markdown** (https://spec-md.com/) — Edit annotation syntax (`{++add++}`, `{--remove--}`) for showing changes inline. Stable section IDs that survive renames. fctry borrows both patterns for the spec viewer's change history.

- **Log4brains** (https://github.com/thomvaill/log4brains) — Timeline-based ADR (Architecture Decision Record) viewer with a sidebar showing chronological history and diffs on click. fctry's spec viewer uses this pattern for the change history timeline.

- **Docsify** (https://docsify.js.org/) — Zero-build documentation site generator. Markdown renders directly in the browser with no build step. fctry's spec viewer uses this approach for simplicity and instant updates.

- **Notion's Import UX** — Drag-and-drop file upload, progress indicator, preview-before-commit pattern. Referenced in section 2.5 as inspiration for the bulk import flow (example reference incorporation).

- **CXDB** (https://github.com/strongdm/cxdb) — StrongDM's open-source AI Context Store. Its Turn DAG model (immutable actions forming a directed acyclic graph with branching) and design discussion of what agentic workloads need from context stores informed fctry's mission control enrichments: chunk lifecycle states, retry-as-branching visibility, typed activity events, and build run provenance.

- **Leash** (https://github.com/strongdm/leash) — StrongDM's agent governance system. Its observe-suggest-enforce progression model (Record → Shadow → Enforce), typed event streaming architecture (ring buffer with sequence numbers, bulk-send on connect, event type filtering), policy suggestion engine (observing behavior patterns and proposing specific rules from them), and Control UI patterns (live event feed with filtering, build log export) informed fctry's mission control event history, activity feed filtering, drift severity model, and spec update suggestion system.

- **Attractor** (https://github.com/strongdm/attractor) — StrongDM's DOT-based pipeline orchestration engine for multi-stage AI workflows. Its explicit dependency graph model (chunks as nodes, dependencies as edges), checkpoint-and-resume pattern (persisting pipeline state after each stage for crash recovery), context fidelity modes (managing context window usage across pipeline stages), manager loop pattern (supervisor monitoring child pipelines and rebalancing work), goal gates (must-succeed checkpoints before the pipeline can exit), and join/error policies (configurable failure behavior for parallel branches) informed fctry's build checkpoint and resume system, visual dependency graph in mission control, context fidelity as an autonomous execution decision, build coordination, convergence milestones, and execution-priority-driven failure behavior.

- **Claude Context OS** (https://github.com/Arkya-AI/claude-context-os) — A CLAUDE.md-based system for preventing context loss across multi-session Claude work. Its structured session handoff pattern (explicit manifests of what to load next session), uncertainty marking discipline (OPEN/ASSUMED/MISSING markers that prevent silent resolution of ambiguity), and "write state to disk, not conversation" principle informed fctry's interview state uncertainty markers, intermediate agent output persistence, and State Owner relevance manifests. Also cites research on LLM context limits (NoLiMa 32K token cliff, 5-10 active constraint cap) that validates fctry's progressive disclosure architecture and chunk boundary decisions.

- **ccproxy** (https://github.com/starbaser/ccproxy) — A Claude Code proxy for intelligent model routing via rule-based request classification. Its hook pipeline with error isolation (one hook failing never blocks others) informed fctry's hook error isolation rule.

- **DeepWiki** (https://github.com/AsyncFuncAI/deepwiki-open) — An AI-powered wiki generator that streams progressive content via WebSocket, filling in a wiki tree as sections generate. Its "structure visible immediately, content fills in progressively" pattern informed fctry's mission control section-fill visualization.

- **cc-devflow** (https://github.com/Dimon94/cc-devflow) — A Claude Code workflow system with 22 specialized sub-agents, a harness runtime with checkpoint/resume/events, session handoff documents, and quality gates. Its structured review frameworks (user story reconstruction from code, customer journey gap analysis) informed fctry's experience-level review analysis. Its session handoff pattern validated fctry's build checkpoint design.

- **CodeBoarding** (https://github.com/CodeBoarding/CodeBoarding) — An interactive codebase diagram generator using static analysis + LLM interpretation in a two-pass architecture. Its multi-level clickable diagrams and progressive detail disclosure informed fctry's mission control visualization.

- **AntV Infographic** (https://github.com/antvis/Infographic) — A declarative infographic engine with a fault-tolerant streaming DSL designed for AI output. Its per-project theme generation from a single seed color informed fctry's per-project visual identity in the viewer.

- **codebase-digest** (https://github.com/kamilstanuch/codebase-digest) — An AI-friendly codebase packer with 60+ structured analysis prompts. Its token counting as a project intelligence metric informed fctry's codebase size estimation.

- **gitin** (https://github.com/unclecode/gitin) — A minimal repo-to-markdown packer for LLM context, representative of a thriving tool category (Repomix, gpt-repository-loader, GitIngest) that validates "how context reaches the LLM" as a first-class experience concern. The mature version of this pattern is Repomix (https://github.com/yamadashy/repomix), which has Claude Code plugin integration and structured output formats.

- **Peekaboo** (https://github.com/steipete/Peekaboo) — A macOS CLI and MCP server for system-wide screen capture and GUI automation via Accessibility APIs. Its "see the whole screen" paradigm — where an AI agent observes any macOS window at the OS level rather than being confined to a browser tab — informed fctry's system-wide Observer verification tier. Its element-level assertion via Accessibility metadata (not DOM selectors) enables verification of any macOS application regardless of framework (SwiftUI, Electron, AppKit, web).

- **Release Steward concept** (internal reference, `references/ops-steward-agent-idea.md`) — A post-commit release guardrail agent for commit-to-main workflows. Its layered enforcement model (hard CI gates vs. model-based release intelligence), bounded-diff input discipline (25k char max, deterministic manifest reads), and Release Readiness Report artifact (version status, changelog status, risk flags, next action checklist) informed fctry's richer release summary at plan completion — the moment fctry already makes version decisions.

- **Phase Goals / FPOS concept** (internal reference, `references/phase-goals-fpos-spec.md`) — A two-part factory coherence system: Phase Goals (time-bounded experience states with optimization targets, phase types, and version arcs) and FPOS (Factory Packed Output Style — compressed plugin-ingestible transmission format with reflect/adopt self-improvement loop). Its phase type taxonomy, version-arc-as-experience-era framing, and session-friction-based self-improvement loop informed fctry's Executor-inferred phase types, convergence-to-version-arc mapping, and future `/fctry:reflect` direction.

- **cord** (https://github.com/kimjune01/cord) — A coordination protocol for trees of Claude Code CLI agents using SQLite state, spawn/fork context primitives, two-phase execution, typed results, and authority scoping. Its spawn vs. fork context model (isolated chunks with clean context vs. context-carrying chunks with injected predecessor results), experience questions as a named paused build state (question recorded, blocked chunks identified, state surfaced in viewer), build trace as a structured per-build artifact recording what actually happened, prescriptive error messages (errors that tell the agent exactly what to do next), and behavioral test suite direction (testing whether agents follow declared constraints under specific conditions) informed fctry's chunk context model, experience question entity, build trace entity, prescriptive error message rule, and agent behavioral compliance observability signal.

- **claude-code-cmv** (https://github.com/CosmoNaught/claude-code-cmv) — Git-like versioning for Claude Code sessions: snapshot, branch, trim, and visualize session trees. Its selective trimming pattern (stub tool result bodies while preserving reasoning chain, achieving ~50% context reclamation), empirical context composition data (tool results = 60-70%, conversation = 10-15%, system overhead = ~20k constant), and "trimmable" metric (how much context is dead weight vs. active reasoning) informed fctry's trimmed transcript context fidelity mode and validated the context attribution breakdown categories.

- **Superpowers** (https://github.com/obra/superpowers) — An agentic skills framework and software development methodology for Claude Code. Its rationalization-resistant instruction design methodology — TDD cycle applied to agent instructions (baseline failure without the instruction, write the instruction, close loopholes), explicit rationalization tables mapping common agent bypass attempts to counter-arguments, the Description Trap discovery (skill descriptions that summarize workflow cause the model to follow the description shortcut instead of reading the full content), and research-backed persuasion principles for instruction language (authority + commitment + scarcity as the effective combination for discipline-enforcing instructions, from Meincke et al. 2025, N=28k) — informed fctry's agent instruction authoring practices and sharpened the behavioral compliance observability signal with concrete prevention methodology.

- **rtk** (https://github.com/rtk-ai/rtk) — CLI proxy that reduces LLM token consumption by 60-90% via transparent hook-based command interception and 12 named filtering strategies. Its filtering taxonomy (stats-extraction, failure-focus, structure-only, deduplication), retrospective savings analysis (`rtk gain`), and full output recovery on failure (tee) informed fctry's token economy output taxonomy and retrospective context efficiency reporting in experience reports. Its hook-first integration (99.5% reduction in CLAUDE.md footprint vs. legacy injection) validated fctry's progressive disclosure architecture.

- **claude-devtools** (https://github.com/matt1398/claude-devtools) — A retrospective session analysis and visualization tool for Claude Code. It reconstructs session logs from disk and renders them as interactive dashboards with context window composition across 7 categories, compaction visualization, tool inspection (syntax-highlighted reads, inline edit diffs, terminal-styled bash output), nested subagent trees, and cross-session search. Its semantic step taxonomy (classifying tool calls as file_read, code_edit, command_exec, search, agent_spawn), compaction boundary visualization (showing when and why context compressed), per-turn context attribution breakdown (categorized split of what occupies context), named event alerting (surfacing important events above noise via trigger rules), and tool-specific card rendering (type-appropriate visual treatment for each tool kind) informed fctry's interchange semantic step types, compaction boundary events in the activity feed, context health attribution breakdown, named event alerts in mission control, and tool-specific interchange card rendering. Its incremental append-only log parsing pattern and waterfall visualization schema were noted as future directions for build trace streaming and DAG interchange data shape.

- **skillserver** (https://github.com/mudler/skillserver) and the **Agent Skills specification** (https://agentskills.io/specification) — A centralized skills database for AI agents implementing the Agent Skills specification (agentskills.io), an open standard (December 2025) adopted by Claude Code, Codex, Copilot, Cursor, and 20+ platforms. The Agent Skills spec defines skills as directories with a SKILL.md entry point plus optional scripts/references/assets subdirectories, organized in three-tier progressive disclosure (metadata, instructions, resources). fctry's own plugin structure — SKILL.md entry point, commands/*.md per-command, agents/*.md per-agent, references/ on demand — already conforms to this standard; the alignment is structural. skillserver represents the emerging infrastructure layer for skill management, discovery, and sharing across the AI agent ecosystem. Its dual-interface architecture (MCP server for agent consumption, HTTP/WebUI for human browsing) validates fctry's bidirectional observation approach in the spec viewer (WebSocket for agents, browser for humans).

- **OpenBrowser** (https://github.com/billy-enrizky/openbrowser-ai) — An AI-powered browser automation framework using a single `execute_code` MCP tool where the LLM writes Python in a persistent namespace with browser functions (navigate, click, evaluate JS, screenshot). Benchmarked at 3-6x fewer tokens than Playwright MCP (50K vs 159K) and Chrome DevTools MCP (50K vs 300K) for equivalent browser tasks, because it returns only extracted data rather than full page snapshots. Its Claude Code plugin ships an MCP server bundled via `.mcp.json`, 5 skill files as workflow recipes (web-scraping, form-filling, e2e-testing, page-analysis, accessibility-audit), and a persistent namespace pattern where variables survive across tool calls. Its single-tool code-execution architecture and token efficiency data informed fctry's token-efficient browser verification capability for the Observer agent, and its bundled MCP server pattern was noted as a potential approach for shipping Observer browser tools within the fctry plugin itself.

- **Dispatch** (https://github.com/bassimeledath/dispatch) — A Claude Code skill that turns a single session into a lightweight orchestrator by fanning out coding tasks to background workers, each with a fresh context window. Its dispatcher-worker architecture (the orchestrator plans and monitors but never does work itself), checklist-as-state pattern (the plan markdown file is both instruction set and progress tracker — `[x]`/`[ ]`/`[?]`/`[!]` — with no separate state database), filesystem-based IPC with atomic writes and timeout fallback (workers write questions to numbered files; if no answer arrives within 3 minutes, the worker dumps full reasoning context to `context.md` before exiting gracefully so a new worker can resume), multi-model routing per task (different models for different task types based on complexity, with auto-discovery), and "cognitive load transfer" framing (naming the user benefit as "the dispatcher carries the cognitive load" rather than describing system capabilities) informed fctry's understanding of background-worker execution as a future evolution path for chunk parallelism, enriched the build checkpoint with reasoning context preservation on interruption, and sharpened the autonomous execution value proposition.

- **GitNexus** (https://github.com/abhigyanpatwari/GitNexus) — A knowledge-graph-powered code intelligence engine that indexes codebases into a graph database (KuzuDB) and exposes the graph to AI agents via MCP tools. Its quantified staleness tracking with prescriptive recovery hints (not just "stale" but "3 versions behind, rebuild recommended"), self-guiding tool responses that append next-step hints to query results (reducing agent reasoning steps), precomputed structural intelligence via Leiden community detection and process tracing (dependency graphs computed at index time, not query time), and fail-open infrastructure principle (every subsystem degrades gracefully rather than blocking the core workflow) informed fctry's spec index staleness tracking, self-guiding tool responses during builds, precomputed section dependency graph for chunk planning, and fail-open rule for infrastructure subsystems. Its PreToolUse hook for automatic context injection, global multi-repo registry with lazy connection pooling, auto-generated AI context files (CLAUDE.md/AGENTS.md), and skill-based progressive disclosure validated fctry's existing patterns.

- **"My actual real Claude Code setup that 2x my results"** (https://www.reddit.com/r/ClaudeCode/comments/1rbkspc/) — A practitioner's Claude Code setup built around three interlocking mechanisms: weighted complexity scoring that routes prompts to different workflow depths via UserPromptSubmit hooks, hooks-over-CLAUDE.md for critical instruction persistence (multiple commenters independently confirmed CLAUDE.md instructions degrade as context fills, while hooks inject fresh every message), and a cross-session reflections loop where the system records mistakes and codebase-specific patterns, injecting them into subsequent sessions. A commenter (u/entheosoul) contributed the "earned autonomy" framing — splitting agent work into investigation and action phases separated by a confidence gate. fctry adopts the hooks-for-enforcement principle (already implemented via detect-untracked, workflow validation, version checks) and the plan-gated-then-autonomous model (validated by Anthropic's agent autonomy research). fctry adapts the reflections loop as cross-session build learnings (adopted into `#capabilities` 3.1) and complexity-aware verification depth (adopted into `#rules` 3.3). fctry rejects keyword-based complexity scoring — structural signals (spec index, State Owner briefings, section metadata) are richer and less fragile (adopted as anti-pattern into `#rules` 3.3).

- **ATM (Agent Team Manager)** (https://github.com/DatafyingTech/Claude-Agent-Team-Manager) — A Tauri v2 desktop application providing a visual org-chart canvas for designing and deploying Claude Code agent teams. Users build hierarchies of teams, agents, sub-agents, and skills on a drag-and-drop canvas, configure variables that cascade top-down, then one-click deploy a compiled "primer" (all context bundled into a single markdown doc) to Claude CLI. Also supports sequential pipeline chaining (Project Manager nodes that chain teams with per-step objectives and file-based handoff summaries) and OS-level cron scheduling. Reads and writes standard Claude Code config files with zero lock-in. Its deployment primer compilation (frontloading all context to eliminate discovery overhead) validates fctry's State Owner briefing + build plan approach. Its file-based handoff summaries between pipeline steps validate fctry's build trace and state file chunk handoffs. Its file ownership coordination rule for parallel agent work (distinct files per agent to prevent merge conflicts) reinforces the Executor's chunk dependency planning. Its sibling team awareness in deployment primers (each team knows about other teams) validates cross-chunk awareness in build plans. The visual canvas-as-configuration surface is architecturally interesting not as a replacement for spec-as-truth, but as a potential two-way editing surface where the canvas is a UI for authoring the spec itself — the spec stays canonical while the viewer becomes a bidirectional editing surface (queued as an evolve idea for `#spec-viewer`).

- **Zep** (https://github.com/getzep/zep) — A long-term memory service for AI assistants powered by Graphiti, a temporal knowledge graph engine. Its bi-temporal fact model (valid_at/invalid_at/expired_at metadata enabling "what did we believe at time T" queries), Reciprocal Rank Fusion for multi-signal memory ranking (combining semantic similarity, recency, and type priority via fused scoring rather than sequential filtering), MMR (Maximal Marginal Relevance) diversity selection to prevent recall from over-representing one topic, sliding window episode ingestion (per-topic-shift rather than per-session memory boundaries), and LLM-judged deduplication for entity consolidation informed fctry's temporal supersession metadata, fused multi-signal injection ranking with diversity penalty, and per-topic conversation digest scoping. Three patterns skipped: community detection via graph clustering (requires graph DB — fctry's flat markdown store is intentional), rolling entity summaries (fctry's batch consolidation threshold is correct for markdown-first), and group-scoped memory isolation (fctry's global store with structural-match gating is the right model for cross-project knowledge).

- **Trail of Bits claude-code-config** (https://github.com/trailofbits/claude-code-config) — An opinionated configuration distribution for standardizing Claude Code across an engineering organization. Its anti-rationalization Stop hook (prompt-based evaluator that detects premature completion signals and forces continuation — structural enforcement at the decision point, harder to override than system-prompt instructions), credential deny-rule sandboxing (explicit Read deny rules for SSH keys, cloud credentials, Docker configs, crypto wallets — defense in depth for autonomous execution), and turn/context budget management (explicit threshold gates — at 75% capacity, stop starting new work and complete cleanly) informed fctry's Stop hook enforcement during autonomous builds, credential safety recommendations at first run, and context budget gating in the Executor. Its prescriptive PreToolUse blocking hooks, layered CLAUDE.md distribution, CI-as-source-of-truth, audit logging, multi-agent review fanout, and self-installing config command were noted as validating existing fctry patterns (prescriptive errors, three-layer CLAUDE.md, build traces, Observer verification, dev-link self-healing). Its "replace, don't deprecate" philosophy and package manager enforcement were skipped as conflicting with fctry's migration support and agent authority model.

- **semantic-navigator** (https://github.com/Gabriella439/semantic-navigator) — A terminal tool that embeds a repository's files, clusters them by meaning via spectral clustering (Zelnik-Manor & Perona adaptive sigma, eigengap heuristic for cluster count), recursively subdivides until leaf groups have ≤20 items, labels each cluster with an LLM using sibling-aware context and structured "homework" fields, and renders the result as a browsable semantic tree. Its sibling-aware labeling pattern (all siblings in one LLM call so each label is distinctive relative to its peers) informed fctry's sibling-aware structured output rule. Its structured intermediate reasoning ("homework" fields computed but not persisted — `overarchingTheme` + `distinguishingFeature` + `label`) informed fctry's intermediate reasoning discipline for concise agent outputs. Its "browse by meaning" paradigm (embedding-based grouping as an alternative to structural hierarchy) informed fctry's semantic ring in dependency neighborhood diagrams, semantic ranking in viewer search, and semantic dependency discovery in the State Owner's targeted scans. Its content-hash embedding cache with per-model invalidation, small-repo bypass, and recursive hierarchical depth adaptation were noted as validating existing fctry patterns. Its spectral clustering algorithm, eigengap heuristic, and async/semaphore I/O were skipped as solving problems fctry doesn't have (declared hierarchy, small section count, different runtime model).

- **visual-explainer** (https://github.com/nicobailon/visual-explainer) — A Claude Code skill that generates interactive HTML diagrams, flowcharts, and visual explainers from natural language using Mermaid.js and multi-page HTML. Its fact-sheet verification checkpoint (cross-checking generated content against source material before presenting), depth-tiered card presentation (overview → detail → deep-dive), Mermaid CSS class collision guard (namespaced classes preventing style bleed), and diagram zoom controls for complex visualizations informed fctry's Observer fact-sheet verification, viewer depth-tiered section content, Mermaid CSS namespacing, and diagram pan/zoom controls.

- **contrail** (https://github.com/strangeloopcanon/contrail) — A flight recorder for AI coding sessions that captures structured traces of tool calls, decisions, reasoning, and errors for post-hoc analysis and learning. Its learning lifecycle with candidate→active maturation (preventing one-off flukes from becoming permanent lessons), confidence scoring on learnings (incrementing on confirmation, decrementing on contradiction), user-editable vs agent-derived memory separation (user preferences always win conflicts), and atomic compaction writes (temp file → atomic rename to prevent corruption) informed fctry's build lesson maturation lifecycle, confidence scoring, memory authority model, and atomic write discipline for memory operations.

- **value-realization** (https://github.com/Done-0/value-realization) — A structured interview framework for diagnosing user value perception through progressive questioning. Its value timeline question ("When did this go from interesting to essential?") and value perception prompt ("Describe this to someone else in one sentence") informed fctry's Interviewer question toolkit for surfacing the user's mental model and identifying what actually matters.

- **arifOS** (https://github.com/ariffazil/arifOS) — A constitutional AI governance kernel defining principles, permissions, and self-assessment for AI agent behavior. Its minimal/balanced/maximal plan framing (presenting three scope variants at different ambition levels) and reality index (system self-assessment of its own understanding confidence) informed fctry's plan scope framing and State Owner reality index.

- **charlotte** (https://github.com/TickTockBent/charlotte) — An MCP server for token-efficient browser automation using DOM analysis and accessibility trees instead of screenshots. Its tiered observation detail (summary → structural → full DOM, picking the cheapest level that answers the question) and structural diffing for verification (comparing DOM structure rather than pixels) informed fctry's Observer tiered observation and structural diffing verification.

### 5.2 Experience References {#experience-references}

**CXDB — Mission control enrichments** (via `/fctry:ref`, 2026-02-16). Source: https://github.com/strongdm/cxdb. The cxdb design discussion of what agentic workloads need from context stores — immutable action tracking, branching on retry, typed events, and run-level provenance — inspired four patterns adopted into fctry's build experience: (1) explicit chunk lifecycle states visible in mission control (planned, active, retrying, completed, failed), (2) retry visibility showing attempt counts instead of invisible retries, (3) typed activity events in the mission control feed (agent started section, chunk retrying, scenario evaluated) replacing generic file-change notifications, and (4) the build run as a first-class entity connecting the approved plan to live progress and the experience report.

**Leash — Event streaming, drift severity, and spec suggestions** (via `/fctry:ref`, 2026-02-16). Source: https://github.com/strongdm/leash. Leash's agent governance architecture — typed event streaming with ring buffers and sequence numbers, a policy suggestion engine that mines observed behavior to propose specific rules, and a three-mode progression (observe, shadow, enforce) — inspired seven patterns adopted into fctry: (1) event history on reconnect so users joining a build mid-progress see everything that's happened, (2) activity feed filtering by event type to manage noise during parallel builds, (3) drift severity assessment that makes the system's response proportional to divergence magnitude, (4) external tool call visibility in mission control (MCP tool invocations as typed events), (5) build log export for post-build review and sharing, (6) the observe-evolve-build progression made explicit in the review flow, and (7) spec update suggestions generated from observed code changes rather than generic drift flags.

**Attractor — Build pipeline patterns** (via `/fctry:evolve`, 2026-02-17). Source: https://github.com/strongdm/attractor. Attractor's DOT-based pipeline orchestration architecture — explicit dependency graphs, checkpoint-and-resume after each pipeline stage, context fidelity modes across stages, a manager loop pattern that monitors and rebalances child pipelines, goal gates as must-succeed checkpoints, and configurable join/error policies for parallel branches — inspired six patterns adopted into fctry: (1) build checkpoint and resume so interrupted builds survive session death and pick up where they left off, (2) a visual dependency graph in mission control rendering the build plan as an interactive DAG with lifecycle-state animations, (3) context fidelity as an autonomous Executor decision guided by execution priorities, (4) build coordination where the Executor monitors overall build health and rebalances work across the dependency graph, (5) convergence milestones as non-blocking validation points at phase boundaries, and (6) execution-priority-driven failure behavior (speed-first = best-effort, reliability-first = fail-fast).

**Claude Context OS — Session resilience and uncertainty tracking** (via `/fctry:ref`, 2026-02-17). Source: https://github.com/Arkya-AI/claude-context-os. A CLAUDE.md-only system (no runtime code) for preventing context loss across multi-session Claude work. Its structured session handoff pattern, explicit uncertainty markers, and "write to disk, not conversation" discipline — informed by 9 peer-reviewed papers on how LLMs process system prompts — inspired three refinements adopted into fctry: (1) OPEN/ASSUMED/MISSING uncertainty markers in interview state so paused interviews preserve what's settled vs. what's ambiguous, (2) intermediate agent output persistence to the state file during spec evolution workflows (init, evolve, ref) so that mid-workflow context compaction doesn't lose the State Owner's briefing or the Interviewer's captured answers, and (3) a relevance manifest in the State Owner's briefing — a scoped list of files and sections that matter for the current command — so that session resumption and subsequent agents can load targeted context rather than scanning everything. Also validated fctry's existing progressive disclosure architecture (hub-and-spoke matches their 7-rule cap finding from working memory research), disk-first state persistence (state.json, buildRun, checkpoint/resume), and command-level session segmentation.

**ccproxy, DeepWiki, cc-devflow, CodeBoarding, AntV Infographic, codebase-digest — Progressive visualization, resilient execution, and structured analysis** (via `/fctry:ref`, 2026-02-19). Sources: six GitHub repos explored in a batch `/fctry:ref` session. Three cross-cutting themes were identified and five patterns adopted into fctry: (1) hook error isolation — each plugin hook runs independently so one failure never cascades (from ccproxy's error-isolated hook pipeline), adopted into `#rules` (3.3). (2) Progressive section fill in mission control — the full spec structure is visible from the start, with sections transitioning visually as the build brings them to life (from DeepWiki's streaming wiki tree and CodeBoarding's multi-level diagrams), adopted into `#spec-viewer` (2.9). (3) Token-aware project sizing — the State Owner estimates codebase size in context-relevant terms so the Executor can calibrate chunk granularity (from codebase-digest's token counting), adopted into `#execute-flow` (2.7) and `#entities` (3.2). (4) Per-project visual identity — each project in the multi-project viewer gets a distinct accent color for instant orientation when switching projects (from AntV Infographic's seed-based theme generation), adopted into `#spec-viewer` (2.9). (5) Experience-level review analysis — the State Owner reconstructs experience stories from code and compares them to the spec, catching capability drift that structural comparison misses (from cc-devflow's structured review frameworks and codebase-digest's analysis prompt library), adopted into `#review-flow` (2.6).

**Peekaboo — System-wide Observer verification** (via `/fctry:ref`, 2026-02-19). Source: https://github.com/steipete/Peekaboo. Peekaboo's macOS-native screen capture and GUI automation via Accessibility APIs — capturing any window at the OS level, detecting UI elements without DOM access, and handling system dialogs programmatically — inspired four patterns adopted into fctry: (1) a system-wide Observer verification tier above the existing browser-only full mode, making any macOS application an observable surface (adopted into `#observability` 6.3), (2) Peekaboo as an external connection with graceful degradation to browser-only when unavailable (adopted into `#external-connections` 3.4), (3) system dialog handling during autonomous builds so blocking dialogs don't stall execution (adopted into `#execute-flow` 2.7), and (4) application-level and screenshot surface distribution as new observability signals.

**Release Steward + Phase Goals / FPOS — Release intelligence, phase types, and self-improvement** (via `/fctry:ref`, 2026-02-19). Sources: `references/ops-steward-agent-idea.md`, `references/phase-goals-fpos-spec.md`. Two concept documents exploring factory extensions. Five patterns adopted into fctry: (1) richer release summary at plan completion — when suggesting a version bump, the Executor now generates a release summary with experience-language headline, user-visible highlights, affected sections, and migration notes (adopted into `#execute-flow` 2.7 and `#details` 2.11). (2) Convergence phases as version arcs — each convergence phase maps to a minor version arc with narrative release notes that tell the experience story (adopted into `#convergence-strategy` 6.2). (3) Executor-inferred phase type — the Executor characterizes each build plan as Capability, Hardening, Refactor, Integration, or Polish based on the readiness distribution, explaining why the plan looks the way it does (adopted into `#rules` 3.3 and `#execute-flow` 2.7). (4) Release summary format — headline, highlights, deltas, and migration notes (adopted into `#details` 2.11). (5) Future self-improvement loop — a `/fctry:reflect` direction that analyzes session friction and proposes system improvements (noted in `#convergence-strategy` 6.2 and `#capabilities` 3.1).

**cord — Chunk context, experience questions, build traces, and behavioral testing** (via `/fctry:ref`, 2026-02-20). Source: https://github.com/kimjune01/cord. A coordination protocol for trees of Claude Code agents using SQLite state and typed results. Five patterns adopted into fctry: (1) chunk context model — chunks are either isolated (clean context, no predecessor state) or context-carrying (injected results from completed predecessors), giving the Executor an explicit vocabulary for how context flows through the build graph (adopted into `#execute-flow` 2.7). (2) Experience questions as named build state — when a spec ambiguity requires human input, the build enters a formal paused state with the question recorded, blocked chunks identified, and state surfaced in the viewer as a pulsing indicator (adopted into `#execute-flow` 2.7 and `#error-handling` 2.10). (3) Build trace as a first-class entity — a structured per-build artifact recording what actually happened (chunks attempted, retries, context decisions, experience questions asked), enabling post-build analysis and future self-improvement (adopted into `#entities` 3.2). (4) Prescriptive error messages — every error tells the agent or user exactly what to do next, not just what went wrong (adopted into `#rules` 3.3). (5) Agent behavioral compliance as an observability signal — tracking whether agents follow declared constraints (token economy, interchange emission, experience language) under specific conditions, catching constraint drift that functional tests miss (adopted into `#observability` 6.3).

**claude-code-cmv — Selective trimming, context composition data, and trimmed transcript fidelity** (via `/fctry:ref`, 2026-02-20). Source: https://github.com/CosmoNaught/claude-code-cmv. A CLI tool and TUI dashboard that brings git-like versioning to Claude Code sessions — snapshot, branch, trim, and visualize session trees. Three patterns adopted into fctry: (1) trimmed transcript as a named context fidelity option — full conversation with tool result bodies stubbed (>500 chars), preserving the reasoning chain and decisions while reclaiming ~50% of token budget, positioned between full transcript and structured summary in the fidelity spectrum (adopted into `#agent-decides` 6.4 and `#entities` 3.2). (2) Empirical context composition baselines — tool results = 60-70% of context, conversation = 10-15%, thinking signatures = 15-20%, system overhead = ~20k tokens constant — validating fctry's context attribution breakdown categories and informing what "healthy" vs "stressed" context looks like (validates `#spec-viewer` 2.9 and `#observability` 6.3). (3) Token economy output taxonomy — explicit named strategies for when each token economy rule applies (stats-extraction for briefings, structure-only for interchange, failure-focus for verdicts), making the existing three rules more actionable for agents (adopted into `#rules` 3.3). Two patterns noted but not adopted: named context checkpoints (relevant to user-facing session management, not autonomous builds) and session export/import (out of scope for plugin architecture).

**rtk — Retrospective context efficiency and filtering taxonomy validation** (via `/fctry:ref`, 2026-02-20). Source: https://github.com/rtk-ai/rtk. A Rust CLI proxy that intercepts dev commands and compresses output before it enters context, with 12 named filtering strategies, SQLite-based savings tracking, and retrospective analysis. Two patterns adopted into fctry: (1) retrospective context efficiency in experience reports — after a build completes, the experience report includes a context health summary (whether compaction fired, which sections drove pressure, whether fidelity settings were adequate), following rtk's "retrospective value proof" principle of surfacing efficiency data when the user asks rather than during work (adopted into `#observability` 6.3). (2) Token economy output taxonomy — rtk's 12 named filtering strategies (stats-extraction, failure-focus, structure-only, deduplication) validated and sharpened fctry's token economy rules with explicit context-to-strategy mappings (adopted into `#rules` 3.3, jointly with CMV findings). Three patterns noted but not adopted: transparent hook-based command interception (validates fctry's existing hook-first architecture but no spec change needed), persistent cumulative savings tracking (fctry monitors per-build context, not cross-session ROI), and economic cost mapping (implementation-level concern, not experience-level).

**claude-devtools — Semantic step taxonomy, compaction boundaries, context attribution, event alerting, and tool-specific rendering** (via `/fctry:ref`, 2026-02-20). Source: https://github.com/matt1398/claude-devtools. A retrospective session analysis tool for Claude Code that reconstructs session logs into interactive dashboards with context window composition, compaction visualization, and tool inspection. Seven patterns identified, five adopted and two noted: (1) semantic step taxonomy — tool calls within interchange cards are classified as file_read, code_edit, command_exec, search, agent_spawn, or external_tool, with type-appropriate rendering (inline diffs for edits, syntax highlighting for reads, terminal style for commands) (adopted into `#spec-viewer` 2.9 and `#entities` 3.2). (2) Compaction boundary events — when auto-compaction fires during a build, the activity feed shows it as a typed event with build state preservation confirmation (adopted into `#spec-viewer` 2.9). (3) Named event alerting — important events (retry threshold exceeded, verification failure, context compaction) are pinned with visual accent in the activity feed, surfacing above noise without requiring the user to filter (adopted into `#spec-viewer` 2.9). (4) Per-chunk context attribution breakdown — the context health indicator expands on hover to show a categorized split (spec content, code, tool output, agent state, conversation) instead of just an aggregate percentage (adopted into `#spec-viewer` 2.9 and `#observability` 6.3). (5) Tool-specific card rendering in interchange — different visual treatments per tool category, driven by semantic step type in the interchange payload (adopted into `#spec-viewer` 2.9). (6) Incremental append-only build trace parsing — writing trace entries during the build rather than constructing the full trace at completion, enabling live streaming and partial trace reads from interrupted builds (noted as future direction in `#convergence-strategy` 6.2). (7) Waterfall visualization schema — concrete type shape for DAG interchange fields (start time, duration, dependencies, lifecycle state) enabling direct rendering from interchange data (noted in `#entities` 3.2).

**OpenBrowser — Token-efficient browser verification via code-execution architecture** (via `/fctry:ref`, 2026-02-22). Source: https://github.com/billy-enrizky/openbrowser-ai/tree/main/plugin. A Claude Code plugin shipping a single `execute_code` MCP tool where the LLM writes Python in a persistent namespace with browser functions, benchmarked at 3-6x fewer tokens than Playwright MCP and Chrome DevTools MCP for equivalent tasks. Two patterns adopted into fctry: (1) token-efficient browser verification — the Observer can use a code-execution browser architecture that returns only extracted data instead of full page snapshots, achieving dramatically lower token cost for verification workflows (adopted into `#capabilities` 3.1 and `#external-connections` 3.4 as OpenBrowser MCP). (2) Persistent namespace for multi-step verification — variables survive across tool calls, enabling the Observer to build up verification state across steps (navigate, extract, compare, screenshot) without re-establishing context each time (adopted into `#capabilities` 3.1). One pattern noted but not adopted: bundled MCP server via `.mcp.json` in the plugin directory — fctry could potentially ship its own browser MCP server to eliminate the dependency on user-installed browser tools, but this is an implementation concern for the Executor to decide.

**skillserver + Agent Skills specification — Ecosystem positioning and plugin format standard** (via `/fctry:ref`, 2026-02-22). Sources: https://github.com/mudler/skillserver, https://agentskills.io/specification. The Agent Skills specification (December 2025) is the open standard adopted by Claude Code, Codex, Copilot, Cursor, and 20+ platforms for defining AI agent skills. It specifies a SKILL.md-based directory structure with YAML frontmatter, three-tier progressive disclosure (metadata in frontmatter, instructions in SKILL.md body, resources in subdirectories), and a clear relationship to MCP ("MCP gives agents tools; skills teach agents what to do with them"). fctry's plugin format already conforms to this standard: SKILL.md entry point maps to the skill root, commands/*.md per-command maps to the instruction tier, agents/*.md per-agent maps to deeper instruction content, and references/ on demand maps to the resource tier. skillserver is a centralized skills database implementing this standard with dual interfaces (MCP for agent consumption, HTTP/WebUI for human browsing), representing the emerging infrastructure layer for skill discovery and curation. No patterns were adopted into fctry (the alignment is already structural), but the reference documents fctry's position within a standardized ecosystem and validates two existing design choices: (1) progressive disclosure architecture matches the spec's three-tier model, and (2) the dual-interface pattern (agent-facing and human-facing surfaces for the same content) validates the viewer's bidirectional observation approach.

**Superpowers — Rationalization-resistant instruction design** (via `/fctry:ref`, 2026-02-20). Source: https://github.com/obra/superpowers. An agentic skills framework and software development methodology built as a Claude Code plugin, with 14 composable skills enforcing a brainstorm-plan-execute-review workflow. Unlike fctry's non-coder-facing model, Superpowers is developer-facing — but its instruction design methodology applies universally to any system with agent compliance requirements. Four patterns adopted into fctry: (1) TDD cycle for agent instructions — run pressure scenarios without the instruction to observe failure modes (RED), write the instruction addressing those failures (GREEN), close rationalization loopholes the agent uses to bypass the instruction (REFACTOR). This gives fctry a concrete methodology for authoring and hardening the 8 agent instruction files, rather than relying on informal iteration (adopted into `#rules` 3.3). (2) Rationalization tables — a reusable format that maps common agent bypass attempts ("This is too simple for the full process," "I need more context first," "The skill is overkill for this case") to specific counter-arguments. When an agent rationalizes skipping a step, the table provides the pre-written response. This sharpens fctry's workflow enforcement from "surface an error when steps are skipped" to "anticipate and counter the specific reasoning patterns that lead to skipping" (adopted into `#rules` 3.3). (3) The Description Trap — when a skill or agent description summarizes its workflow, Claude follows the description as a shortcut instead of reading the full instruction content, causing it to skip steps (e.g., doing one review stage instead of two). Descriptions should be trigger-only (what the skill is for and when to invoke it) with no process details. This directly informs fctry's progressive disclosure architecture: SKILL.md descriptions, agent frontmatter descriptions, and command summaries must avoid summarizing workflow steps (adopted into `#rules` 3.3). (4) Research-backed persuasion principles for instruction language — authority (framing instructions as institutional policy, not suggestions), commitment (requiring explicit acknowledgment before proceeding), and scarcity (emphasizing what's lost by skipping, not just what's gained by following) as the effective combination for discipline-enforcing instructions (Meincke et al. 2025, N=28k on LLM instruction compliance). This validates and sharpens the tone of fctry's prescriptive error messages and workflow enforcement language (adopted into `#rules` 3.3 and `#observability` 6.3). Three patterns noted but not adopted: two-stage review ordering (spec compliance then code quality — useful for Observer implementation but implementation-level, not experience-level), implementer self-review before external review (minor Observer optimization, not spec-level), and git worktree isolation (explicitly in `#agent-decides` 6.4 scope).

**GitNexus — Spec index staleness, self-guiding responses, precomputed dependencies, fail-open infrastructure** (via `/fctry:ref`, 2026-02-25). Source: https://github.com/abhigyanpatwari/GitNexus. A knowledge-graph-powered code intelligence engine that indexes codebases into a graph DB and exposes structural intelligence to AI agents via MCP tools. Four patterns adopted into fctry: (1) quantified spec index staleness tracking — the spec index records which spec version it was built from and includes a prescriptive recovery hint in query responses when stale ("index 3 versions behind, rebuild recommended"), letting agents make informed trust decisions about cached results rather than silently using outdated data (adopted into `#capabilities` 3.1 and `#entities` 3.2). (2) Self-guiding tool responses — spec-index queries and Observer verdicts append next-step hints to their results (e.g., "3 unresolved cross-refs — consider loading sections X, Y, Z"), reducing agent reasoning steps in multi-step workflows by leveraging the tool's own structural knowledge (adopted into `#execute-flow` 2.7). (3) Precomputed section dependency graph — cross-references and scenario overlap between sections are computed at index time (not query time) and cached in SQLite, giving the Executor a ready-made dependency graph for chunk boundary decisions, dependency edge identification, and cluster detection (adopted into `#execute-flow` 2.7 and `#entities` 3.2). (4) Fail-open principle for infrastructure subsystems — every derived subsystem (spec index, status line, viewer, Observer, hooks) proceeds without blocking when it encounters errors, surfacing degradation as hints rather than hard stops, ensuring the core workflow always works even when every infrastructure subsystem is broken (adopted into `#rules` 3.3). Four patterns noted but not adopted: PreToolUse hook for automatic context injection (validates existing State Owner briefing pattern), global multi-repo registry with lazy connection pooling (validates existing project registry), auto-generated AI context files (validates CLAUDE.md approach), and skill-based progressive disclosure (validates existing progressive disclosure architecture).

**ATM (Agent Team Manager) — Visual agent team management, deployment primer compilation, pipeline chaining** (via `/fctry:ref`, 2026-02-26). Source: https://github.com/DatafyingTech/Claude-Agent-Team-Manager. A Tauri v2 desktop application for visual management of Claude Code agent teams via drag-and-drop org-chart canvas. No patterns adopted — all findings confirmatory. Five patterns noted as validating existing fctry approaches: (1) deployment primer compilation (single-doc context bundling for agent execution) validates fctry's State Owner briefing + build plan frontloading, (2) file-based handoff summaries between sequential pipeline steps validate fctry's build trace + state file chunk handoffs, (3) file ownership coordination rule for parallel agent work (distinct files per agent to avoid merge conflicts) reinforces Executor chunk dependency planning, (4) sibling team awareness in deployment primers validates cross-chunk awareness in build plans, (5) sequential pipeline execution with machine-readable status tracking validates buildRun in state.json. Three patterns skipped: typed variable cascade (fctry agents share conversation context, not variable trees), OS-level cron scheduling (future direction, not current priority), and visual canvas as configuration surface (interesting as a two-way spec editing surface rather than a replacement for spec-as-truth — queued as an evolve idea for `#spec-viewer`).

**Dispatch — Background-worker execution, checklist-as-state, IPC with context dump, cognitive load framing** (via `/fctry:ref`, 2026-02-25). Source: https://github.com/bassimeledath/dispatch. A Claude Code skill that turns a single session into a lightweight orchestrator by spawning background workers, each with a fresh context window. Three patterns adopted into fctry: (1) reasoning context preservation on build interruption — when a build is interrupted (session crash, context exhaustion, user closes laptop), the checkpoint now preserves not just structural state (completed chunks, dependency graph position) but also a reasoning context dump — the key decisions, approach rationale, and unresolved considerations from the interrupted chunk — so that resumption starts with richer context than the structural checkpoint alone provides (adopted into `#execute-flow` 2.7 and `#error-handling` 2.10). (2) Background-worker execution as a future evolution path — the Executor may evolve toward spawning fresh context windows per chunk (each worker with a full, uncluttered context) rather than executing all chunks within one session's context window, inverting the context management problem from "manage scarcity" to "create abundance" (noted as future direction in `#execute-flow` 2.7). (3) "Cognitive load transfer" as the value framing for autonomous execution — naming the user benefit as "the factory carries the cognitive load" centers what the user gains (freedom from tracking work, debugging failures, managing context) over what the system does (autonomy), sharpening the pitch for plan-gated execution (noted in `#execute-flow` 2.7). Two patterns noted but not adopted: checklist-as-state where the plan markdown file is both instruction set and progress tracker (fctry's structured JSON state is more powerful for the multi-surface model — viewer, status line, dashboard all read from it — but the legibility of the checklist format is worth studying for build trace files), and multi-model routing per chunk based on complexity (relevant as a future token-efficiency optimization if fctry adopts background workers, but implementation-level for now).

**Zep — Temporal supersession metadata, fused multi-signal ranking with diversity, per-topic digest scope** (via `/fctry:ref`, 2026-02-27). Source: https://github.com/getzep/zep. A long-term memory service powered by Graphiti, a temporal knowledge graph engine that stores facts as bi-temporal entities with validity windows, retrieves via multi-signal fusion (semantic + temporal + structural), and maintains entity coherence through LLM-judged deduplication. Three patterns adopted into fctry: (1) temporal metadata on decision supersession — superseded decision records now carry a `superseded_by` reference linking to the replacement record and a `superseded_at` timestamp, creating a navigable chain so the user or system can trace the full decision history for a given pattern and answer "what was the decision at time T" (adopted into `#entities` 3.2 and `#rules` 3.3). (2) Fused multi-signal ranked selection with diversity penalty — the State Owner's memory injection algorithm now scores entries across alias match, recency, and type priority simultaneously via weighted sum (rather than sequential greedy filtering), with a diversity penalty that diminishes subsequent entries from the same section so no single section dominates the injection window (adopted into `#entities` 3.2 and `#rules` 3.3). (3) Per-topic conversation digest scope — conversation digests are now scoped to topic shifts within a session rather than one digest per session, producing smaller targeted digests (one per section or decision point discussed) that the selection algorithm can pick individually rather than forcing all-or-nothing inclusion of a large session summary (adopted into `#capabilities` 3.1 and `#rules` 3.3). Five patterns noted or skipped: LLM-judged deduplication (validates fctry's consolidation pass — 5+ entries about same pattern → cross-project lesson), community detection via graph clustering (requires graph DB, fctry's flat markdown store is intentional), rolling entity summaries (batch consolidation threshold is correct for markdown-first), group-scoped memory isolation (fctry's global store with structural-match gating is the right model), and MMR diversity selection algorithm (adapted as a simpler diminishing-score diversity penalty rather than full MMR, since fctry's entry count is small enough that the simpler approach suffices).

**Trail of Bits claude-code-config — Anti-rationalization Stop hook, credential deny rules, context budget gating** (via `/fctry:ref`, 2026-02-27). Source: https://github.com/trailofbits/claude-code-config. An opinionated configuration distribution for standardizing Claude Code across Trail of Bits, a security research firm. Packages global settings, CLAUDE.md templates, hook scripts (PreToolUse blockers, PostToolUse audit logging, Stop hook anti-rationalization), credential deny rules, and slash commands for common workflows. Three patterns adopted into fctry: (1) anti-rationalization Stop hook — a prompt-based evaluator that detects premature completion signals during autonomous builds ("good enough," "out of scope," "follow-up") and forces continuation. This structural enforcement layer complements fctry's existing instruction-level anti-rationalization design: instructions counter rationalization through persuasion (authority, commitment, scarcity framing), while the Stop hook fires at the decision point and is harder to override through context pressure. Two layers, neither sufficient alone (adopted into `#execute-flow` 2.7 and `#rules` 3.3). (2) Credential deny-rule sandboxing — explicit Read deny rules for sensitive paths (`~/.ssh/**`, `~/.aws/**`, `~/.gnupg/**`, `~/.config/gh/**`, `~/.git-credentials`, `~/.docker/config.json`, `~/Library/Keychains/**`). fctry now recommends these at first run and documents credential safety as a hard constraint, especially important for fctry's non-coder target user who may not understand what the Executor can access during autonomous builds (adopted into `#first-run` 2.1 and `#hard-constraints` 4.4). (3) Context budget gating — explicit threshold (75% context usage) that stops the Executor from starting new chunks, completing the current chunk cleanly and writing a checkpoint for fresh-session resumption. Prevents compaction-degraded builds where later chunks execute with progressively less context fidelity (adopted into `#execute-flow` 2.7). Eight patterns noted as validating existing fctry design: prescriptive PreToolUse blocking hooks (validates prescriptive error convention), context window management guidance (validates pipeline handoffs and progressive disclosure), multi-agent parallel review fanout (validates Observer verification), layered CLAUDE.md distribution (validates three-layer model), self-installing config command (validates dev-link-ensure self-healing), "hooks are structured prompt injection at opportune times" framing (validates hook architecture), statusline with cache hit rate (minor enhancement opportunity), and CI-as-source-of-truth for build discovery (noted but conflicts with agent-decides-implementation). Four patterns skipped: "replace, don't deprecate" philosophy (conflicts with fctry's migration support), package manager enforcement (violates agent authority), audit logging via PostToolUse (build traces are more structured), and telemetry/privacy controls (user's Claude Code settings, not plugin concern).

**semantic-navigator — Sibling-aware labeling, structured intermediate reasoning, semantic neighborhood navigation** (via `/fctry:ref`, 2026-02-27). Source: https://github.com/Gabriella439/semantic-navigator. A terminal tool that embeds repository files, clusters them by meaning via self-tuning spectral clustering, recursively subdivides into a browsable hierarchy, and labels each cluster with an LLM using sibling-aware context. Three patterns adopted into fctry: (1) sibling-aware structured outputs — when agents write or update multiple peer items (scenarios within a feature, sections within a category, claims within a section), they process all siblings in a single structured pass with sibling context, producing more distinctive labels. Each output is written in context of its peers, not independently. The principle: labeling peers together produces better labels than labeling each alone (adopted into `#rules` 3.3). (2) Structured intermediate reasoning for concise outputs — when agents produce compressed text (scenario titles, section summaries), the structured schema includes intermediate reasoning fields (`experienceContext` + `distinguishingBehavior` + `title`) that are computed but not persisted. The intermediate fields guide the model's reasoning path toward more precise final outputs (adopted into `#rules` 3.3). (3) Semantic neighborhood navigation — the existing embedding infrastructure in the spec index (`section_embeddings` table, cosine similarity) is extended to three surfaces: dependency neighborhood diagrams gain a semantic ring showing embedding-similar sections alongside structural cross-references (visually distinct — dashed edges), the `Cmd+K` search modal gains semantic ranking when embeddings are active, and the State Owner's targeted scans supplement explicit cross-references with top-N semantically similar sections to catch implicit dependencies (adopted into `#spec-viewer` 2.9 and `#capabilities` 3.1). Five patterns noted as validating existing fctry design: content-hash embedding cache with per-model invalidation (validates `section_embeddings` table), recursive hierarchical depth adaptation (validates recursive kanban), small-repo bypass (validates scan depth scaling), compressed labels (validates status line compactness), and TUI tree filtering (validates viewer fuzzy search). Three patterns skipped: spectral clustering algorithm (fctry's spec hierarchy is declared, not discovered), eigengap heuristic (explicit section count makes auto-grouping unnecessary), and async/semaphore I/O (different runtime model).

**visual-explainer, contrail, value-realization, arifOS, charlotte — Verification depth, learning maturation, interview toolkit, plan framing, and observation efficiency** (via `/fctry:ref`, 2026-02-27). Sources: five GitHub repos explored in a batch `/fctry:ref` session. Fourteen patterns adopted across six spec sections, organized by theme: **Verification and observation** — (1) fact-sheet verification checkpoint: the Observer cross-checks structured chunk outputs against source material before committing, catching hallucinated values or misquoted spec text (from visual-explainer, adopted into `#execute-flow` 2.7). (2) Structural diffing: the Observer compares before/after DOM structure rather than pixel screenshots for UI verification, a cheaper and more reliable signal (from charlotte, adopted into `#execute-flow` 2.7). (3) Tiered observation detail: three levels (summary → structural → full DOM), auto-selected by what's being checked so verification tokens scale with question complexity (from charlotte, adopted into `#capabilities` 3.1). **Learning and memory** — (4) Learning maturation lifecycle: new build lessons start as `candidate` with confidence 1, graduate to `active` after 3 confirmations across sessions, preventing one-off flukes from becoming permanent knowledge (from contrail, adopted into `#capabilities` 3.1 and `#entities` 3.2). (5) Confidence scoring: each lesson carries a score that increments on confirmation, decrements on contradiction, and triggers pruning at zero (from contrail, adopted into `#entities` 3.2). (6) Memory authority model: explicit separation between user-authored entries (always win conflicts) and agent-derived entries (can be overridden), preventing the system from gradually overriding user preferences with inferred patterns (from contrail, adopted into `#rules` 3.3). (7) Atomic compaction writes: memory and lesson compaction operations write to temp file then atomic rename, preventing corruption on interruption (from contrail, adopted into `#rules` 3.3). **Viewer and diagrams** — (8) Depth-tiered section content: detail panel renders at three tiers (overview → detail → deep-dive) so users control information density (from visual-explainer, adopted into `#spec-viewer` 2.9). (9) Mermaid CSS collision guard: namespaced CSS classes prevent diagram styles from bleeding into viewer layout (from visual-explainer, adopted into `#spec-viewer` 2.9). (10) Diagram zoom controls: pan/zoom/reset on complex diagrams, hidden on small ones (from visual-explainer, adopted into `#spec-viewer` 2.9). **Interview and planning** — (11) Value timeline question: "When did this go from interesting to essential?" surfaces the inflection point that reveals what matters most (from value-realization, adopted into `#core-flow` 2.2). (12) Value perception prompt: "Describe this to someone else in one sentence" reveals the user's mental model vs. what the spec captures (from value-realization, adopted into `#core-flow` 2.2). (13) Plan scope framing: minimal/balanced/maximal variants let the user pick scope matching their energy, preventing all-or-nothing plan dynamics (from arifOS, adopted into `#execute-flow` 2.7). (14) State Owner reality index: self-assessed confidence (high/medium/low) in the briefing header so downstream agents can calibrate trust (from arifOS, adopted into `#capabilities` 3.1). Patterns noted but not adopted: visual-explainer's fact-check slash command (subsumed by Observer verification), visual-explainer's cognitive debt hotspot and understanding gap concepts (interesting for future self-improvement/reflect direction), contrail's DLP lint on memory writes (fctry's memory is local-only, no exfiltration risk), contrail's explicit failure probe strings (implementation-level concern), value-realization's aha moment mapping (the value timeline question captures this), arifOS's tool permission matrix per agent (fctry agents share tool access via Claude Code's permission model), and charlotte as an MCP browser tool recommendation (already covered by OpenBrowser and Rodney/Surf in `#external-connections`).

---

## 6. Satisfaction and Convergence

### 6.1 Satisfaction Definition {#satisfaction-definition}

The fctry system is satisfactory when:

- A non-coder with a project idea can run `/fctry:init`, describe their vision conversationally, and receive a complete, coherent spec within 20 minutes — without needing to understand databases, APIs, or architecture.

- The user can pause an interview, return days later, and resume exactly where they left off with no loss of context or repeated questions.

- The user can point to any part of the spec (by number or alias) and update it in isolation, seeing exactly what changed and confident that unrelated sections remain untouched.

- When the spec and code diverge, the system surfaces the conflict with specific evidence (recency, changelog, code behavior) and asks the user to resolve it, never guessing or assuming.

- The user can incorporate external inspiration (a URL, a screenshot, a design) and see it interpreted in experience language and integrated into the spec within 60 seconds.

- The user can run `/fctry:execute`, approve a build plan, and watch the system build autonomously toward scenario satisfaction — with ambient progress visibility through mission control and the status line, convergence milestones at phase boundaries, and the ability to resume interrupted builds where they left off.

- The user can open the spec viewer and see the spec rendered cleanly, watch it update in real-time as agents work, navigate the change history, and understand exactly what's changing and why.

- The user feels like they have a co-founder with perfect memory, deep context, and the ability to translate their vision into a buildable spec without them needing to learn to code.

### 6.2 Convergence Strategy {#convergence-strategy}

**Start with:** Core command loop and multi-session interviews.

The first working version demonstrates `/fctry:init` with conversational interviewing, state persistence (save and pause, resume), State Owner briefing, Scenario Crafter and Spec Writer producing the spec and scenarios, and addressable sections (aliases and numbers). The user can create a complete spec, stop partway, and resume later.

**Then layer in:** Evolve, ref, and review commands.

Once init works, add `/fctry:evolve <section>` with targeted interviews, diff summaries, and conflict resolution (spec vs. code drift detection). Add `/fctry:ref <url>` with Researcher and Visual Translator, experience-language interpretation, and both targeted and open modes. Add `/fctry:review` with gap analysis and recommendations.

**Next:** Execute with plan-gated autonomous building.

Add `/fctry:execute` with the Executor agent, scenario satisfaction evaluation, build plan proposal and approval, autonomous chunked execution with execution priorities shaping parallelization and failure behavior, and build checkpointing so interrupted builds can resume where they left off.

**Then:** Tool validation and changelog integration.

Add startup tool validation (check for rg, sg, gh, MCP servers) with fail-fast errors and installation instructions. Add changelog maintenance (append-only, timestamped, machine-readable). Wire the State Owner to read the changelog for sharper drift detection and trajectory analysis.

**Then:** Live spec viewer.

Add the local web UI (started via `/fctry:view`, stopped via `/fctry:stop`) with zero-build markdown rendering, WebSocket-based real-time updates, section highlighting when agents are working, change history timeline with diffs, and keyboard navigation. The user can watch the spec evolve in real-time.

**Then:** Autonomous execution.

Evolve execute from paced (per-chunk approval) to autonomous (plan-level approval). Add experience reports (not satisfaction scorecards) and silent failure handling. The build plan shows execution order and dependency handling. The system resurfaces only for experience-level questions.

**Then:** Viewer mission control and async inbox.

Transform the viewer into mission control during builds (real-time concurrent progress, section lighting, dependency visualization). Add the async inbox (evolve ideas, reference URLs, new features) that processes in the background. The factory never idles — builds, reference analysis, and evolve prep all run concurrently.

**Then:** Multi-project viewer.

Evolve the viewer from per-project servers to a single multi-project-aware server. Add the global project registry (`~/.fctry/projects.json`), auto-registration on init, project sidebar with quick status, and full context switching between projects. The server persists across sessions and self-heals.

**Then:** Kanban as primary interface.

Replace the static project dashboard with a recursive kanban board. Projects become draggable cards in priority columns (Inbox/Now/Next/Later/Satisfied). Clicking a project drills into a section-level kanban with a section/scenario toggle. Clicking a section drills into claim-level cards. Inbox items land as inbox cards. Kanban position drives State Owner assessment depth, Executor build ordering, and review granularity. The kanban is the primary observation, decision-making, and prioritization surface — the user looks, prioritizes, and decides here, Claude Code executes.

**Then:** Automatic diagramming and visual polish.

Add five types of auto-generated Mermaid diagrams (entity relationships, user flows, agent pipeline, convergence phases, section dependency neighborhoods). Per-section toggle with `d` shortcut and global "show all as diagrams" mode. Add dark mode (system-detected with manual override, Radix-based token system). Add visual polish: skeleton loading, syntax highlighting, fuzzy search, styled toasts, uncapped activity feed.

**Finally:** Viewer as control plane.

Embed a terminal emulator (e.g., xterm.js + node-pty) in the viewer, running Claude Code inside the browser. This inverts the current model — the viewer becomes the primary surface where the user thinks, plans, and directs work, while Claude Code runs as the execution engine within it. The user sees all their projects, switches between them, kicks off builds, has conversations, and watches mission control — all in one window. This is the long-term architectural direction: the viewer wraps around Claude Code rather than sitting alongside it.

**Convergence phases as version arcs.** Each convergence phase described above maps to a minor version arc: completing the core command loop is a minor bump, completing the viewer is a minor bump, completing mission control is a minor bump. When the Executor suggests a minor version bump at the end of a build plan, it characterizes the phase as an experience era in the release notes — not just listing what changed, but describing the experience shift the phase represents ("the viewer era is complete — you can now watch every spec update and build in real-time from the browser"). This makes version numbers meaningful: v0.2.0 → v0.3.0 tells a story, not just a changelog. The phase type inferred for each build plan (see `#rules` 3.3) shapes this narrative: a Capability phase completion reads differently from a Hardening phase completion. Major version bumps mark experience eras that span multiple phases — the transition from "spec authoring only" to "autonomous builds live" is a major bump regardless of which phase technically completed it.

**Future direction: Incremental build trace parsing.** Build traces (`.fctry/build-trace-{runId}.md`) are currently written as a complete document when the build completes. An incremental append-only format — where each chunk completion appends a structured entry to the trace file during the build rather than constructing the full trace at the end — would enable the viewer to stream trace data in real-time and allow the State Owner to read partial traces from interrupted builds. This pattern (from claude-devtools' incremental log parsing) is noted here for future implementation when build traces become a first-class live data source rather than a post-build artifact.

**Future direction: Self-improvement loop.** A `/fctry:reflect` command that analyzes recent session behavior — retry rates, token patterns, drift frequency, friction points — and proposes config, prompt, or hook improvements. The system observes its own execution patterns and suggests how to improve itself. Rather than requiring the user to tune the system when something feels slow or error-prone, the reflect command surfaces specific proposals: "your builds average 2.3 retries per chunk across the last 5 sessions — these sections tend to generate experience questions: consider evolving `#core-flow` to be more specific." This extends fctry from a user-directed tool to a self-improving system. The reflect loop would use the same findings/proposals pattern as `/fctry:review` but turned inward — examining fctry's own behavior rather than spec-code alignment. Proposals are numbered and require user approval before any config changes are made.

### 6.3 Observability {#observability}

Key signals to watch:

- **Interview completion rate.** What fraction of users who start `/fctry:init` complete the interview vs. abandon partway? High abandonment suggests the interview is too long, too tedious, or not drawing out the vision effectively.

- **Multi-session usage.** How often do users pause and resume interviews? If rarely, multi-session support may not be needed. If frequently, it's critical — and we should watch how long between pause and resume (hours? days? weeks?).

- **Section update frequency.** Which sections get updated most often via `/fctry:evolve`? High churn in a section suggests it's under-specified or the user's vision is still forming. Low churn suggests the spec is stable.

- **Drift detection accuracy.** When the State Owner flags drift, how often does the user confirm it's real vs. dismiss it as a false positive? High false positive rate suggests the drift detection logic needs refinement.

- **Execute chunk success rate.** What fraction of build chunks succeed on first attempt vs. require retry or manual intervention? High retry rate suggests the spec is ambiguous or the coding agent is misinterpreting it.

- **Scenario satisfaction trajectory.** How quickly does satisfaction improve during `/fctry:execute`? Steady improvement suggests the build is converging. Flat or declining satisfaction suggests the spec and scenarios are misaligned or the coding agent is stuck.

- **Execution priority distribution.** What rankings do users choose? If most users rank speed first, the default preset should favor speed. If most use the same ranking across all projects, per-project overrides may be unnecessary complexity. If rankings vary significantly by project, per-project support is justified.

- **Spec viewer usage.** Do users keep the viewer open while running commands? Do they interact with the change history? If the viewer is rarely used, it may not be delivering enough value to justify the complexity.

- **Tool validation failure rate.** How often do users hit missing tool errors? If frequently, the installation instructions need to be clearer or the tool dependency list needs to shrink.

- **Time to first spec.** How long does it take from `/fctry:init` to a complete, satisfactory spec? Target: under 20 minutes for a simple project. If consistently over 30 minutes, the interview is too long or the Spec Writer is too slow.

- **Workflow enforcement trigger rate.** How often do agents hit the "State Owner must run first" error? High rates suggest the enforcement is catching real process drift. If it never fires, the enforcement may be unnecessary overhead — or the process is being followed naturally.

- **Untracked change frequency.** How often does the PostToolUse hook detect file writes outside fctry commands that cover spec sections? High frequency suggests users are doing ad-hoc development between fctry commands — the nudge may need to be less intrusive, or `/fctry:review` needs to better reconcile untracked changes.

- **Section readiness distribution.** What fraction of sections are in each readiness state (draft, undocumented, ready-to-build, aligned, ready-to-execute, satisfied, deferred)? A project with many `undocumented` sections has code outpacing the spec. A project with many `ready-to-build` sections has a detailed spec but little implementation.

- **Spec index rebuild frequency.** How often does the SQLite cache rebuild from the markdown? Frequent rebuilds (every few seconds) during active evolve sessions are expected. Rebuilds outside of fctry commands suggest the user is editing the spec manually — which should be rare.

- **Chunk retry rate.** How often do chunks need multiple attempts, and how many attempts are typical? A high retry rate across builds suggests specs are consistently ambiguous or the coding agent is struggling with certain patterns. A low rate with occasional spikes points to specific section complexity. Tracked per build run.

- **Build run duration.** Wall-clock time from plan approval to experience report. Compared against the plan's estimated time to calibrate future estimates. Tracked per build run alongside chunk count and parallelism level.

- **External tool call frequency.** How often do agents invoke MCP tools (Firecrawl, Context7, Playwright) during builds? Which tools are used most? If a build involves many external calls, the activity feed becomes richer and more informative. If certain tools fail frequently, the user should know (via the experience report) that external dependencies slowed the build.

- **Build log export usage.** How often do users download build logs after completion? If rarely, the export feature may not justify its placement. If frequently, it validates that users want a record of what the system did.

- **Build resume frequency.** How often do builds get interrupted and resumed? If rarely (most builds complete in one session), the checkpoint system may be over-engineered. If frequently, it validates the investment. Track reasons for interruption: session crash, context exhaustion, user closed laptop, explicit stop at milestone.

- **Convergence milestone interaction.** When milestones are presented, how often do users try the system at that point? How often do they stop the build at a milestone vs. letting it continue? High stop rates at milestones suggest users are finding problems early — which is the point. If milestones are always ignored, they may be too noisy.

- **Build coordination effectiveness.** How often does the Executor detect and recover from stuck chunks, and what's the recovery success rate? If the coordinator rarely intervenes, builds may be simple enough that coordination adds no value. If it intervenes often and succeeds, the pattern is justified.

- **Observer verification pass rate.** What fraction of post-chunk verifications pass on first attempt? A consistently high pass rate (95%+) suggests the build is reliable and verification is confirming quality. A low pass rate suggests either the Observer's checks are too strict or the build quality needs attention. Track pass-on-first-attempt vs. pass-on-retry vs. failed-after-retry to understand transient vs. persistent issues.

- **Observer degradation frequency.** How often does the Observer operate in reduced mode (API + files only) or minimal mode (files only) instead of system-wide mode (Peekaboo + browser + API + files) or full mode (browser + API + files)? Frequent degradation suggests browser or system-wide tools aren't reliably available — the system still works, but verification coverage is reduced. If degradation is rare, the full tooling stack is healthy.

- **Application-level verification coverage.** When Peekaboo is available, what fraction of build chunks trigger non-browser verification (native app windows, terminal UIs, system dialogs)? High usage validates the investment in system-wide observation. Low usage suggests most builds are web-only and browser tools suffice.

- **Screenshot capture surface distribution.** Of all Observer screenshots taken during builds, what fraction come from browser tools (Rodney/Surf) vs. system-wide tools (Peekaboo)? A shift toward system-wide captures over time suggests builds are producing more diverse output surfaces.

- **Average checks per chunk.** How many Observer checks does a typical chunk trigger? Too few checks suggest verification is shallow; too many suggest it's over-thorough and adding latency without proportional value. Track alongside chunk complexity (number of affected sections, estimated time).

- **Screenshot capture success rate.** When the Observer attempts to take a screenshot (for evidence or verification), how often does it succeed? Screenshot failures typically indicate tool availability issues. High success rates validate the Rodney/Surf/Peekaboo integration; low rates suggest the system should rely more on API-based checks. Peekaboo captures cover non-browser surfaces (native app windows, terminal UIs, system dialogs) where Rodney and Surf cannot reach.

- **Context compaction frequency during builds.** How often does auto-compaction fire during build sessions? If frequently, builds are pushing context limits and the Executor's context boundary strategy is load-bearing. If rarely, most builds fit comfortably in the context window and context management is low-value overhead. Track alongside build size (chunk count, total estimated time) to understand which builds stress context.

- **Build quality consistency across chunks.** Is there measurable quality degradation in later chunks compared to earlier ones (more retries, lower scenario satisfaction rates, more Observer verification failures)? If later chunks consistently perform worse, context pressure may be a factor even when the system doesn't explicitly compact. If quality is consistent, the context management strategy is working.

- **Retrospective context efficiency in experience reports.** After a build completes, the experience report includes a brief context health summary: whether compaction fired, how many times, which sections drove the most context pressure, and whether context fidelity settings were adequate. This is retrospective information reviewed at the user's discretion — not a real-time alert during the build. A build that completed with no compaction gets a single line ("context pressure: none"). A build with frequent compaction gets a breakdown showing which chunks stressed context and what fidelity mode was used.

- **Agent behavioral compliance.** Do agents follow their declared constraints under pressure — token economy rules, interchange emission, experience-language-only output? Behavioral tests (e.g., "given a 50-section spec, does the State Owner's briefing stay under the prose budget?", "does the Executor emit a valid interchange document after each chunk?") catch constraint drift that functional tests miss. Track compliance rates per agent per constraint category to identify which rules agents reliably follow vs. which need stronger enforcement or simpler formulation. The rationalization-resistant instruction design methodology (see `#rules` 3.3) is the authoring practice that this signal validates — when compliance drops for a specific constraint, the TDD-for-instructions cycle (pressure test, write instruction, close loopholes) produces the fix. Common rationalization patterns ("too simple for the full process," "already know enough to skip") are documented in agent instruction files as explicit counter-arguments, so the system's response to non-compliance is pre-written rather than improvised.

### 6.4 What the Agent Decides {#agent-decides}

The coding agent has full authority over:

- Technology choices (language, framework, database, tooling) — The spec describes experience; the agent picks the stack that best delivers it.
- Architecture and code structure — Monolith, microservices, layered, hexagonal — all agent decisions.
- Data model design — Tables, schemas, indexes, relations — inferred from the entities described in section 3.2, but the agent designs the actual data model.
- Internal APIs and interfaces — How components talk to each other, what data they exchange, what contracts they expose — all agent decisions.
- Testing strategy and tooling — Unit tests, integration tests, E2E tests (beyond the scenarios) — agent's choice.
- Build and deployment configuration — How the code is built, bundled, and run — agent's choice.
- Error handling implementation — How errors are caught, logged, and recovered from — agent's choice, constrained only by the user experience in section 2.10.
- Performance optimization approach — Caching, indexing, lazy loading, batching — agent's choice, constrained only by the performance expectations in section 3.5.
- Agent implementation (prompts, orchestration logic, file I/O, state management) — The coding agent that builds fctry itself decides how the agents are implemented, how they communicate, and how state is persisted.
- MCP server implementation (WebSocket protocol, markdown rendering, change history storage) — The coding agent decides how the spec viewer is built and served.
- Execution strategy — How chunks are ordered and executed, including whether to attempt any form of parallelism (e.g., subagents for independent chunks) or run purely sequentially. Today, builds run sequentially in dependency order; the agent may evolve toward parallelism as tooling matures. The agent's strategy is guided by the user's execution priorities: speed-first priorities favor aggressive retries and moving past failures, reliability-first priorities favor conservative approaches with thorough verification, token-efficiency-first priorities favor context reuse and minimal overhead.
- Context fidelity between chunks — How much context from a completed chunk carries into a dependent chunk: full transcript, trimmed transcript (full conversation with tool result bodies stubbed — preserves reasoning chain while reclaiming 50-70% of token budget), structured summary, or fresh start with artifacts only. Guided by execution priorities: token-efficiency-first favors trimmed transcript or minimal context, reliability-first favors full or trimmed transcript, speed-first favors compact summaries.
- Build coordination strategy — How to monitor build health, detect stuck chunks, and rebalance work across the dependency graph. The agent decides when a chunk is stuck (vs. just slow), when to escalate to an experience question (vs. trying another approach), and how to reorder remaining work when the graph allows it.
- Async inbox processing — How the viewer inbox items are queued, processed, and stored. The spec describes the three item types and their expected outcomes; the agent decides the processing pipeline.
- Observer verification depth — How many checks to run per chunk, whether to use browser tools or API-only inspection, and how thorough to make each check. The spec describes the Observer's capabilities and degradation levels; the agent decides the verification strategy for each chunk based on execution priorities and tool availability. Reliability-first priorities favor thorough browser-based verification; speed-first priorities favor lightweight API checks; token-efficiency-first priorities favor minimal file-only inspection.
- Context isolation between chunks — Whether to use subagent boundaries, fresh sessions, or other mechanisms to ensure each chunk operates with clean context. The spec requires that context pressure never degrades build quality; the agent decides the isolation mechanism. Guided by execution priorities: reliability-first favors strict isolation (each chunk in a fresh context), speed-first favors lightweight boundaries (summaries between chunks), token-efficiency-first favors context reuse where safe.

The agent's implementation decisions are constrained only by:

- The design principles in section 1.3 (experience language, agent decides, grounded in reality, approval-gated, conversational, progressive, addressable)
- The hard constraints in section 4.4 (Claude Code plugin model, experience language only, scenario holdout separation, approval-gated execution, State Owner first, no code review)
- The experience described in section 2 (what the user sees, does, and feels at every step)
- Satisfaction of the scenarios in `.fctry/scenarios.md` (the holdout set)
- The user's execution priorities (speed, token efficiency, reliability ranking) — for failure behavior, retry strategy, verification depth, and context management decisions

No human reviews the code. The code is validated solely through scenario satisfaction and convergence.

---

## Appendix A: Decision Rationale

**Why experience language only, never implementation language?**

The target user is a non-coder with a clear vision but no mental model of databases, APIs, or architecture. If the spec uses technical language, the user can't meaningfully review or refine it. Experience language ("the user sees a list sorted by urgency") is accessible, reviewable, and precise enough for a coding agent to infer implementation. This decision rules out any UI that asks the user about technical details.

**Why are scenarios in a separate file from the spec?**

In machine learning, holdout sets are kept separate from training data to prevent overfitting. The same principle applies here: if scenarios are visible to the coding agent during development, the agent can "teach to the test" by implementing exactly what the scenarios check and nothing more. Separation ensures the agent builds from the spec (the experience) and scenarios validate the result, not guide it.

**Why must the State Owner always run first?**

Without grounding in reality, spec updates become speculative. The State Owner provides the current state: what code exists, what the spec says, where they diverge, what changed recently. Every other agent operates on this briefing. If the State Owner runs later (or not at all), agents work from assumptions, leading to specs that describe things that don't exist or ignore things that do.

**Why addressable sections with both aliases and numbers?**

Humans remember concepts, not numbers. "The core flow" is easier to recall than "section 2.2." But numbers provide stable, unambiguous references that survive renames. Supporting both gives users the flexibility to reference sections however they think about them, without the system needing to guess or resolve ambiguity.

**Why plan-level approval instead of per-chunk gates?**

The user needs to control the scope and direction of builds, but not the moment-to-moment execution. Plan approval gives the user authority over what gets built, how much work is in scope, and the execution strategy. Per-chunk gates added friction ("chunk 1 done, continue?") without adding value — the user always said yes. After plan approval, the system executes autonomously, handling technical decisions silently. The user retains control through the plan itself and through experience questions when the spec is ambiguous.

**Why multi-session interviews?**

Real projects are complex. Users need time to think, gather information, or consult others before answering some questions. Forcing completion in one session leads to shallow specs or abandoned interviews. Multi-session support respects the user's time and thinking process, making spec authoring a progressive activity rather than a marathon session.

**Why enforce the workflow instead of just documenting it?**

Documentation describes intent; enforcement ensures adherence. When the process is only documented, Claude can (and does) skip steps — going straight to code when a quick fix seems obvious, bypassing the State Owner scan, updating code without updating the spec. For a non-coder, this is invisible: they think they're working within the factory model, but they're actually in ad-hoc mode. Enforcement makes the boundary explicit. The numbered-options error ("Run State Owner now / Skip / Abort") keeps it conversational rather than rigid — the user can always skip, but they do so consciously.

**Why SQLite as a cache instead of as the primary store?**

The markdown spec must remain portable and human-readable. A non-coder should be able to open the spec in any text editor or viewer. Making SQLite the primary store would lock the spec behind a database that requires tooling to read. By keeping markdown as source of truth and SQLite as a derived cache, the system gets structured queries (section-level access, cross-references, readiness filtering) without sacrificing portability. If the database file is deleted, corrupted, or missing, agents fall back to reading the full markdown file — the system degrades gracefully rather than failing.

**Why detect untracked changes via a hook instead of only during review?**

Non-coders may not realize that fixing a bug directly in code creates drift between the spec and the implementation. By the time they run `/fctry:review`, the drift may have compounded across multiple files. Real-time detection surfaces the issue immediately with a gentle nudge — not a blocking error. The user can dismiss it and reconcile later, but they're aware. This is designed to be dialed back: if the nudge proves too intrusive, it can be moved to `/fctry:review`-only detection without changing the spec.

**Why autonomous execution after plan approval instead of per-chunk approval gates?**

Per-chunk gates were designed to prevent unbounded resource consumption, but in practice they interrupt the user for decisions that don't require human judgment — "chunk 1 done, continue to chunk 2?" The user always says yes. The meaningful decision is the plan itself: what scope of work, which scenarios, what parallelization strategy. Once that's approved, the remaining gates add friction without adding value. The user still controls scope (through the plan) and can still observe progress (through mission control). They lose the ability to pause mid-build, but gain uninterrupted autonomous progress. Code failures, retries, and rearchitecting are the agent's domain — surfacing them breaks the factory model's core promise that no human touches or reviews the code.

**Why does the agent resurface only for experience questions?**

The factory line is clear: human and LLM collaborate on vision (init, evolve, ref, review); the build is LLM-only. During a build, the only thing the human knows that the agent doesn't is what the experience should feel like. Technical questions (how to fix a compilation error, which library to use, how to structure the code) are the agent's domain. Experience questions (should items without a due date appear at the top or bottom?) require the user's judgment. This boundary keeps the human in their zone of authority and the agent in its zone of authority.

**Why an async inbox in the viewer instead of queuing ideas in the CLI?**

The CLI (Claude Code) is the conversation surface — it's where evolve discussions happen. But ideas don't arrive during conversations; they arrive at random moments: browsing the web, using a competitor's product, thinking in the shower. The viewer is always accessible (a browser tab) and always connected to the project. Making it an input surface for async items means the user can capture ideas the moment they occur, without switching to the terminal, without interrupting a build, without losing context. The inbox is a queue, not a conversation — it doesn't try to replace the CLI for spec discussions, just captures raw input for later processing.

**Why a version registry instead of ad-hoc version management?**

Projects have multiple versions (project version, spec version, potentially API version) that appear in multiple files. Without a registry, version bumps require knowing which files to update and remembering to update all of them — a manual, error-prone process. The version registry centralizes this: declare version types and their propagation targets once, and every version change updates everything automatically. This is especially critical for the target user (non-coders) who shouldn't need to know that a version number appears in `package.json`, `plugin.json`, and a README badge. Auto-discovery at first execute reduces manual configuration, while declared targets ensure propagation is predictable. Relationship rules between version types (e.g., major spec change → external minor bump) make the version ecosystem self-consistent without the user managing cross-version dependencies.

**Why does the spec viewer auto-start silently instead of requiring `/fctry:view`?**

Observability should be always available, not opt-in. The viewer runs on a plugin hook that fires on every prompt, but the `ensure` logic makes it a no-op (<5ms) when no spec exists or the viewer is already running — so it never slows anything down. Auto-start uses `--no-open` to avoid surprise browser tabs; the user runs `/fctry:view` when they want to actually look at the viewer. The server persists across sessions because it serves all projects — killing it on one session end would disrupt monitoring of other projects. Self-healing on the next prompt means no orphaned-process management needed. The result: the viewer is always ready when the user wants it, never in the way when they don't.

**Why a single multi-project server instead of per-project servers?**

A user with many projects (the target persona) would otherwise accumulate separate server processes, each on a different port, each requiring its own browser tab. That's operational overhead that contradicts the "co-founder with perfect memory" vision. A single server with a project sidebar lets the user see all their projects at a glance and switch instantly — the same mental model as a multi-tab IDE or a project management dashboard. It also creates the natural foundation for a future dashboard view (overview of all projects) and for the viewer evolving into a control plane. The tradeoff is increased server complexity and a global lifecycle (persists across sessions, must self-heal), but the user experience is dramatically simpler.

---

## Appendix B: Glossary

| Term | Meaning |
|------|---------|
| **Experience language** | Descriptions of what users see, do, and feel — never databases, APIs, or code. Example: "The user sees a list of items sorted by urgency, with overdue items highlighted." |
| **NLSpec v2** | Natural Language Specification format, version 2. A structured template for describing software systems in experience language. See `references/template.md`. |
| **Scenario** | A user story that describes a complete journey through the system, written in experience language. Scenarios form the holdout set used to evaluate satisfaction. |
| **Holdout set** | In machine learning, a dataset kept separate from training to prevent overfitting. Here: scenarios kept separate from the spec to prevent the coding agent from "teaching to the test." |
| **Satisfaction** | Probabilistic measure of success: of all observed trajectories through all scenarios, what fraction satisfy the user? Replaces binary pass/fail. |
| **State Owner** | The first agent in every command. Scans the codebase, reads the spec and changelog, detects drift, and produces a briefing that grounds all other agents in reality. |
| **Briefing** | A document produced by the State Owner summarizing the current state: project classification, scenario satisfaction, drift, recent changes, and recommendations. |
| **Drift** | When the spec and code describe different behavior. Detected by comparing spec text, code behavior, and recency signals (commits, changelog). |
| **Chunk** | A discrete unit of work in a build plan, focused on satisfying one or more scenarios. Chunks execute sequentially in dependency order. Executed autonomously after plan approval. |
| **Addressable section** | A section of the spec with both a number (e.g., `2.2`) and a stable alias (e.g., `#core-flow`). Both can be used in commands to reference the section. |
| **Changelog** | An append-only log of spec updates, timestamped and machine-readable. Read by the State Owner to understand the trajectory of spec evolution. |
| **Pacing options** | (Superseded by autonomous execution.) Previously, the user chose after each chunk. Now, the user approves the full plan once and the system executes autonomously. |
| **Workflow enforcement** | The system's mechanism for ensuring agents follow the prescribed workflow (State Owner first → domain agents → Scenario Crafter → Spec Writer). Agents validate prerequisites before proceeding; violations surface as numbered errors. |
| **Spec index** | A structured SQLite cache (`.fctry/spec.db`) derived from the markdown spec. Contains section content, metadata, readiness, and changelog entries. Enables agents to query individual sections without loading the full spec. |
| **Section readiness** | Per-section metadata indicating the section's current state: `draft`, `undocumented`, `ready-to-build`, `aligned`, `ready-to-execute`, `satisfied`, or `deferred`. Assessed by the State Owner during every scan and updated by the Executor after each build chunk. Stored authoritatively in `state.json` as a `sectionReadiness` map; all display surfaces (status line, viewer, dashboard) read from this single source. The readiness vocabulary matches the gap analysis headings — `undocumented` maps to "Decisions Needed", `ready-to-build` maps to "Ready to Build" — so the same terms appear everywhere. `deferred` marks intentionally-postponed sections — counted as "ready" in aggregation. |
| **Untracked changes** | File modifications made outside fctry commands that affect code covered by spec sections. Detected by a PostToolUse hook and surfaced to the user for reconciliation. |
| **Autonomous execution** | After plan approval, the system executes all build chunks without further user approval. The agent handles failures, retries, and rearchitecting silently, resurfacing only for experience-level questions. |
| **Experience report** | The post-build summary that describes what the user can now do in concrete, experience-mapped terms — not satisfaction percentages or scenario IDs. |
| **Experience question** | A question the agent surfaces during autonomous execution when the spec is ambiguous or contradictory in a way that affects the user experience. The only reason the agent interrupts the user during a build. |
| **Mission control** | The spec viewer's build-time mode showing real-time build progress: the active chunk, completed sections, dependency status, and pending experience questions. |
| **Project registry** | A global list of all fctry projects at `~/.fctry/projects.json`. Auto-populated when specs are created or when the user works in a project with an existing spec. Consumed by the multi-project viewer to populate the project sidebar. |
| **Project sidebar** | The viewer's project switcher — a compact list of all registered projects with quick status (build state, readiness, last activity). Clicking a project performs a full context switch. |
| **Async inbox** | The spec viewer's input surface for evolve ideas, reference URLs, and new feature proposals. Items are processed in the background and ready for the user when they next run a fctry command. |
| **Execution strategy** | Part of the build plan showing chunk execution order, dependency handling, failure approach, and how execution priorities influenced these choices. |
| **Build run** | A first-class entity representing a single `/fctry:execute` invocation after plan approval. Contains a run ID, the approved plan, a chunk tree with lifecycle states and retry counts, overall status, and duration. Observed by mission control. Persisted in `.fctry/state.json` as a `buildRun` object so incomplete builds survive session death and can be resumed. Cleared when the build completes or the user starts a fresh plan. |
| **Chunk lifecycle** | The explicit states a build chunk moves through: planned (in the approved plan, not yet started), active (currently executing), retrying (failed and re-attempting with an adjusted approach), completed (finished successfully), or failed (exhausted all approaches). Visible in mission control and the terminal status line. |
| **Build checkpoint** | A persistent snapshot of build state (completed chunks, pending chunks, dependency graph position, approved plan reference) written after each chunk completes. Enables resuming interrupted builds without re-executing completed work. Stored in `.fctry/state.json`. |
| **Build resume** | The ability to continue an interrupted build from where it left off. When `/fctry:execute` detects an incomplete build, it offers to resume — skipping completed chunks and picking up at the next pending chunk. If the spec changed for a completed section, the user chooses whether to rebuild or keep the old result. |
| **Context fidelity** | How much context from a completed chunk flows to a dependent chunk: full transcript, trimmed transcript (tool result bodies stubbed, reasoning preserved), structured summary, or fresh start with artifacts only. An autonomous Executor decision guided by execution priorities, not user-configured. |
| **Build coordination** | The Executor's role as a supervisor of overall build health — monitoring for stuck chunks, detecting when failures suggest spec ambiguity, and rebalancing work across the dependency graph. Invisible to the user; manifests as better build outcomes. |
| **Convergence milestone** | A non-blocking checkpoint at a convergence phase boundary during a build. The Executor presents what the user can now try before the next layer builds. The build continues automatically unless the user stops it. Gives the user natural validation points without imposing approval gates. |
| **Visual dependency graph** | The build plan rendered as an interactive DAG in the spec viewer's mission control view. Chunk nodes show lifecycle states with color and animation. Dependency edges show the flow of work. Updates in real-time as the build progresses. |
| **Observer** | An infrastructure agent available to any other agent on demand. Observes any observable surface (browser, terminal, file system, APIs) and reports findings as verification verdicts or observation reports. Sits alongside the State Owner as an infrastructure peer — not in the domain pipeline. Runs automatic post-chunk verification during builds and can be invoked ad-hoc by any agent. |
| **Verification verdict** | A tight pass/fail result from the Observer for a specific check. Contains the check description, result (pass/fail), evidence (screenshots, API responses), and whether it passed on first attempt or after retry. Emitted as verification events to the activity feed. |
| **Observation report** | A broad scan result from the Observer. Contains what was checked, what was seen, and findings with evidence. Used for general observation requests rather than specific pass/fail checks. |
| **Verification audit trail** | A structured record of all Observer checks during a build run, produced via executable markdown. Links evidence (screenshots, command outputs) to the checks that produced them. Downloadable alongside the build log. |
| **Build event** | A typed event emitted during a build run. Includes both lifecycle events (from the Executor) and verification events (from the Observer). Events feed the activity feed in mission control and are stored in the build run for post-build review. |
| **Lifecycle event** | An event emitted by the Executor as chunks progress: chunk-started, chunk-completed, chunk-failed, chunk-retrying, section-started, section-completed, scenario-evaluated. These form the backbone of the activity feed during builds. |
| **Verification event** | An event emitted by the Observer after checking a chunk's output: chunk-verified (pass) or verification-failed (with evidence). Complements lifecycle events in the activity feed. |
| **Version registry** | A declarative model in `.fctry/config.json` that defines what versions a project tracks (one external, one or more internal), where each appears (propagation targets), how each increments (rules), and how internal changes ripple to the external version (relationship rules). Seeded at init, enriched at first execute via auto-discovery. All version changes propagate automatically to declared targets. |
| **External version** | The project's public-facing semver version — what users, consumers, and release notes reference. One per project. Managed by the version registry. |
| **Internal version** | A version tracking an internal artifact — the spec version, an API version, a schema version, etc. Multiple allowed per project. Each has its own increment rules and propagation targets. |
| **Propagation target** | A specific file and location where a version appears (e.g., `package.json` → `version` field). Declared in the version registry. Updated atomically when the version changes. |
| **Version relationship rule** | A rule governing how an internal version change triggers an external version change (e.g., major spec change → suggest external minor bump). Default relationships are universal; project-specific relationships can be added. |
| **Spec status** | A lifecycle indicator in the spec frontmatter with three values: `draft` (initial creation), `active` (spec and scenarios written, being iterated or built from), `stable` (full scenario satisfaction, no drift). Transitions are fully automatic. There is no `building` status — build-in-progress is tracked in the build run, not the spec lifecycle. |
| **Software Factory model** | A development model where code is written entirely by machines, validated entirely through scenarios (not human code review), and success is measured by satisfaction (not pass/fail). See StrongDM's article: https://factory.strongdm.ai/ |
